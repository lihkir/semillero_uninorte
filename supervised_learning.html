
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Aprendizaje supervisado &#8212; Maestría en Estadística Aplicada</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" href="_static/styles/sphinx-book-theme.css?digest=5115cc725059bd94278eecd172e13a965bf8f5a9" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/proof.css" />
    <link rel="stylesheet" type="text/css" href="_static/design-style.b7bb847fb20b106c3d81b95245e65545.min.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script src="_static/scripts/sphinx-book-theme.js?digest=9c920249402e914e316237a7dbc6769907cce411"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Evaluación de modelos" href="model_evaluation.html" />
    <link rel="prev" title="Introducción a Dash y Jupyter Book" href="dash_jbook.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="_static/logo-uninorte.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Maestría en Estadística Aplicada</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="intro.html">
                    Machine Learning
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="dash_jbook.html">
   Introducción a
   <code class="docutils literal notranslate">
    <span class="pre">
     Dash
    </span>
   </code>
   y
   <code class="docutils literal notranslate">
    <span class="pre">
     Jupyter
    </span>
    <span class="pre">
     Book
    </span>
   </code>
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   Aprendizaje supervisado
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="model_evaluation.html">
   Evaluación de modelos
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="chains_pipelines.html">
   Cadenas de Algoritmos y Pipelines
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="unsupervised_learning.html">
   Aprendizaje de maquinas no supervisado
  </a>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<div class="menu-dropdown menu-dropdown-launch-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Launch interactive content">
      <i class="fas fa-rocket"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://mybinder.org/v2/gh/executablebooks/jupyter-book/master?urlpath=tree/docs/supervised_learning.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Launch on Binder"
>
  

<span class="headerbtn__icon-container">
  
    <img src="_static/images/logo_binder.svg">
  </span>
<span class="headerbtn__text-container">Binder</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

<div class="menu-dropdown menu-dropdown-repository-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Source repositories">
      <i class="fab fa-github"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://github.com/executablebooks/jupyter-book"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Source repository"
>
  

<span class="headerbtn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="headerbtn__text-container">repository</span>
</a>

      </li>
      
      <li>
        <a href="https://github.com/executablebooks/jupyter-book/issues/new?title=Issue%20on%20page%20%2Fsupervised_learning.html&body=Your%20issue%20content%20here."
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Open an issue"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="headerbtn__text-container">open issue</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="_sources/supervised_learning.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.ipynb</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#ejemplos-de-tareas-de-aprendizaje-automatico-supervisado">
   Ejemplos de tareas de aprendizaje automático supervisado
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#clasificacion-y-regresion">
   Clasificación y regresión
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#generalizacion-sobreajuste-y-subajuste">
   Generalización, sobreajuste y subajuste
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#relacion-entre-la-complejidad-del-modelo-y-el-tamano-del-conjunto-de-datos">
   Relación entre la complejidad del modelo y el tamaño del conjunto de datos
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#algoritmos-de-aprendizaje-automatico-supervisado">
   Algoritmos de aprendizaje automático supervisado
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#algunos-ejemplos-de-conjuntos-de-datos">
   Algunos ejemplos de conjuntos de datos
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#k-vecinos-mas-cercanos">
   <span class="math notranslate nohighlight">
    \(k\)
   </span>
   -Vecinos más cercanos
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#clasificacion-k-vecinos">
     Clasificación
     <span class="math notranslate nohighlight">
      \(k\)
     </span>
     -Vecinos
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#analisis-de-kneighborsclassifier">
     Análisis de
     <code class="docutils literal notranslate">
      <span class="pre">
       KNeighborsClassifier
      </span>
     </code>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#regresion-por-k-vecinos">
     Regresión por
     <span class="math notranslate nohighlight">
      \(k\)
     </span>
     -vecinos
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#analisis-de-kneighborsregressor">
     Análisis de
     <code class="docutils literal notranslate">
      <span class="pre">
       KNeighborsRegressor
      </span>
     </code>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#puntos-fuertes-puntos-debiles-y-parametros">
     Puntos fuertes, puntos débiles y parámetros
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#modelos-lineales">
   Modelos lineales
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#modelos-de-regresion-lineal">
     Modelos de regresión lineal
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#regresion-lineal-minimos-cuadrados-ordinarios-ols">
     Regresión lineal (Mínimos Cuadrados Ordinarios) OLS
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#regresion-ridge">
     Regresión ridge
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#lasso">
     Lasso
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#modelos-lineales-para-clasificacion">
     Modelos lineales para clasificación
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#modelos-lineales-para-la-clasificacion-multiclase">
     Modelos lineales para la clasificación multiclase
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id2">
     Puntos fuertes, puntos débiles y parámetros
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#clasificadores-naive-bayes">
   Clasificadores Naive Bayes
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#arboles-de-decision">
   Árboles de decisión
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#combinacion-de-clasificadores">
     Combinación de clasificadores
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#control-de-complejidad">
     Control de complejidad
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#analisis-de-los-arboles-de-decision">
     Análisis de los árboles de decisión
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#caracteristicas-importantes-en-los-arboles">
     Características importantes en los árboles
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#ensamble-de-arboles-de-decision">
     Ensamble de árboles de decisión
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#maquinas-de-vectores-de-soporte">
   Máquinas de vectores de soporte
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#analisis">
     Análisis
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#espacios-de-hilbert-con-kernel-reproductor">
     Espacios de Hilbert con Kernel reproductor
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#teorema-de-representacion">
     Teorema de representación
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#regresion-ridge-con-kernel">
     Regresión ridge con Kernel
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#regresion-de-vectores-de-soporte">
     Regresión de vectores de soporte
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#regresion-optima-lineal-varepsilon-insensible">
     Regresión óptima lineal
     <span class="math notranslate nohighlight">
      \(\varepsilon\)
     </span>
     -insensible
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#regresion-kernel-ridge">
     Regresión Kernel Ridge
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id12">
     Máquinas de vectores de soporte
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#clases-linealmente-separables-clasificador-de-maximo-margen">
     Clases linealmente separables: Clasificador de máximo margen
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#clases-no-separables">
     Clases no separables
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#aplicacion">
     Aplicación
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#modelos-lineales-y-caracteristicas-no-lineales">
     Modelos lineales y características no lineales
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#el-kernel-trick">
     El Kernel Trick
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#ajuste-de-los-parametros-de-svm">
     Ajuste de los parámetros de SVM
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#preprocesamiento-de-datos-para-svm">
     Preprocesamiento de datos para SVM
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id14">
     Puntos fuertes, puntos débiles y parámetros
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#redes-neuronales-y-deep-learning">
   Redes Neuronales y Deep Learning
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#gradiente-descendiente">
     Gradiente descendiente
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#redes-neuronales">
     Redes neuronales
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#el-perceptron">
     El perceptrón
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#redes-neuronales-multicapa-feed-forward">
     Redes Neuronales Multicapa Feed-Forward
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#redes-totalmente-conectadas">
     Redes Totalmente Conectadas
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#el-algoritmo-de-backpropagation">
     El Algoritmo De Backpropagation
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#el-esquema-de-backpropagation-para-gradiente-descendiente">
     El Esquema De Backpropagation Para Gradiente Descendiente
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#apendice">
   Apéndice
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#bibliografia">
   Bibliografía
  </a>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Aprendizaje supervisado</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#ejemplos-de-tareas-de-aprendizaje-automatico-supervisado">
   Ejemplos de tareas de aprendizaje automático supervisado
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#clasificacion-y-regresion">
   Clasificación y regresión
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#generalizacion-sobreajuste-y-subajuste">
   Generalización, sobreajuste y subajuste
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#relacion-entre-la-complejidad-del-modelo-y-el-tamano-del-conjunto-de-datos">
   Relación entre la complejidad del modelo y el tamaño del conjunto de datos
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#algoritmos-de-aprendizaje-automatico-supervisado">
   Algoritmos de aprendizaje automático supervisado
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#algunos-ejemplos-de-conjuntos-de-datos">
   Algunos ejemplos de conjuntos de datos
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#k-vecinos-mas-cercanos">
   <span class="math notranslate nohighlight">
    \(k\)
   </span>
   -Vecinos más cercanos
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#clasificacion-k-vecinos">
     Clasificación
     <span class="math notranslate nohighlight">
      \(k\)
     </span>
     -Vecinos
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#analisis-de-kneighborsclassifier">
     Análisis de
     <code class="docutils literal notranslate">
      <span class="pre">
       KNeighborsClassifier
      </span>
     </code>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#regresion-por-k-vecinos">
     Regresión por
     <span class="math notranslate nohighlight">
      \(k\)
     </span>
     -vecinos
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#analisis-de-kneighborsregressor">
     Análisis de
     <code class="docutils literal notranslate">
      <span class="pre">
       KNeighborsRegressor
      </span>
     </code>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#puntos-fuertes-puntos-debiles-y-parametros">
     Puntos fuertes, puntos débiles y parámetros
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#modelos-lineales">
   Modelos lineales
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#modelos-de-regresion-lineal">
     Modelos de regresión lineal
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#regresion-lineal-minimos-cuadrados-ordinarios-ols">
     Regresión lineal (Mínimos Cuadrados Ordinarios) OLS
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#regresion-ridge">
     Regresión ridge
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#lasso">
     Lasso
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#modelos-lineales-para-clasificacion">
     Modelos lineales para clasificación
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#modelos-lineales-para-la-clasificacion-multiclase">
     Modelos lineales para la clasificación multiclase
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id2">
     Puntos fuertes, puntos débiles y parámetros
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#clasificadores-naive-bayes">
   Clasificadores Naive Bayes
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#arboles-de-decision">
   Árboles de decisión
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#combinacion-de-clasificadores">
     Combinación de clasificadores
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#control-de-complejidad">
     Control de complejidad
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#analisis-de-los-arboles-de-decision">
     Análisis de los árboles de decisión
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#caracteristicas-importantes-en-los-arboles">
     Características importantes en los árboles
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#ensamble-de-arboles-de-decision">
     Ensamble de árboles de decisión
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#maquinas-de-vectores-de-soporte">
   Máquinas de vectores de soporte
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#analisis">
     Análisis
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#espacios-de-hilbert-con-kernel-reproductor">
     Espacios de Hilbert con Kernel reproductor
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#teorema-de-representacion">
     Teorema de representación
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#regresion-ridge-con-kernel">
     Regresión ridge con Kernel
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#regresion-de-vectores-de-soporte">
     Regresión de vectores de soporte
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#regresion-optima-lineal-varepsilon-insensible">
     Regresión óptima lineal
     <span class="math notranslate nohighlight">
      \(\varepsilon\)
     </span>
     -insensible
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#regresion-kernel-ridge">
     Regresión Kernel Ridge
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id12">
     Máquinas de vectores de soporte
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#clases-linealmente-separables-clasificador-de-maximo-margen">
     Clases linealmente separables: Clasificador de máximo margen
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#clases-no-separables">
     Clases no separables
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#aplicacion">
     Aplicación
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#modelos-lineales-y-caracteristicas-no-lineales">
     Modelos lineales y características no lineales
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#el-kernel-trick">
     El Kernel Trick
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#ajuste-de-los-parametros-de-svm">
     Ajuste de los parámetros de SVM
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#preprocesamiento-de-datos-para-svm">
     Preprocesamiento de datos para SVM
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id14">
     Puntos fuertes, puntos débiles y parámetros
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#redes-neuronales-y-deep-learning">
   Redes Neuronales y Deep Learning
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#gradiente-descendiente">
     Gradiente descendiente
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#redes-neuronales">
     Redes neuronales
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#el-perceptron">
     El perceptrón
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#redes-neuronales-multicapa-feed-forward">
     Redes Neuronales Multicapa Feed-Forward
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#redes-totalmente-conectadas">
     Redes Totalmente Conectadas
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#el-algoritmo-de-backpropagation">
     El Algoritmo De Backpropagation
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#el-esquema-de-backpropagation-para-gradiente-descendiente">
     El Esquema De Backpropagation Para Gradiente Descendiente
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#apendice">
   Apéndice
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#bibliografia">
   Bibliografía
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <section class="tex2jax_ignore mathjax_ignore" id="aprendizaje-supervisado">
<h1>Aprendizaje supervisado<a class="headerlink" href="#aprendizaje-supervisado" title="Permalink to this headline">#</a></h1>
<figure class="align-center" id="fig-supervised-classification">
<a class="reference internal image-reference" href="_images/supervised_classification.png"><img alt="_images/supervised_classification.png" src="_images/supervised_classification.png" style="width: 621.5999999999999px; height: 219.1px;" /></a>
</figure>
<ul class="simple">
<li><p>Los tipos de algoritmos de <code class="docutils literal notranslate"><span class="pre">aprendizaje</span> <span class="pre">automático</span></code> más exitosos son los que automatizan procesos de toma de decisiones mediante generalización, a partir de ejemplos conocidos, el <code class="docutils literal notranslate"><span class="pre">aprendizaje</span> <span class="pre">supervisado</span></code> es un claro ejemplo de este tipo de algoritmos. En el <code class="docutils literal notranslate"><span class="pre">aprendizaje</span> <span class="pre">supervisado</span></code>, el usuario proporciona al algoritmo pares de entradas/salidas deseadas <code class="docutils literal notranslate"><span class="pre">(datos</span> <span class="pre">etiquetados)</span></code>, para entrenar algoritmos que clasifiquen datos o predigan resultados con precisión.</p></li>
<li><p>El algoritmo encuentra la manera de producir el resultado deseado a partir de una entrada. A medida que los datos de entrada se introducen en el modelo, éste ajusta sus ponderaciones hasta que el modelo se ha ajustado adecuadamente. A este procedimiento de ajuste del modelo se le conoce como <code class="docutils literal notranslate"><span class="pre">validación</span> <span class="pre">cruzada</span></code>. En concreto, el algoritmo es capaz de crear una salida para una entrada que nunca ha visto antes, sin la ayuda de un humano. Los algoritmos de <code class="docutils literal notranslate"><span class="pre">aprendizaje</span> <span class="pre">supervisado</span></code> son llamados así, porque un “maestro” proporciona supervisión a los algoritmos, en forma de las salidas deseadas para cada ejemplo del que aprenden.</p></li>
</ul>
<section id="ejemplos-de-tareas-de-aprendizaje-automatico-supervisado">
<h2>Ejemplos de tareas de aprendizaje automático supervisado<a class="headerlink" href="#ejemplos-de-tareas-de-aprendizaje-automatico-supervisado" title="Permalink to this headline">#</a></h2>
<ul class="simple">
<li><p><strong><code class="docutils literal notranslate"><span class="pre">Identificar</span> <span class="pre">el</span> <span class="pre">código</span> <span class="pre">postal</span> <span class="pre">a</span> <span class="pre">partir</span> <span class="pre">de</span> <span class="pre">los</span> <span class="pre">dígitos</span> <span class="pre">escritos</span> <span class="pre">a</span> <span class="pre">mano</span> <span class="pre">en</span> <span class="pre">un</span> <span class="pre">sobre:</span></code></strong>
Aquí la entrada es un escaneo de la escritura a mano, y la salida deseada son los dígitos reales del código postal. Para crear un conjunto de datos para construir un modelo de aprendizaje automático, hay que recoger muchos sobres. Entonces puedes leer los códigos postales tú mismo y almacenar los dígitos como los resultados deseados.</p></li>
<li><p><strong><code class="docutils literal notranslate"><span class="pre">Determinar</span> <span class="pre">si</span> <span class="pre">un</span> <span class="pre">tumor</span> <span class="pre">es</span> <span class="pre">benigno</span> <span class="pre">a</span> <span class="pre">partir</span> <span class="pre">de</span> <span class="pre">una</span> <span class="pre">imagen</span> <span class="pre">médica:</span></code></strong>
Aquí la entrada es la imagen, y la salida es si el tumor es benigno. Para crear un conjunto de datos para construir un modelo, se necesita una base de datos de imágenes médicas. También se necesita la opinión de un experto, por lo que un médico tiene que ver todas las imágenes y decidir qué tumores son benignos y cuáles no. Incluso puede ser necesario hacer un diagnóstico adicional más allá del contenido de la imagen para determinar si el tumor de la imagen es cancerígeno o no.</p></li>
<li><p><strong><code class="docutils literal notranslate"><span class="pre">Detección</span> <span class="pre">de</span> <span class="pre">actividades</span> <span class="pre">fraudulentas</span> <span class="pre">en</span> <span class="pre">transacciones</span> <span class="pre">con</span> <span class="pre">tarjetas</span> <span class="pre">de</span> <span class="pre">crédito</span></code></strong>
Aquí la entrada es un registro de la transacción de la tarjeta de crédito, y la salida es si es probable que sea fraudulenta o no. Suponiendo que usted es la entidad que distribuye las tarjetas de crédito, recopilar un conjunto de datos significa almacenar todas las transacciones y registrar si un usuario denuncia alguna transacción como fraudulenta.</p></li>
</ul>
</section>
<section id="clasificacion-y-regresion">
<h2>Clasificación y regresión<a class="headerlink" href="#clasificacion-y-regresion" title="Permalink to this headline">#</a></h2>
<ul class="simple">
<li><p>Hay dos tipos principales de problemas de <code class="docutils literal notranslate"><span class="pre">aprendizaje</span> <span class="pre">automático</span> <span class="pre">supervisado</span></code>, denominados <code class="docutils literal notranslate"><span class="pre">clasificación</span></code> y <code class="docutils literal notranslate"><span class="pre">regresión</span></code>. En la <code class="docutils literal notranslate"><span class="pre">clasificación</span></code>, el objetivo es predecir una etiqueta de clase, que es una elección entre una lista predefinida de posibilidades. La <code class="docutils literal notranslate"><span class="pre">clasificación</span></code> se divide en <code class="docutils literal notranslate"><span class="pre">clasificación</span> <span class="pre">binaria</span></code>, que es el caso especial de distinguir entre exactamente dos clases, y <code class="docutils literal notranslate"><span class="pre">clasificación</span> <span class="pre">multiclase</span></code>, que es la clasificación entre más de dos clases. Se puede pensar en la <code class="docutils literal notranslate"><span class="pre">clasificación</span> <span class="pre">binaria</span></code> como si se tratara de responder sí/no a una pregunta. Clasificar los correos electrónicos como spam o no spam es un ejemplo de problema de clasificación binaria.</p></li>
<li><p><em>En la <code class="docutils literal notranslate"><span class="pre">clasificación</span> <span class="pre">binaria</span></code> se suele hablar de que una clase es la <code class="docutils literal notranslate"><span class="pre">positiva</span></code> y la otra la <code class="docutils literal notranslate"><span class="pre">negativa</span></code>. Aquí, <code class="docutils literal notranslate"><span class="pre">positivo</span></code> no representa tener un beneficio o un valor, sino cuál es el objeto de estudio. Así, cuando se busca el spam, <code class="docutils literal notranslate"><span class="pre">&quot;positivo&quot;</span></code> podría significar la clase de spam. Cuál de las dos clases se denomina <code class="docutils literal notranslate"><span class="pre">positiva</span></code> suele ser una cuestión subjetiva y específica del ámbito.</em></p></li>
</ul>
<ul class="simple">
<li><p>En las tareas de <code class="docutils literal notranslate"><span class="pre">regresión</span></code>, el objetivo es predecir un número continuo, o flotante en términos de programación (o un número real en términos matemáticos). Predecir los ingresos anuales de una persona a partir de su educación, su edad y su lugar de residencia es un ejemplo de tarea de <code class="docutils literal notranslate"><span class="pre">regresión</span></code>. Al predecir los ingresos, el valor predicho es una cantidad, y puede ser cualquier número en un rango determinado.</p></li>
<li><p>Una forma fácil de distinguir entre las tareas de <code class="docutils literal notranslate"><span class="pre">clasificación</span></code> y las de <code class="docutils literal notranslate"><span class="pre">regresión</span></code> es preguntarse si hay algún tipo de <em>continuidad en el resultado</em>. Si hay <em>continuidad</em> entre los posibles resultados, el problema es de regresión. En cambio, para la tarea de reconocer el idioma de un sitio web (que es un problema de <code class="docutils literal notranslate"><span class="pre">clasificación</span></code>), no hay cuestión de grado. Un sitio web está en un idioma o en otro. No hay continuidad entre las lenguas, y no hay ninguna lengua que esté entre el inglés y el francés.</p></li>
</ul>
</section>
<section id="generalizacion-sobreajuste-y-subajuste">
<h2>Generalización, sobreajuste y subajuste<a class="headerlink" href="#generalizacion-sobreajuste-y-subajuste" title="Permalink to this headline">#</a></h2>
<ul class="simple">
<li><p>En el <code class="docutils literal notranslate"><span class="pre">aprendizaje</span> <span class="pre">supervisado</span></code>, queremos construir un modelo sobre los datos de entrenamiento y luego ser capaces de realizar predicciones precisas, sobre datos desconocidos que tengan las mismas características que el conjunto de entrenamiento que hemos utilizado. Si un modelo es capaz de realizar predicciones precisas, sobre datos desconocidos, decimos que es capaz de <code class="docutils literal notranslate"><span class="pre">generalizar</span></code> del conjunto de <code class="docutils literal notranslate"><span class="pre">entrenamiento</span></code> al conjunto de <code class="docutils literal notranslate"><span class="pre">prueba</span></code>. Queremos construir un modelo que sea capaz de <code class="docutils literal notranslate"><span class="pre">generalizar</span></code> con la mayor precisión posible.</p></li>
<li><p>Por lo general, construimos un modelo de manera que pueda hacer predicciones precisas en el conjunto de entrenamiento. Si los conjuntos de <code class="docutils literal notranslate"><span class="pre">entrenamiento</span></code> y de <code class="docutils literal notranslate"><span class="pre">prueba</span></code> tienen suficientes puntos en común, esperamos que el modelo también sea preciso en el conjunto de <code class="docutils literal notranslate"><span class="pre">prueba</span></code>. Sin embargo, hay algunos casos en los que esto puede no funcionar. Por ejemplo, si nos permitimos construir modelos muy complejos, podemos siempre ser tan precisos como queramos en el conjunto de entrenamiento, pero que no es capaz de generalizarse a nuevos datos <code class="docutils literal notranslate"><span class="pre">sobreajuste</span></code>.</p></li>
<li><p>El <code class="docutils literal notranslate"><span class="pre">sobreajuste</span> <span class="pre">(overfitting)</span></code> se produce cuando se ajusta un modelo demasiado a las particularidades del conjunto de entrenamiento, y se obtiene un modelo que funciona bien en el conjunto de entrenamiento pero no es capaz de generalizarse con nuevos datos. Por otro lado, si el modelo es demasiado simple, es posible que no sea capaz de captar todos los aspectos y la variabilidad de los datos, y el modelo funcionará mal incluso en el conjunto de entrenamiento. La elección de demasiado simple se denomina <code class="docutils literal notranslate"><span class="pre">subajuste</span> <span class="pre">(underfitting)</span></code>.</p></li>
</ul>
<ul class="simple">
<li><p><em><code class="docutils literal notranslate"><span class="pre">Cuanto</span> <span class="pre">más</span> <span class="pre">complejo</span> <span class="pre">permitimos</span> <span class="pre">que</span> <span class="pre">sea</span> <span class="pre">nuestro</span> <span class="pre">modelo,</span> <span class="pre">mejor</span> <span class="pre">podremos</span> <span class="pre">predecir</span> <span class="pre">en</span> <span class="pre">los</span> <span class="pre">datos</span> <span class="pre">de</span> <span class="pre">entrenamiento.</span> <span class="pre">Sin</span> <span class="pre">embargo,</span> <span class="pre">si</span> <span class="pre">nuestro</span> <span class="pre">modelo</span> <span class="pre">se</span> <span class="pre">vuelve</span> <span class="pre">demasiado</span> <span class="pre">complejo,</span> <span class="pre">empezamos</span> <span class="pre">a</span> <span class="pre">centrarnos</span> <span class="pre">demasiado</span> <span class="pre">en</span> <span class="pre">cada</span> <span class="pre">punto</span> <span class="pre">de</span> <span class="pre">datos</span> <span class="pre">individual</span> <span class="pre">de</span> <span class="pre">nuestro</span> <span class="pre">conjunto</span> <span class="pre">de</span> <span class="pre">entrenamiento,</span> <span class="pre">y</span> <span class="pre">el</span> <span class="pre">modelo</span> <span class="pre">no</span> <span class="pre">se</span> <span class="pre">generalizará</span> <span class="pre">correctamente</span> <span class="pre">con</span> <span class="pre">nuevos</span> <span class="pre">datos.</span> <span class="pre">Hay</span> <span class="pre">un</span> <span class="pre">punto</span> <span class="pre">intermedio</span> <span class="pre">en</span> <span class="pre">el</span> <span class="pre">que</span> <span class="pre">se</span> <span class="pre">obtiene</span> <span class="pre">el</span> <span class="pre">mejor</span> <span class="pre">rendimiento</span> <span class="pre">de</span> <span class="pre">generalización.</span> <span class="pre">Este</span> <span class="pre">es</span> <span class="pre">el</span> <span class="pre">modelo</span> <span class="pre">que</span> <span class="pre">queremos</span> <span class="pre">encontrar.</span> <span class="pre">El</span> <span class="pre">equilibrio</span> <span class="pre">entre</span> <span class="pre">el</span> <span class="pre">overfitting</span> <span class="pre">y</span> <span class="pre">underfitting.</span></code></em></p></li>
</ul>
<figure class="align-center" id="fig-sweet-spot">
<img alt="_images/sweet_spot.png" src="_images/sweet_spot.png" />
<figcaption>
<p><span class="caption-number">Fig. 1 </span><span class="caption-text">Equilibrio entre la complejidad del modelo frente a la precisión del entrenamiento y la prueba.</span><a class="headerlink" href="#fig-sweet-spot" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
</section>
<section id="relacion-entre-la-complejidad-del-modelo-y-el-tamano-del-conjunto-de-datos">
<h2>Relación entre la complejidad del modelo y el tamaño del conjunto de datos<a class="headerlink" href="#relacion-entre-la-complejidad-del-modelo-y-el-tamano-del-conjunto-de-datos" title="Permalink to this headline">#</a></h2>
<ul class="simple">
<li><p>Es importante señalar que la complejidad del modelo está íntimamente ligada a la variación de entradas contenidas en el conjunto de datos de entrenamiento: <code class="docutils literal notranslate"><span class="pre">cuanto</span> <span class="pre">mayor</span> <span class="pre">sea</span> <span class="pre">la</span> <span class="pre">variedad</span> <span class="pre">de</span> <span class="pre">puntos</span> <span class="pre">de</span> <span class="pre">datos,</span> <span class="pre">más</span> <span class="pre">complejo</span> <span class="pre">será</span> <span class="pre">el</span> <span class="pre">modelo</span> <span class="pre">que</span> <span class="pre">se</span> <span class="pre">puede</span> <span class="pre">utilizar</span> <span class="pre">sin</span> <span class="pre">sobreajustar</span></code>. Por lo general, al recolectar más puntos de datos se obtiene un modelo más complejo sin que haya un exceso de ajuste. Sin embargo, la simple duplicación de los mismos puntos de datos o la recopilación de datos muy similares no ayudará.</p></li>
<li><p>Disponer de más datos y construir modelos adecuadamente más complejos a menudo puede hacer maravillas en las tareas de <code class="docutils literal notranslate"><span class="pre">aprendizaje</span> <span class="pre">supervisado</span></code>. En este curso, nos centraremos en trabajar con conjuntos de datos de tamaño fijo. En el mundo real, a menudo se puede decidir la cantidad de datos que se van a recoger, lo cual puede ser más beneficioso que ajustar y afinar su modelo. <code class="docutils literal notranslate"><span class="pre">Nunca</span> <span class="pre">subestime</span> <span class="pre">el</span> <span class="pre">poder</span> <span class="pre">de</span> <span class="pre">tener</span> <span class="pre">más</span> <span class="pre">datos</span></code>.</p></li>
</ul>
</section>
<section id="algoritmos-de-aprendizaje-automatico-supervisado">
<h2>Algoritmos de aprendizaje automático supervisado<a class="headerlink" href="#algoritmos-de-aprendizaje-automatico-supervisado" title="Permalink to this headline">#</a></h2>
<ul class="simple">
<li><p>A continuación se abordarán los <code class="docutils literal notranslate"><span class="pre">algoritmos</span> <span class="pre">de</span> <span class="pre">aprendizaje</span> <span class="pre">automático</span></code> más populares. Se estudiará cómo aprenden de los datos y cómo hacen predicciones. También discutiremos el concepto de complejidad para cada uno de estos modelos, y proporcionaremos una visión general de cómo cada algoritmo construye un modelo. Examinaremos los puntos fuertes y débiles de cada algoritmo y a qué tipo de datos pueden aplicarse mejor. También explicaremos el significado de los parámetros y opciones más importantes. Muchos algoritmos tienen una variante de clasificación y otra de regresión, y describiremos ambas.</p></li>
</ul>
</section>
<section id="algunos-ejemplos-de-conjuntos-de-datos">
<h2>Algunos ejemplos de conjuntos de datos<a class="headerlink" href="#algunos-ejemplos-de-conjuntos-de-datos" title="Permalink to this headline">#</a></h2>
<ul>
<li><p>Utilizaremos varios conjuntos de datos para ilustrar los diferentes algoritmos. Algunos de los conjuntos de datos serán pequeños y sintéticos, diseñados para destacar aspectos concretos de los algoritmos. Otros conjuntos de datos serán ejemplos grandes del mundo real. Un ejemplo de conjunto de datos sintético de clasificación de dos clases es el conjunto de datos de <code class="docutils literal notranslate"><span class="pre">forge</span></code>, que tiene dos características.</p></li>
<li><p>El siguiente código crea un gráfico de dispersión que visualiza todos los puntos de datos de este <code class="docutils literal notranslate"><span class="pre">dataset</span></code>. El gráfico tiene la primera característica en el eje <span class="math notranslate nohighlight">\(x\)</span> y la segunda en el eje <span class="math notranslate nohighlight">\(y\)</span>. Como siempre ocurre en los gráficos de dispersión, cada punto de datos está representado por un punto. El color y la forma del punto indican su clase. Generamos el conjunto de datos usando la librería <code class="docutils literal notranslate"><span class="pre">mglearn</span></code> (también puede utilizar <code class="docutils literal notranslate"><span class="pre">make_blobs</span></code> de <code class="docutils literal notranslate"><span class="pre">sklearn</span></code>) e importamos <code class="docutils literal notranslate"><span class="pre">warning</span></code> para evitar mensajes molestos, relacionados con advertencias inofensivas o funciones obsoletas en la actual versión de <code class="docutils literal notranslate"><span class="pre">Python</span></code>. En el presente curso usaremos las <code class="docutils literal notranslate"><span class="pre">versión</span> <span class="pre">3.8</span> <span class="pre">de</span> <span class="pre">Python</span></code>.</p></li>
<li><p>Para instalar <code class="docutils literal notranslate"><span class="pre">mglearn</span></code> en su ambiente para <code class="docutils literal notranslate"><span class="pre">Machine</span> <span class="pre">Learning</span></code> utilizar la siguiente orden</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>pip install mglearn
</pre></div>
</div>
<p>Si su algortimo presenta algún problema a la hora de reconocer <code class="docutils literal notranslate"><span class="pre">mglearn</span></code>, para solucionar este problema, elimine su actual enviroment. Luego cree un nuevo enviroment y en este instale el requirement asociado a este curso. El archivo aparece en (ver <a class="reference external" href="https://github.com/lihkir/Data/blob/main/requirements.txt">requirements.txt</a>).</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>pip install -r requirements.txt
</pre></div>
</div>
</li>
</ul>
<ul class="simple">
<li><p>Procedemos ahora sí a importar cada una de las librerías del ejemplo, incluyendo: <code class="docutils literal notranslate"><span class="pre">matplotlib</span></code> y <code class="docutils literal notranslate"><span class="pre">numpy</span></code></p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">warnings</span>
<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s2">&quot;ignore&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">mglearn</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">mglearn</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">make_forge</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Trazar el conjunto de datos</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">mglearn</span><span class="o">.</span><span class="n">discrete_scatter</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">y</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">([</span><span class="s2">&quot;Class 0&quot;</span><span class="p">,</span> <span class="s2">&quot;Class 1&quot;</span><span class="p">],</span> <span class="n">loc</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;First feature&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Second feature&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;X.shape: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>X.shape: (26, 2)
</pre></div>
</div>
<img alt="_images/supervised_learning_22_1.png" src="_images/supervised_learning_22_1.png" />
</div>
</div>
<ul class="simple">
<li><p>Como se puede ver en <code class="docutils literal notranslate"><span class="pre">X.shape</span></code>, este dataset consta de 26 puntos de datos, con 2 características. Para ilustrar los algoritmos de regresión, utilizaremos el dataset sintético <code class="docutils literal notranslate"><span class="pre">wave</span></code>. Este dataset tiene una única característica de entrada y una variable objetivo continua (o respuesta) que queremos modelar.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">mglearn</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">make_wave</span><span class="p">(</span><span class="n">n_samples</span><span class="o">=</span><span class="mi">40</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="s1">&#39;o&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="o">-</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Feature&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Target&quot;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/supervised_learning_24_0.png" src="_images/supervised_learning_24_0.png" />
</div>
</div>
<ul class="simple">
<li><p>Complementaremos estos pequeños datasets sintéticos con dos conjuntos de datos del mundo real que se incluyen en <code class="docutils literal notranslate"><span class="pre">scikit-learn</span></code>. Uno de ellos es el conjunto de datos de cáncer de mama de Wisconsin (<code class="docutils literal notranslate"><span class="pre">cancer</span></code>, para abreviar), que registra mediciones clínicas de tumores de cáncer de mama. Cada tumor se etiqueta como <code class="docutils literal notranslate"><span class="pre">benign</span></code> (para tumores inofensivos) o <code class="docutils literal notranslate"><span class="pre">malignant</span></code> (para tumores cancerosos). La tarea es aprender a predecir si un tumor es maligno basándose en las mediciones del tejido. Los datos pueden cargarse con la función <code class="docutils literal notranslate"><span class="pre">load_breast_cancer</span></code> de <code class="docutils literal notranslate"><span class="pre">scikit-learn</span></code></p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_breast_cancer</span>
<span class="n">cancer</span> <span class="o">=</span> <span class="n">load_breast_cancer</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;cancer.keys(): </span><span class="se">\n</span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">cancer</span><span class="o">.</span><span class="n">keys</span><span class="p">()))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>cancer.keys(): 
dict_keys([&#39;data&#39;, &#39;target&#39;, &#39;frame&#39;, &#39;target_names&#39;, &#39;DESCR&#39;, &#39;feature_names&#39;, &#39;filename&#39;, &#39;data_module&#39;])
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p><em><code class="docutils literal notranslate"><span class="pre">Los</span> <span class="pre">conjuntos</span> <span class="pre">de</span> <span class="pre">datos</span> <span class="pre">que</span> <span class="pre">se</span> <span class="pre">incluyen</span> <span class="pre">en</span> <span class="pre">scikit-learn</span> <span class="pre">suelen</span> <span class="pre">almacenarse</span> <span class="pre">como</span> <span class="pre">objetos</span> <span class="pre">Bunch,</span> <span class="pre">que</span> <span class="pre">contienen</span> <span class="pre">alguna</span> <span class="pre">información</span> <span class="pre">sobre</span> <span class="pre">el</span> <span class="pre">conjunto</span> <span class="pre">de</span> <span class="pre">datos</span> <span class="pre">así</span> <span class="pre">como</span> <span class="pre">los</span> <span class="pre">datos</span> <span class="pre">reales.</span> <span class="pre">Todo</span> <span class="pre">lo</span> <span class="pre">que</span> <span class="pre">necesita</span> <span class="pre">saber</span> <span class="pre">sobre</span> <span class="pre">los</span> <span class="pre">objetos</span> <span class="pre">Bunch</span> <span class="pre">es</span> <span class="pre">que</span> <span class="pre">se</span> <span class="pre">comportan</span> <span class="pre">como</span> <span class="pre">diccionarios,</span> <span class="pre">con</span> <span class="pre">la</span> <span class="pre">ventaja</span> <span class="pre">añadida</span> <span class="pre">de</span> <span class="pre">que</span> <span class="pre">se</span> <span class="pre">puede</span> <span class="pre">acceder</span> <span class="pre">a</span> <span class="pre">los</span> <span class="pre">valores</span> <span class="pre">utilizando</span> <span class="pre">un</span> <span class="pre">punto</span> <span class="pre">(como</span> <span class="pre">en</span> <span class="pre">bunch.key</span> <span class="pre">en</span> <span class="pre">lugar</span> <span class="pre">de</span> <span class="pre">bunch['clave']</span> <span class="pre">).</span></code></em></p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Shape of cancer data: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">cancer</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Shape of cancer data: (569, 30)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">cancer</span><span class="o">.</span><span class="n">target_names</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([&#39;malignant&#39;, &#39;benign&#39;], dtype=&#39;&lt;U9&#39;)
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>El conjunto de datos consta de 569 puntos de datos, con 30 características cada uno</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Sample counts per class:</span><span class="se">\n</span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
<span class="p">{</span><span class="n">n</span><span class="p">:</span> <span class="n">v</span> <span class="k">for</span> <span class="n">n</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">cancer</span><span class="o">.</span><span class="n">target_names</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">bincount</span><span class="p">(</span><span class="n">cancer</span><span class="o">.</span><span class="n">target</span><span class="p">))}))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Sample counts per class:
{&#39;malignant&#39;: 212, &#39;benign&#39;: 357}
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>De estos 569 puntos de datos, 212 están etiquetados como malignos y 357 como benignos. Para obtener una descripción del significado semántico de cada característica, podemos echar un vistazo a el atributo <code class="docutils literal notranslate"><span class="pre">feature_names</span></code>. Si está interesado, puede obtener más información sobre los datos leyendo <code class="docutils literal notranslate"><span class="pre">cancer.DESCR</span></code>. Para mas información acerca de este conjunto de datos (ver <a class="reference external" href="https://scikit-learn.org/stable/datasets/toy_dataset.html#breast-cancer-dataset">Breast cancer wisconsin (diagnostic) dataset</a>)</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Feature names:</span><span class="se">\n</span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">cancer</span><span class="o">.</span><span class="n">feature_names</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Feature names:
[&#39;mean radius&#39; &#39;mean texture&#39; &#39;mean perimeter&#39; &#39;mean area&#39;
 &#39;mean smoothness&#39; &#39;mean compactness&#39; &#39;mean concavity&#39;
 &#39;mean concave points&#39; &#39;mean symmetry&#39; &#39;mean fractal dimension&#39;
 &#39;radius error&#39; &#39;texture error&#39; &#39;perimeter error&#39; &#39;area error&#39;
 &#39;smoothness error&#39; &#39;compactness error&#39; &#39;concavity error&#39;
 &#39;concave points error&#39; &#39;symmetry error&#39; &#39;fractal dimension error&#39;
 &#39;worst radius&#39; &#39;worst texture&#39; &#39;worst perimeter&#39; &#39;worst area&#39;
 &#39;worst smoothness&#39; &#39;worst compactness&#39; &#39;worst concavity&#39;
 &#39;worst concave points&#39; &#39;worst symmetry&#39; &#39;worst fractal dimension&#39;]
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>También utilizaremos un conjunto de datos de regresión del mundo real, el conjunto de datos <code class="docutils literal notranslate"><span class="pre">Boston</span> <span class="pre">Housing</span></code>. La tarea asociada a este conjunto de datos consiste en predecir el valor medio de las viviendas en varios barrios de Boston en la década de 1970, utilizando información como el índice de criminalidad, la proximidad al río Charles, la accesibilidad a las autopistas, etc. El dataset contiene 506 puntos de datos, descritos por 13 características</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_boston</span>
<span class="n">boston</span> <span class="o">=</span> <span class="n">load_boston</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Data shape: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">boston</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Data shape: (506, 13)
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>De nuevo, puede obtener más información sobre el conjunto de datos leyendo el atributo <code class="docutils literal notranslate"><span class="pre">DESCR</span></code> de <code class="docutils literal notranslate"><span class="pre">boston</span></code>. Para nuestro propósito, vamos a ampliar este conjunto de datos, no sólo 13 mediciones como características de entrada serán consideradas, sino también observando todos los productos (también llamados <code class="docutils literal notranslate"><span class="pre">interactions</span></code>) entre las características. En otras palabras, no sólo consideraremos la tasa de criminalidad y la accesibilidad a las carreteras como características, sino que también, el producto entre la tasa de criminalidad y la accesibilidad a las carreteras. La inclusión de características derivadas como éstas se denomina <code class="docutils literal notranslate"><span class="pre">ingeniería</span> <span class="pre">de</span> <span class="pre">características</span> <span class="pre">(feature</span> <span class="pre">engineering)</span></code>, de la que hablaremos en secciones posteriores. Este conjunto de datos derivados puede ser cargado con la función <code class="docutils literal notranslate"><span class="pre">load_extended_boston</span></code></p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">mglearn</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">load_extended_boston</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;X.shape: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>X.shape: (506, 104)
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Las 104 características resultantes son las 13 características originales junto con las 91 combinaciones posibles de dos características dentro de esas 13. Utilizaremos estos conjuntos de datos para explicar e ilustrar las propiedades de los distintos algoritmos de aprendizaje automático. Pero por ahora, vamos a hablar de los algoritmos en sí. En primer lugar, vamos a examinar el algoritmo de los <code class="docutils literal notranslate"><span class="pre">vecinos</span> <span class="pre">más</span> <span class="pre">cercanos</span> <span class="pre">(k-nearest</span> <span class="pre">neighbors)</span> <span class="pre">(k-NN)</span></code>.</p></li>
</ul>
</section>
<section id="k-vecinos-mas-cercanos">
<h2><span class="math notranslate nohighlight">\(k\)</span>-Vecinos más cercanos<a class="headerlink" href="#k-vecinos-mas-cercanos" title="Permalink to this headline">#</a></h2>
<ul class="simple">
<li><p>El algoritmo <span class="math notranslate nohighlight">\(k\)</span>-NN es posiblemente el algoritmo de aprendizaje automático más sencillo. La construcción de el modelo consiste únicamente en almacenar el conjunto de datos de entrenamiento. Para hacer una predicción de un nuevo punto de datos, el algoritmo encuentra los puntos de datos más cercanos en el conjunto de datos de entrenamiento, <code class="docutils literal notranslate"><span class="pre">&quot;nearest</span> <span class="pre">neighbors&quot;</span></code>.</p></li>
</ul>
<section id="clasificacion-k-vecinos">
<h3>Clasificación <span class="math notranslate nohighlight">\(k\)</span>-Vecinos<a class="headerlink" href="#clasificacion-k-vecinos" title="Permalink to this headline">#</a></h3>
<ul class="simple">
<li><p>En su versión más sencilla, el algoritmo <code class="docutils literal notranslate"><span class="pre">k-NN</span></code> sólo considera exactamente un vecino más cercano, que es el dato de entrenamiento más cercano al punto para el que queremos hacer una predicción. La predicción es entonces simplemente la salida conocida para este punto de entrenamiento.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">mglearn</span><span class="o">.</span><span class="n">plots</span><span class="o">.</span><span class="n">plot_knn_classification</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/supervised_learning_43_0.png" src="_images/supervised_learning_43_0.png" />
</div>
</div>
<ul class="simple">
<li><p>Aquí, añadimos tres nuevos puntos de datos, mostrados como estrellas. Para cada uno de ellos, marcamos el punto más cercano en el conjunto de entrenamiento. La predicción del algoritmo del <code class="docutils literal notranslate"><span class="pre">vecino</span> <span class="pre">más</span> <span class="pre">cercano</span></code> es la etiqueta de ese punto (mostrada por el color de la cruz).</p></li>
<li><p>En lugar de considerar sólo al vecino más cercano, también podemos considerar un número arbitrario <span class="math notranslate nohighlight">\(k\)</span>, de vecinos. De ahí viene el nombre del algoritmo <span class="math notranslate nohighlight">\(k\)</span>-vecinos más cercanos. Cuando se considera más de un vecino, se utiliza la votación para asignar una etiqueta. Esto significa que, para cada punto de prueba, contamos cuántos vecinos pertenecen a clase 0 y cuántos vecinos pertenecen a la clase 1. A continuación, asignamos la clase que es más frecuente: es decir, la clase mayoritaria entre los <span class="math notranslate nohighlight">\(k\)</span> <code class="docutils literal notranslate"><span class="pre">vecinos</span> <span class="pre">más</span> <span class="pre">cercanos</span></code>.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">mglearn</span><span class="o">.</span><span class="n">plots</span><span class="o">.</span><span class="n">plot_knn_classification</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/supervised_learning_45_0.png" src="_images/supervised_learning_45_0.png" />
</div>
</div>
<ul class="simple">
<li><p>Aunque esta ilustración se refiere a un problema de clasificación binaria, este método puede aplicarse a conjuntos de datos con cualquier número de clases. Para más clases, contamos cuántos vecinos pertenecen a cada clase y volvemos a predecir la clase más común. Ahora veamos cómo podemos aplicar el algoritmo de los <code class="docutils literal notranslate"><span class="pre">vecinos</span> <span class="pre">más</span> <span class="pre">cercanos</span></code> utilizando <code class="docutils literal notranslate"><span class="pre">scikit-learn</span></code>. En primer lugar, dividimos nuestros datos en un conjunto de <code class="docutils literal notranslate"><span class="pre">entrenamiento</span></code> y otro de <code class="docutils literal notranslate"><span class="pre">prueba</span></code> para poder evaluar el rendimiento de la <code class="docutils literal notranslate"><span class="pre">generalización</span></code>. <code class="docutils literal notranslate"><span class="pre">random_state=0</span></code> nos asegura que obtendremos los mismos conjuntos de training y test para diferentes ejecuciones. Para mas información sobre <code class="docutils literal notranslate"><span class="pre">sklearn.model_selection.train_test_split</span></code> (ver documentación <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html">train_test_split</a>). Por defecto, cuando no es suministrado el porcentaje de entrenamiento <code class="docutils literal notranslate"><span class="pre">train_test_split</span></code> considera este porcentaje para el test como el 25%, esto es <code class="docutils literal notranslate"><span class="pre">test_size=0.25</span></code></p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">mglearn</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">make_forge</span><span class="p">()</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>A continuación, importamos e instanciamos la clase <code class="docutils literal notranslate"><span class="pre">KNeighborsClassifier</span></code> de <code class="docutils literal notranslate"><span class="pre">sklearn</span></code> encargada de la tarea de clasificación. Aquí es cuando podemos establecer parámetros, como el número de vecinos a utilizar, el cual consideramos como 3 para este ejemplo <code class="docutils literal notranslate"><span class="pre">n_neighbors=3</span></code></p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.neighbors</span> <span class="kn">import</span> <span class="n">KNeighborsClassifier</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">clf</span> <span class="o">=</span> <span class="n">KNeighborsClassifier</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Ahora, ajustamos el clasificador utilizando el conjunto de entrenamiento. Para la clase <code class="docutils literal notranslate"><span class="pre">KNeighborsClassifier</span></code> esto significa almacenar el conjunto de datos, para poder calcular los vecinos durante la predicción, teniendo en cuenta la asignación de la clase más frequente, explicada anteriormente</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>KNeighborsClassifier(n_neighbors=3)
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Para hacer predicciones sobre los datos de prueba, llamamos al método de predicción <code class="docutils literal notranslate"><span class="pre">predict()</span></code>. Para cada punto de datos en el conjunto de prueba, éste calcula sus vecinos más cercanos en el conjunto de entrenamiento y encuentra la clase más común entre ellos. Para mas informaación sobre el cálculo del <code class="docutils literal notranslate"><span class="pre">score</span></code> (ver documentación <a class="reference external" href="https://scikit-learn.org/stable/modules/model_evaluation.html#accuracy-score">Accuracy score</a>)</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Test set predictions: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Test set predictions: [1 0 1 0 1 0 0]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X_test</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([[11.54155807,  5.21116083],
       [10.06393839,  0.99078055],
       [ 9.49123469,  4.33224792],
       [ 8.18378052,  1.29564214],
       [ 8.30988863,  4.80623966],
       [10.24028948,  2.45544401],
       [ 8.34468785,  1.63824349]])
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Test set predictions: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Test set predictions: [1 0 1 0 1 0 0]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Test set: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">y_test</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Test set: [1 0 1 0 1 1 0]
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Para evaluar lo bien que <code class="docutils literal notranslate"><span class="pre">generaliza</span></code> nuestro modelo, podemos llamar al método <code class="docutils literal notranslate"><span class="pre">score()</span></code> con los datos de prueba junto con las etiquetas de prueba <code class="docutils literal notranslate"><span class="pre">X_text,</span> <span class="pre">y_test</span></code>.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Test set accuracy: </span><span class="si">{:.2f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">clf</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Test set accuracy: 0.86
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Vemos que nuestro modelo tiene una precisión del 86%, lo que significa que el modelo predijo la clase correctamente para el 86% de las muestras del conjunto de datos de prueba.</p></li>
</ul>
</section>
<section id="analisis-de-kneighborsclassifier">
<h3>Análisis de <code class="docutils literal notranslate"><span class="pre">KNeighborsClassifier</span></code><a class="headerlink" href="#analisis-de-kneighborsclassifier" title="Permalink to this headline">#</a></h3>
<ul class="simple">
<li><p>Para los conjuntos de datos bidimensionales, también podemos ilustrar la predicción para todos los posibles puntos de prueba en el plano <span class="math notranslate nohighlight">\(xy\)</span>. Coloreamos el plano según la clase que se asignaría a un punto en esta región. Esto nos permite ver el <code class="docutils literal notranslate"><span class="pre">límite</span> <span class="pre">de</span> <span class="pre">decisión</span> <span class="pre">(decision</span> <span class="pre">boundary)</span></code>, la cual está entre el lugar donde el algoritmo asigna la clase 0 y el lugar donde asigna la clase 1.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>

<span class="k">for</span> <span class="n">n_neighbors</span><span class="p">,</span> <span class="n">ax</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">9</span><span class="p">],</span> <span class="n">axes</span><span class="p">):</span>
    <span class="n">clf</span> <span class="o">=</span> <span class="n">KNeighborsClassifier</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="n">n_neighbors</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
    <span class="n">mglearn</span><span class="o">.</span><span class="n">plots</span><span class="o">.</span><span class="n">plot_2d_separator</span><span class="p">(</span><span class="n">clf</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">fill</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">.4</span><span class="p">)</span>
    <span class="n">mglearn</span><span class="o">.</span><span class="n">discrete_scatter</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">y</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">{}</span><span class="s2"> neighbor(s)&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">n_neighbors</span><span class="p">))</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;feature 0&quot;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;feature 1&quot;</span><span class="p">)</span>
    <span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/supervised_learning_64_0.png" src="_images/supervised_learning_64_0.png" />
</div>
</div>
<ul class="simple">
<li><p>Como se puede ver en la figura de la izquierda, el uso de un solo vecino da como resultado una decisión que sigue de cerca los datos de entrenamiento. La consideración de más vecinos conduce a un límite de decisión más suave. Un límite más suave corresponde a un modelo más sencillo. En otras palabras, <code class="docutils literal notranslate"><span class="pre">el</span> <span class="pre">uso</span> <span class="pre">de</span> <span class="pre">pocos</span> <span class="pre">vecinos</span> <span class="pre">corresponde</span> <span class="pre">a</span> <span class="pre">una</span> <span class="pre">alta</span> <span class="pre">complejidad</span> <span class="pre">del</span> <span class="pre">modelo</span></code> (como se muestra en el lado derecho), y <code class="docutils literal notranslate"><span class="pre">el</span> <span class="pre">uso</span> <span class="pre">de</span> <span class="pre">muchos</span> <span class="pre">vecinos</span> <span class="pre">corresponde</span> <span class="pre">a</span> <span class="pre">una</span> <span class="pre">baja</span> <span class="pre">complejidad</span> <span class="pre">del</span> <span class="pre">modelo</span></code>. Si se considera el caso extremo en el que el número de vecinos es el número de todos los puntos de datos del conjunto de entrenamiento, cada punto de prueba tendría exactamente los mismos vecinos (todos puntos de entrenamiento) y todas las predicciones serían las mismas: la clase más frecuente en el conjunto de entrenamiento.</p></li>
<li><p>Investiguemos si podemos confirmar la conexión entre la complejidad del modelo y la generalización que hemos discutido antes. Lo haremos con el conjunto de datos de cáncer de mama <code class="docutils literal notranslate"><span class="pre">(Breast</span> <span class="pre">Cancer)</span></code> del mundo real. Comenzamos dividiendo el conjunto de datos en un conjunto de entrenamiento y otro de prueba. A continuación, evaluamos el rendimiento del conjunto de entrenamiento y de prueba con diferentes números de vecinos</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_breast_cancer</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">cancer</span> <span class="o">=</span> <span class="n">load_breast_cancer</span><span class="p">()</span>

<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">cancer</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">cancer</span><span class="o">.</span><span class="n">target</span><span class="p">,</span> <span class="n">stratify</span><span class="o">=</span><span class="n">cancer</span><span class="o">.</span><span class="n">target</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">66</span><span class="p">)</span>

<span class="n">training_accuracy</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">test_accuracy</span> <span class="o">=</span> <span class="p">[]</span>

<span class="n">neighbors_settings</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">11</span><span class="p">)</span>
<span class="k">for</span> <span class="n">n_neighbors</span> <span class="ow">in</span> <span class="n">neighbors_settings</span><span class="p">:</span>
    <span class="n">clf</span> <span class="o">=</span> <span class="n">KNeighborsClassifier</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="n">n_neighbors</span><span class="p">)</span>
    <span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
    <span class="n">training_accuracy</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">clf</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">))</span>
    <span class="n">test_accuracy</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">clf</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">))</span>

<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">neighbors_settings</span><span class="p">,</span> <span class="n">training_accuracy</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;training accuracy&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">neighbors_settings</span><span class="p">,</span> <span class="n">test_accuracy</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;test accuracy&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Accuracy&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;n_neighbors&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">();</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/supervised_learning_67_0.png" src="_images/supervised_learning_67_0.png" />
</div>
</div>
<ul class="simple">
<li><p>El gráfico muestra la precisión de los conjuntos de entrenamiento y de prueba en el eje <span class="math notranslate nohighlight">\(y\)</span> contra el ajuste de <code class="docutils literal notranslate"><span class="pre">n_vecinos</span></code> en el eje <span class="math notranslate nohighlight">\(x\)</span>. Aunque los gráficos del mundo real no suelen ser muy suaves, podemos reconocer algunas de las características del sobreajuste <code class="docutils literal notranslate"><span class="pre">(overfitting)</span></code> y del subajuste <code class="docutils literal notranslate"><span class="pre">(underfitting)</span></code>. Si se considera un solo vecino más cercano, la predicción en el conjunto de entrenamiento es perfecta. Pero cuando se consideran más vecinos, el modelo se simplifica y la precisión del entrenamiento disminuye.</p></li>
<li><p>La precisión del conjunto de prueba cuando se utiliza un solo vecino es menor que cuando se utilizan más vecinos, lo que indica que <code class="docutils literal notranslate"><span class="pre">el</span> <span class="pre">uso</span> <span class="pre">de</span> <span class="pre">un</span> <span class="pre">solo</span> <span class="pre">vecino</span> <span class="pre">más</span> <span class="pre">cercano</span> <span class="pre">conduce</span> <span class="pre">a</span> <span class="pre">una</span> <span class="pre">mayor</span> <span class="pre">precisión</span> <span class="pre">en</span> <span class="pre">el</span> <span class="pre">conjunto</span> <span class="pre">de</span> <span class="pre">entrenamiento</span></code>. Pero cuando se consideran más vecinos, el modelo se simplifica y la precisión del entrenamiento disminuye. La precisión del conjunto de prueba, cuando se utiliza un único vecino es menor que cuando se utilizan más vecinos, lo que indica que <code class="docutils literal notranslate"><span class="pre">el</span> <span class="pre">uso</span> <span class="pre">del</span> <span class="pre">único</span> <span class="pre">vecino</span> <span class="pre">más</span> <span class="pre">cercano</span> <span class="pre">conduce</span> <span class="pre">a</span> <span class="pre">un</span> <span class="pre">modelo</span> <span class="pre">demasiado</span> <span class="pre">complejo</span></code>.</p></li>
<li><p>Por otro lado, cuando se consideran 10 vecinos, el modelo es demasiado simple y el rendimiento es aún peor. <code class="docutils literal notranslate"><span class="pre">El</span> <span class="pre">mejor</span> <span class="pre">rendimiento</span> <span class="pre">se</span> <span class="pre">encuentra</span> <span class="pre">en</span> <span class="pre">un</span> <span class="pre">punto</span> <span class="pre">intermedio,</span> <span class="pre">utilizando</span> <span class="pre">alrededor</span> <span class="pre">de</span> <span class="pre">seis</span> <span class="pre">vecinos</span></code>. Aun así, es bueno tener en cuenta la escala de la figura. El peor rendimiento está en torno al 88% de precisión, lo que podría ser aceptable.</p></li>
</ul>
</section>
<section id="regresion-por-k-vecinos">
<h3>Regresión por <span class="math notranslate nohighlight">\(k\)</span>-vecinos<a class="headerlink" href="#regresion-por-k-vecinos" title="Permalink to this headline">#</a></h3>
<ul class="simple">
<li><p>También existe una variante de regresión del algoritmo de <span class="math notranslate nohighlight">\(k\)</span>-vecinos más cercanos. Una vez más, vamos a empezar utilizando el vecino más cercano simple, esta vez utilizando el conjunto de datos <code class="docutils literal notranslate"><span class="pre">wave</span></code>. Hemos añadido tres puntos de datos de prueba como estrellas verdes en el eje <span class="math notranslate nohighlight">\(x\)</span>. La predicción utilizando un solo vecino es sólo el valor objetivo del vecino más cercano</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">mglearn</span><span class="o">.</span><span class="n">plots</span><span class="o">.</span><span class="n">plot_knn_regression</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/supervised_learning_71_0.png" src="_images/supervised_learning_71_0.png" />
</div>
</div>
<ul class="simple">
<li><p>De nuevo, podemos utilizar más que el único vecino más cercano para la regresión. Cuando se utilizan varios vecinos más cercanos, la predicción es el promedio, o la media, de los vecinos</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">mglearn</span><span class="o">.</span><span class="n">plots</span><span class="o">.</span><span class="n">plot_knn_regression</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/supervised_learning_73_0.png" src="_images/supervised_learning_73_0.png" />
</div>
</div>
<ul class="simple">
<li><p>El algoritmo de <span class="math notranslate nohighlight">\(k\)</span>-vecinos más cercanos para la regresión se implementa en la clase <code class="docutils literal notranslate"><span class="pre">KNeighbors</span> <span class="pre">Regressor</span></code> en <code class="docutils literal notranslate"><span class="pre">scikit-learn</span></code>. Se utiliza de forma similar a <code class="docutils literal notranslate"><span class="pre">KNeighborsClassifier</span></code></p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.neighbors</span> <span class="kn">import</span> <span class="n">KNeighborsRegressor</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">mglearn</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">make_wave</span><span class="p">(</span><span class="n">n_samples</span><span class="o">=</span><span class="mi">40</span><span class="p">)</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">reg</span> <span class="o">=</span> <span class="n">KNeighborsRegressor</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="n">reg</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>KNeighborsRegressor(n_neighbors=3)
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Ahora podemos hacer predicciones sobre el conjunto de prueba</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Test set predictions:</span><span class="se">\n</span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">reg</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Test set predictions:
[-0.05396539  0.35686046  1.13671923 -1.89415682 -1.13881398 -1.63113382
  0.35686046  0.91241374 -0.44680446 -1.13881398]
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>También podemos evaluar el modelo utilizando el método <code class="docutils literal notranslate"><span class="pre">score</span></code>, que para los regresores devuelve la puntuación <span class="math notranslate nohighlight">\(\mathbb{R}^2\)</span>. La puntuación <span class="math notranslate nohighlight">\(\mathbb{R}^2\)</span>, también conocida como coeficiente de determinación, es una medida de predicción de un modelo de regresión, y arroja una puntuación entre 0 y 1. Un valor de 1 corresponde a una predicción perfecta, y un valor de 0 corresponde a un modelo constante que sólo predice la media de las respuestas del conjunto de entrenamiento, <code class="docutils literal notranslate"><span class="pre">y_train</span></code>. Aquí, el <code class="docutils literal notranslate"><span class="pre">score</span></code> es de 0.83, lo que indica un ajuste del modelo relativamente bueno.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Test set R^2: </span><span class="si">{:.2f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">reg</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Test set R^2: 0.83
</pre></div>
</div>
</div>
</div>
</section>
<section id="analisis-de-kneighborsregressor">
<h3>Análisis de <code class="docutils literal notranslate"><span class="pre">KNeighborsRegressor</span></code><a class="headerlink" href="#analisis-de-kneighborsregressor" title="Permalink to this headline">#</a></h3>
<ul class="simple">
<li><p>Para nuestro conjunto de datos unidimensional, podemos ver cómo son las predicciones para todos los valores posibles de las características. Para ello, creamos un conjunto de datos de prueba compuesto por muchos puntos de la línea</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>

<span class="n">line</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1000</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="k">for</span> <span class="n">n_neighbors</span><span class="p">,</span> <span class="n">ax</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">9</span><span class="p">],</span> <span class="n">axes</span><span class="p">):</span>
    <span class="n">reg</span> <span class="o">=</span> <span class="n">KNeighborsRegressor</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="n">n_neighbors</span><span class="p">)</span>
    <span class="n">reg</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">line</span><span class="p">,</span> <span class="n">reg</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">line</span><span class="p">))</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="s1">&#39;^&#39;</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="n">mglearn</span><span class="o">.</span><span class="n">cm2</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="n">markersize</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">,</span> <span class="s1">&#39;v&#39;</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="n">mglearn</span><span class="o">.</span><span class="n">cm2</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span> <span class="n">markersize</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">{}</span><span class="s2"> neighbor(s)</span><span class="se">\n</span><span class="s2"> train score: </span><span class="si">{:.2f}</span><span class="s2"> test score: </span><span class="si">{:.2f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">n_neighbors</span><span class="p">,</span> 
                                                                                  <span class="n">reg</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">),</span>
                                                                                  <span class="n">reg</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)))</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;Feature&quot;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;Target&quot;</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">legend</span><span class="p">([</span><span class="s2">&quot;Model predictions&quot;</span><span class="p">,</span> <span class="s2">&quot;Training data/target&quot;</span><span class="p">,</span> <span class="s2">&quot;Test data/target&quot;</span><span class="p">],</span> <span class="n">loc</span><span class="o">=</span><span class="s2">&quot;best&quot;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/supervised_learning_83_0.png" src="_images/supervised_learning_83_0.png" />
</div>
</div>
<ul class="simple">
<li><p>Como podemos ver en el gráfico, al utilizar un solo vecino, cada punto del conjunto de entrenamiento tiene una influencia obvia en las predicciones, y los valores predichos pasan por todos los puntos de datos. Esto conduce a una predicción muy inestable. Tener en cuenta más vecinos conduce a predicciones más suaves, pero éstas no se ajustan tan bien a los datos de entrenamiento.</p></li>
</ul>
</section>
<section id="puntos-fuertes-puntos-debiles-y-parametros">
<h3>Puntos fuertes, puntos débiles y parámetros<a class="headerlink" href="#puntos-fuertes-puntos-debiles-y-parametros" title="Permalink to this headline">#</a></h3>
<ul class="simple">
<li><p>En principio, hay dos parámetros importantes en el clasificador <code class="docutils literal notranslate"><span class="pre">KNeighbors</span></code>: el número de vecinos y cómo se mide la distancia entre los puntos de datos. En la práctica, utilizar un número pequeño de vecinos, como tres o cinco, suele funcionar bien, pero se debería ajustar este parámetro.</p></li>
<li><p>La elección de la medida de distancia correcta es también crucial. Por defecto, <code class="docutils literal notranslate"><span class="pre">KNeighbors</span></code> utiliza la distancia euclidiana, que funciona bien en muchos casos. Uno de los puntos fuertes de <span class="math notranslate nohighlight">\(k\)</span>-NN es que el modelo es muy fácil de entender, y a menudo da un rendimiento razonable sin necesidad de muchos ajustes. El uso de este algoritmo es un buen método de referencia para probar, antes de considerar técnicas más avanzadas.</p></li>
<li><p>La construcción del modelo de vecinos más cercanos suele ser muy rápida, pero <code class="docutils literal notranslate"><span class="pre">cuando</span> <span class="pre">el</span> <span class="pre">conjunto</span> <span class="pre">de</span> <span class="pre">entrenamiento</span> <span class="pre">es</span> <span class="pre">muy</span> <span class="pre">grande</span> <span class="pre">(ya</span> <span class="pre">sea</span> <span class="pre">en</span> <span class="pre">número</span> <span class="pre">de</span> <span class="pre">características</span> <span class="pre">o</span> <span class="pre">en</span> <span class="pre">número</span> <span class="pre">de</span> <span class="pre">muestras)</span> <span class="pre">la</span> <span class="pre">predicción</span> <span class="pre">puede</span> <span class="pre">ser</span> <span class="pre">lenta</span></code>. Cuando se utiliza el algoritmo <span class="math notranslate nohighlight">\(k\)</span>-NN, es importante preprocesar los datos, tema que revisaremos en secciones posteriores. Este enfoque no suele funcionar bien en conjuntos de datos con muchas características (<code class="docutils literal notranslate"><span class="pre">cientos</span> <span class="pre">o</span> <span class="pre">más</span></code>), y lo hace especialmente mal con conjuntos de datos en los que la mayoría de las características son 0 la mayor parte del tiempo (<code class="docutils literal notranslate"><span class="pre">los</span> <span class="pre">llamados</span> <span class="pre">conjuntos</span> <span class="pre">de</span> <span class="pre">datos</span> <span class="pre">dispersos</span></code>).</p></li>
<li><p>Por lo tanto, aunque el algoritmo de <span class="math notranslate nohighlight">\(k\)</span><code class="docutils literal notranslate"><span class="pre">-vecinos</span> <span class="pre">más</span> <span class="pre">cercanos</span></code> es fácil de entender, no se utiliza a menudo en la práctica, debido a que la predicción es lenta y a su incapacidad para manejar muchas características. El método que comentamos a continuación no tiene ninguno de estos inconvenientes.</p></li>
</ul>
</section>
</section>
<section id="modelos-lineales">
<h2>Modelos lineales<a class="headerlink" href="#modelos-lineales" title="Permalink to this headline">#</a></h2>
<ul class="simple">
<li><p>Los <code class="docutils literal notranslate"><span class="pre">modelos</span> <span class="pre">lineales</span></code> son una clase de modelos que se utilizan ampliamente en la práctica y se han estudiado mucho en las últimas décadas, con raíces que se remontan a más de cien años. Los <code class="docutils literal notranslate"><span class="pre">modelos</span> <span class="pre">lineales</span></code> hacen una predicción utilizando una función lineal de las características de entrada, que explicaremos en breve.</p></li>
</ul>
<section id="modelos-de-regresion-lineal">
<h3>Modelos de regresión lineal<a class="headerlink" href="#modelos-de-regresion-lineal" title="Permalink to this headline">#</a></h3>
<p><strong><code class="docutils literal notranslate"><span class="pre">Formulación</span></code></strong></p>
<p>El modelo</p>
<div class="math notranslate nohighlight" id="equation-linear-reg">
<span class="eqno">(1)<a class="headerlink" href="#equation-linear-reg" title="Permalink to this equation">#</a></span>\[
\boldsymbol{y}=\boldsymbol{X}\boldsymbol{\beta}+\boldsymbol{\varepsilon},
\]</div>
<p>se denomina, <code class="docutils literal notranslate"><span class="pre">modelo</span> <span class="pre">de</span> <span class="pre">regresión</span> <span class="pre">lineal</span></code> clásico, si se cumplen los siguientes supuestos:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(E(\boldsymbol{\varepsilon})=\boldsymbol{0}\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(Cov(\boldsymbol{\varepsilon})=E(\boldsymbol{\varepsilon}\boldsymbol{\varepsilon}^{T})=\sigma^{2}\boldsymbol{I}\)</span></p></li>
<li><p>La matriz de diseño <span class="math notranslate nohighlight">\(\boldsymbol{X}\)</span> tiene rango completo, es decir <span class="math notranslate nohighlight">\(\textrm{rk}(\boldsymbol{X})=p+1\)</span></p></li>
<li><p>El <code class="docutils literal notranslate"><span class="pre">modelo</span> <span class="pre">de</span> <span class="pre">regresión</span> <span class="pre">normal</span></code> clasico es obtenido si adicionalmente  se tiene que <span class="math notranslate nohighlight">\(\boldsymbol{\varepsilon}\sim N(\boldsymbol{0}, \sigma^{2}\boldsymbol{I})\)</span>.</p></li>
<li><p>El <code class="docutils literal notranslate"><span class="pre">modelo</span> <span class="pre">de</span> <span class="pre">regresión</span> <span class="pre">lineal</span></code> <a class="reference internal" href="#equation-linear-reg">(1)</a> puede escribirse en la siguiente forma</p></li>
</ul>
<div class="math notranslate nohighlight" id="equation-linear-reg-mat">
<span class="eqno">(2)<a class="headerlink" href="#equation-linear-reg-mat" title="Permalink to this equation">#</a></span>\[\begin{split}
\begin{pmatrix}
y_{1}\\
y_{2}\\
\vdots\\
y_{i}\\
\vdots\\
y_{n}
\end{pmatrix}
=
\begin{pmatrix}
1 &amp; x_{11} &amp; x_{12} &amp; \cdots &amp; x_{1p}\\
1 &amp; x_{21} &amp; x_{22} &amp; \cdots &amp; x_{2p}\\
\vdots &amp; \vdots &amp; \vdots &amp; \ddots &amp; \vdots\\
1 &amp; x_{i1} &amp; x_{i2} &amp; \cdots &amp; x_{ip}\\
\vdots &amp; \vdots &amp; \vdots &amp; \ddots &amp; \vdots\\
1 &amp; x_{n1} &amp; x_{n2} &amp; \cdots &amp; x_{np}
\end{pmatrix}
\begin{pmatrix}
\beta_{0}\\[2mm]
\beta_{1}\\[2mm]
\beta_{2}\\
\vdots\\[2mm]
\beta_{p}
\end{pmatrix}
+
\begin{pmatrix}
\varepsilon_{1}\\
\varepsilon_{2}\\
\vdots\\
\varepsilon_{i}\\
\vdots\\
\varepsilon_{n}
\end{pmatrix}
\end{split}\]</div>
<ul class="simple">
<li><p>En el curso de <code class="docutils literal notranslate"><span class="pre">modelos</span> <span class="pre">lineales</span></code> se estudian estimaciones del vector de coeficientes de regresión <span class="math notranslate nohighlight">\(\boldsymbol{\beta}\)</span> utilizando método de <code class="docutils literal notranslate"><span class="pre">mínimos</span> <span class="pre">cuadrados</span></code> y <code class="docutils literal notranslate"><span class="pre">máxima</span> <span class="pre">verosimilitud</span></code>.</p></li>
</ul>
<ul class="simple">
<li><p>A partir del sistema <a class="reference internal" href="#equation-linear-reg-mat">(2)</a>, se puede observar que la <span class="math notranslate nohighlight">\(i\)</span>-esima predicción para un modelo lineal es la siguiente:</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
\hat{y}_{i}=\hat{\beta}_{0}+\hat{\beta}_{1}\cdot x_{i1}+\hat{\beta}_{2}\cdot x_{i2}+\cdots+\hat{\beta}_{p}\cdot x_{ip}=\boldsymbol{\hat{\beta}}^{T}\boldsymbol{x}_{i},~i = 1,2,\dots, n.
\]</div>
<ul class="simple">
<li><p>Aquí, <span class="math notranslate nohighlight">\(x_{i1},\dots, x_{ip}\)</span> denotan las <code class="docutils literal notranslate"><span class="pre">variables</span> <span class="pre">predictoras</span></code> o características (en este ejemplo, el número de características es <span class="math notranslate nohighlight">\(p\)</span>). Los valores, <span class="math notranslate nohighlight">\(\hat{\beta}_{i},~i=0,1,\dots,p\)</span>, son lo parámetros aprendidos por el modelo y <span class="math notranslate nohighlight">\(\hat{y}_{i}\)</span> es la predicción obtenida por el modelo. Para un conjunto de datos con una sola característica</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
\hat{y}_{i} = \hat{\beta}_{0}+\hat{\beta}_{1}\cdot x_{i1},~i=1,2,\dots,n.
\]</div>
<ul class="simple">
<li><p>Aquí, <span class="math notranslate nohighlight">\(\hat{\beta}_{1}\)</span> es la pendiente y <span class="math notranslate nohighlight">\(\hat{\beta}_{0}\)</span> es el desplazamiento en el eje <span class="math notranslate nohighlight">\(y\)</span>. Para más características, <span class="math notranslate nohighlight">\(\boldsymbol{\hat{\beta}}\)</span> contiene las pendientes a lo largo de cada eje de características. Alternativamente, se puede pensar en la respuesta predicha como una suma ponderada de las características de entrada, con pesos (que pueden ser negativos) dados por las entradas de <span class="math notranslate nohighlight">\(\boldsymbol{\hat{\beta}}\)</span>.</p></li>
</ul>
<p><strong><code class="docutils literal notranslate"><span class="pre">Aplicación</span></code></strong></p>
<ul class="simple">
<li><p>Considere el ejemplo de intentar aprender los parámetros <span class="math notranslate nohighlight">\(\hat{\beta}_{1}:=w[0]\)</span> y <span class="math notranslate nohighlight">\(\hat{\beta}_{0}:=b\)</span> en nuestro conjunto de datos de ondas unidimensionales (<code class="docutils literal notranslate"><span class="pre">wave</span></code>) usando <code class="docutils literal notranslate"><span class="pre">plot_linear_regression_wave()</span></code></p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">mglearn</span><span class="o">.</span><span class="n">plots</span><span class="o">.</span><span class="n">plot_linear_regression_wave</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>w[0]: 0.393906  b: -0.031804
</pre></div>
</div>
<img alt="_images/supervised_learning_98_1.png" src="_images/supervised_learning_98_1.png" />
</div>
</div>
<ul class="simple">
<li><p>Hemos añadido una cruz de coordenadas en el gráfico para facilitar la comprensión de la línea. Si observamos <span class="math notranslate nohighlight">\(\hat{\beta}_{1}\)</span>, vemos que la pendiente debería estar en torno a 0.4, lo que podemos confirmar visualmente en el gráfico. La intercepción es el punto en el que la línea de predicción debería cruzar el eje <span class="math notranslate nohighlight">\(y\)</span>: está ligeramente por debajo de cero, lo que también se puede confirmar en la imagen.</p></li>
<li><p>Los <code class="docutils literal notranslate"><span class="pre">modelos</span> <span class="pre">de</span> <span class="pre">regresión</span> <span class="pre">lineal</span></code> pueden caracterizarse como modelos de regresión en los que la predicción es una línea para una sola característica, un plano cuando se utilizan dos características, o un hiperplano en dimensiones más altas (es decir, cuando se utilizan más características).</p></li>
<li><p>Si se comparan las predicciones realizadas por la línea recta con las realizadas por el modelo <code class="docutils literal notranslate"><span class="pre">KNeighborsRegressor</span></code>, usar una línea recta para hacer predicciones parece muy restrictivo. Parece que se pierden todos los detalles finos de los datos. En cierto sentido, esto es cierto. Es una suposición fuerte (y algo irreal) que nuestro objetivo <span class="math notranslate nohighlight">\(y\)</span> es una combinación lineal de las características. Pero mirar los datos unidimensionales da una perspectiva algo sesgada.</p></li>
<li><p>Para los conjuntos de datos con muchas características, los <code class="docutils literal notranslate"><span class="pre">modelos</span> <span class="pre">lineales</span></code> pueden ser muy potentes. En particular, si tiene más características que puntos de datos de entrenamiento, cualquier objetivo <span class="math notranslate nohighlight">\(y\)</span> puede modelarse perfectamente (en el conjunto de entrenamiento) como una <code class="docutils literal notranslate"><span class="pre">función</span> <span class="pre">lineal</span></code>. Hay muchos modelos lineales diferentes para la regresión. La diferencia entre estos La diferencia entre estos modelos radica en cómo se aprenden los parámetros del modelo <span class="math notranslate nohighlight">\(\boldsymbol{\beta}_{1}\)</span> y <span class="math notranslate nohighlight">\(\boldsymbol{\beta}_{0}\)</span> a partir de los datos de entrenamiento, y en cómo se puede controlar la complejidad del modelo. A continuación veremos los modelos lineales más populares.</p></li>
</ul>
</section>
<section id="regresion-lineal-minimos-cuadrados-ordinarios-ols">
<h3>Regresión lineal (Mínimos Cuadrados Ordinarios) OLS<a class="headerlink" href="#regresion-lineal-minimos-cuadrados-ordinarios-ols" title="Permalink to this headline">#</a></h3>
<ul class="simple">
<li><p>La regresión lineal, o mínimos cuadrados ordinarios <code class="docutils literal notranslate"> <span class="pre">ordinary</span> <span class="pre">least</span> <span class="pre">squares</span> <span class="pre">(OLS)</span></code>, es el método lineal más sencillo y clásico para la regresión. La regresión lineal encuentra el vector de parámetros <span class="math notranslate nohighlight">\(\boldsymbol{\hat{\beta}}\)</span> que minimiza el error cuadrático medio entre las predicciones y los verdaderos objetivos de la regresión, <span class="math notranslate nohighlight">\(y\)</span>, en el conjunto de entrenamiento. El error medio al cuadrado es la suma de las diferencias al cuadrado entre las predicciones y los valores reales. La regresión lineal no tiene parámetros, lo cual es una ventaja, pero tampoco tiene forma de controlar la complejidad del modelo.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LinearRegression</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">mglearn</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">make_wave</span><span class="p">(</span><span class="n">n_samples</span><span class="o">=</span><span class="mi">60</span><span class="p">)</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="n">lr</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">()</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>El número <code class="docutils literal notranslate"><span class="pre">42</span></code> es normalmente elegido en la literatura relacionadas con <code class="docutils literal notranslate"><span class="pre">AI</span></code>, como homenaje al libro de la <code class="docutils literal notranslate"><span class="pre">Douglas</span> <span class="pre">Adams</span></code> “<a class="reference external" href="https://en.wikipedia.org/wiki/Phrases_from_The_Hitchhiker%27s_Guide_to_the_Galaxy#The_number_42">The Hitchhiker’s Guide to the Galaxy</a>”, una serie de cómic de ciencia ficción creada por <code class="docutils literal notranslate"><span class="pre">Douglas</span> <span class="pre">Adams</span></code> que se ha hecho popular entre los aficionados al género y los <code class="docutils literal notranslate"><span class="pre">miembros</span> <span class="pre">de</span> <span class="pre">la</span> <span class="pre">comunidad</span> <span class="pre">científica</span></code>. Supuestamente era la respuesta a la gran pregunta <code class="docutils literal notranslate"><span class="pre">&quot;Life,</span> <span class="pre">the</span> <span class="pre">universe,</span> <span class="pre">and</span> <span class="pre">everything&quot;</span></code>, calculada por un ordenador (llamado <code class="docutils literal notranslate"><span class="pre">&quot;Deep</span> <span class="pre">Thought&quot;</span></code>) creado específicamente para resolverla <code class="docutils literal notranslate"><span class="pre">:)</span></code>. Sin embargo, <code class="docutils literal notranslate"><span class="pre">random_state</span></code> puede ser cualquier número entero, mas aún, podemos realizar un <code class="docutils literal notranslate"><span class="pre">grid</span> <span class="pre">search</span></code> para conseguir aquel parámetro <code class="docutils literal notranslate"><span class="pre">random_state</span></code> que no entrega el mejor score. Mas adelante abordaremos el uso de <code class="docutils literal notranslate"><span class="pre">GirdSearch</span></code>. Si no establece <code class="docutils literal notranslate"><span class="pre">random_state</span></code> en <code class="docutils literal notranslate"><span class="pre">42</span></code> o cualquier otro entero positivo, cada vez que ejecute su código de nuevo, generará un conjunto de pruebas diferente.</p></li>
</ul>
<ul class="simple">
<li><p>Los parámetros de “pendiente” (<span class="math notranslate nohighlight">\(\hat{\beta}_{i},~i=1,2,\dots,p\)</span>), también llamados pesos o coeficientes, se almacenan en el atributo <code class="docutils literal notranslate"><span class="pre">coef_</span></code>, mientras que el desplazamiento o intercepción (<span class="math notranslate nohighlight">\(\hat{\beta}_{0}\)</span>) se almacena en el atributo <code class="docutils literal notranslate"><span class="pre">intercept_</span></code>:</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;lr.coef_: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">lr</span><span class="o">.</span><span class="n">coef_</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;lr.intercept_: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">lr</span><span class="o">.</span><span class="n">intercept_</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>lr.coef_: [0.39390555]
lr.intercept_: -0.031804343026759746
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p><em><code class="docutils literal notranslate"><span class="pre">El</span> <span class="pre">extraño</span> <span class="pre">guión</span> <span class="pre">bajo</span> <span class="pre">al</span> <span class="pre">final</span> <span class="pre">de</span> <span class="pre">de</span> <span class="pre">coef_</span> <span class="pre">e</span> <span class="pre">intercept_</span> <span class="pre">es</span> <span class="pre">usado</span> <span class="pre">a</span> <span class="pre">menudo</span> <span class="pre">por</span> <span class="pre">scikit-learn</span> <span class="pre">para</span> <span class="pre">almacenar</span> <span class="pre">cualquier</span> <span class="pre">objeto</span> <span class="pre">que</span> <span class="pre">se</span> <span class="pre">derive</span> <span class="pre">de</span> <span class="pre">los</span> <span class="pre">datos</span> <span class="pre">de</span> <span class="pre">entrenamiento,</span> <span class="pre">usando</span> <span class="pre">atributos</span> <span class="pre">que</span> <span class="pre">terminan</span> <span class="pre">con</span> <span class="pre">un</span> <span class="pre">guión</span> <span class="pre">bajo</span> <span class="pre">al</span> <span class="pre">final.</span> <span class="pre">Esto</span> <span class="pre">es</span> <span class="pre">para</span> <span class="pre">separarlos</span> <span class="pre">de</span> <span class="pre">los</span> <span class="pre">parámetros</span> <span class="pre">que</span> <span class="pre">son</span> <span class="pre">establecidos</span> <span class="pre">por</span> <span class="pre">el</span> <span class="pre">usuario.</span></code></em></p></li>
</ul>
<ul class="simple">
<li><p>El atributo <code class="docutils literal notranslate"><span class="pre">intercept_</span></code> es siempre un único número flotante, mientras que el atributo <code class="docutils literal notranslate"><span class="pre">coef_</span></code> es una matriz <code class="docutils literal notranslate"><span class="pre">NumPy</span></code> con una entrada por característica. Como sólo tenemos una característica de entrada en el conjunto de datos <code class="docutils literal notranslate"><span class="pre">wave</span></code>, <code class="docutils literal notranslate"><span class="pre">lr.coef_</span></code> sólo tiene una entrada. Veamos el rendimiento del conjunto de entrenamiento y del conjunto de prueba</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Training set score: </span><span class="si">{:.2f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">lr</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Test set score: </span><span class="si">{:.2f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">lr</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Training set score: 0.67
Test set score: 0.66
</pre></div>
</div>
</div>
</div>
<div class="tip dropdown admonition">
<p class="admonition-title">¿Cual sería un buen score?</p>
<p>Definir un buen <code class="docutils literal notranslate"><span class="pre">score</span></code> en <code class="docutils literal notranslate"><span class="pre">machine</span> <span class="pre">learning</span></code> es un tema subjetivo, y bastante ligado a los datos. Pero, de forma coherente con los estándares de la industria, cualquier score superior al 70% es un gran rendimiento del modelo. De hecho, una medida de precisión de entre el 70% y el 90% no sólo es ideal, sino que es realista.</p>
</div>
<ul class="simple">
<li><p>Un <span class="math notranslate nohighlight">\(\mathbb{R}^2\)</span> en torno a 0.66 no es muy bueno, pero podemos ver que los <code class="docutils literal notranslate"><span class="pre">score</span></code> en los conjuntos de entrenamiento y de prueba están muy cerca. Esto significa que probablemente estemos <code class="docutils literal notranslate"><span class="pre">subajustando</span> <span class="pre">(underfitting)</span></code>, no <code class="docutils literal notranslate"><span class="pre">sobreajustando</span> <span class="pre">(overfitting)</span></code>. Para este conjunto de datos unidimensional, hay poco peligro de overfitting, ya que el modelo es muy simple (o restringido). En este tipo de casos, optamos por complejificar el modelo para obtener un modelo menos simple. Sin embargo, con conjuntos de datos de mayor dimensión (es decir, conjuntos de datos con un gran número de características), los modelos lineales son más potentes, y hay más posibilidades de que se ajusten en exceso.</p></li>
<li><p>Veamos cómo se comporta <code class="docutils literal notranslate"><span class="pre">LinearRegression</span></code> en un conjunto de datos más complejo, como el conjunto de datos de viviendas de Boston. Recordemos que este conjunto de datos tiene 506 muestras y 105 características derivadas. En primer lugar, cargamos el conjunto de datos y lo dividimos en un conjunto de entrenamiento y otro de prueba. A continuación, construimos el modelo de regresión lineal como antes</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">mglearn</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">load_extended_boston</span><span class="p">()</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">lr</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">()</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Al comparar los <code class="docutils literal notranslate"><span class="pre">score</span></code> de los conjuntos de entrenamiento y de prueba, comprobamos que predecimos con mucha precisión en el conjunto de entrenamiento, pero el <span class="math notranslate nohighlight">\(\mathbb{R}^2\)</span> en el conjunto de prueba es mucho peor</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Training set score: </span><span class="si">{:.2f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">lr</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Test set score: </span><span class="si">{:.2f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">lr</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Training set score: 0.95
Test set score: 0.61
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Esta discrepancia entre el rendimiento en el conjunto de entrenamiento y el conjunto de prueba es un claro signo de <code class="docutils literal notranslate"><span class="pre">overfitting</span></code>, y por lo tanto, debemos tratar de encontrar un modelo que nos permita controlar la <code class="docutils literal notranslate"><span class="pre">complejidad</span></code>. Usualmente, en este tipo de casos utilizamos técnicas de regularización. Una de las alternativas más utilizadas a la regresión lineal estándar es la regresión <code class="docutils literal notranslate"><span class="pre">ridge</span></code>, que estudiaremos a continuación.</p></li>
</ul>
</section>
<section id="regresion-ridge">
<h3>Regresión ridge<a class="headerlink" href="#regresion-ridge" title="Permalink to this headline">#</a></h3>
<p><strong><code class="docutils literal notranslate"><span class="pre">Observación</span></code></strong></p>
<ul class="simple">
<li><p>En la regresión ridge, los coeficientes <span class="math notranslate nohighlight">\(\boldsymbol{\hat{\beta}}\)</span> se eligen no sólo para que predigan bien en los datos de entrenamiento, sino que también, para que se ajusten a una restricción adicional. <code class="docutils literal notranslate"><span class="pre">La</span> <span class="pre">regresión</span> <span class="pre">Ridge</span> <span class="pre">regulariza</span> <span class="pre">la</span> <span class="pre">regresión</span> <span class="pre">lineal</span> <span class="pre">imponiendo</span> <span class="pre">una</span> <span class="pre">penalización</span> <span class="pre">al</span> <span class="pre">tamaño</span> <span class="pre">de</span> <span class="pre">los</span> <span class="pre">coeficientes</span></code>.</p></li>
<li><p>La magnitud de los coeficientes se considera lo más pequeña posible; en otras palabras, todas las entradas de <span class="math notranslate nohighlight">\(\boldsymbol{\hat{\beta}}\)</span> deben ser cercanas a cero. Intuitivamente, esto significa que <code class="docutils literal notranslate"><span class="pre">cada</span> <span class="pre">característica</span> <span class="pre">debe</span> <span class="pre">tener</span> <span class="pre">el</span> <span class="pre">menor</span> <span class="pre">efecto</span> <span class="pre">posible</span> <span class="pre">sobre</span> <span class="pre">el</span> <span class="pre">resultado</span> <span class="pre">(lo</span> <span class="pre">que</span> <span class="pre">se</span> <span class="pre">traduce</span> <span class="pre">en</span> <span class="pre">tener</span> <span class="pre">una</span> <span class="pre">pendiente</span> <span class="pre">pequeña),</span> <span class="pre">sin</span> <span class="pre">dejar</span> <span class="pre">de</span> <span class="pre">predecir</span> <span class="pre">bien</span></code>. Esta restricción es un ejemplo de lo que se llama <code class="docutils literal notranslate"><span class="pre">regularización</span></code>.</p></li>
<li><p>La <code class="docutils literal notranslate"><span class="pre">regularización</span></code> consiste en <code class="docutils literal notranslate"><span class="pre">restringir</span> <span class="pre">explícitamente</span> <span class="pre">un</span> <span class="pre">modelo</span> <span class="pre">para</span> <span class="pre">evitar</span> <span class="pre">el</span> <span class="pre">overfitting</span></code>. El tipo particular utilizado por la regresión ridge se conoce como regularización <span class="math notranslate nohighlight">\(L^2\)</span>.</p></li>
</ul>
<p><strong><code class="docutils literal notranslate"><span class="pre">Formulación</span></code></strong></p>
<p>Consideremos el modelo de regresión lineal</p>
<div class="math notranslate nohighlight" id="equation-linear-model-comp">
<span class="eqno">(3)<a class="headerlink" href="#equation-linear-model-comp" title="Permalink to this equation">#</a></span>\[
y_{i}=\beta_{0}+\beta_{1}\cdot x_{i1}+\beta_{2}\cdot x_{i2}+\cdots+\beta_{p}\cdot x_{ip}+\varepsilon_{i},~i = 1,2,\dots, n,
\]</div>
<p>basado en los datos observados <span class="math notranslate nohighlight">\(\{(y_{i}, x_{i1}, x_{i2},\dots, x_{ip}):~i=1,2,\dots,n\}\)</span> para la variable respuesta <span class="math notranslate nohighlight">\(y\)</span> y <span class="math notranslate nohighlight">\(p\)</span> variables predictoras <span class="math notranslate nohighlight">\(\boldsymbol{x}=(x_{1}, x_{2},\dots,x_{p})\)</span>. La <code class="docutils literal notranslate"><span class="pre">regresión</span> <span class="pre">ridge</span></code> propuesta por <code class="docutils literal notranslate"><span class="pre">Hoerl</span> <span class="pre">y</span> <span class="pre">Kennard</span> <span class="pre">(1970)</span></code> es un método para evitar la inestabilidad de las estimaciones en los modelos de regresión lineal, causada por la multicolinealidad, esto es, correlación alta entre más de dos variables predictoras. Este método es una regularización, en la que la suma de cuadrados de los coeﬃcientes de regresión, excluyendo el intercepto, es el <code class="docutils literal notranslate"><span class="pre">término</span> <span class="pre">de</span> <span class="pre">penalización</span></code>, y las estimaciones de coeﬃcientes de regresión se obtienen de la siguiente manera.</p>
<div class="tip dropdown admonition">
<p class="admonition-title">Problema de multicolinealidad</p>
<p>Cuando las variables predictoras están correlacionadas, esto indica que los cambios en una variable están asociados a cambios en otra. Cuanto más fuerte sea la correlación, más difícil será cambiar una variable sin cambiar otra. <code class="docutils literal notranslate"><span class="pre">Resulta</span> <span class="pre">difícil</span> <span class="pre">para</span> <span class="pre">el</span> <span class="pre">modelo</span> <span class="pre">estimar</span> <span class="pre">la</span> <span class="pre">relación</span> <span class="pre">entre</span> <span class="pre">cada</span> <span class="pre">variable</span> <span class="pre">predictora</span> <span class="pre">y</span> <span class="pre">la</span> <span class="pre">variable</span> <span class="pre">respuesta</span> <span class="pre">de</span> <span class="pre">forma</span> <span class="pre">independiente</span></code> porque las variables predictoras tienden a cambiar al unísono.</p>
</div>
<p>En primer lugar, obtenemos la media <span class="math notranslate nohighlight">\(\bar x_{j}=n^{-1}\sum_{i=1}^{n}x_{ij}\)</span> y la varianza <span class="math notranslate nohighlight">\(s_{j}^2=n^{-1}\sum_{i=1}^{n}(x_{ij}-\bar x_{j})^{2}\)</span>, <span class="math notranslate nohighlight">\(j=1,2,\dots,p\)</span> de los datos para las variables predictoras y estandaricemos los datos de la siguiente manera</p>
<div class="math notranslate nohighlight" id="equation-estand-ridge-reg">
<span class="eqno">(4)<a class="headerlink" href="#equation-estand-ridge-reg" title="Permalink to this equation">#</a></span>\[
z_{ij}=\frac{x_{ij}-\bar x_{j}}{s_{j}},~i=1,2,\dots,n,~j=1,2,\dots,p.
\]</div>
<div class="dropdown admonition">
<p class="admonition-title">¿Por qué estandarizar? </p>
<p>La <code class="docutils literal notranslate"><span class="pre">regresión</span> <span class="pre">ridge</span></code> regulariza la <code class="docutils literal notranslate"><span class="pre">regresión</span> <span class="pre">lineal</span></code> imponiendo una penalización al tamaño de los coeficientes. Así, los coeficientes se contraen hacia cero y entre sí. Cuando esto ocurre, si las variables independientes no tienen la misma escala, la contracción no es justa. <code class="docutils literal notranslate"><span class="pre">Dos</span> <span class="pre">variables</span> <span class="pre">independientes</span> <span class="pre">con</span> <span class="pre">diferentes</span> <span class="pre">escalas</span> <span class="pre">tendrán</span> <span class="pre">diferentes</span> <span class="pre">contribuciones</span> <span class="pre">a</span> <span class="pre">los</span> <span class="pre">términos</span> <span class="pre">penalizados</span></code>, porque el término penalizado es una suma de cuadrados de todos los coeficientes. Para evitar este tipo de problemas, muy a menudo, las variables independientes se centran y se escalan para que tengan varianza unitaria.</p>
</div>
<p>El modelo de regresión lineal basado en los datos estandarizados puede expresarse entonces como</p>
<div class="math notranslate nohighlight" id="equation-eq-reg-li-z">
<span class="eqno">(5)<a class="headerlink" href="#equation-eq-reg-li-z" title="Permalink to this equation">#</a></span>\[\begin{split}
\begin{align*}
y_{i} &amp;= \beta_{0} + \beta_{1}\bar x_{1} + \beta_{2}\bar x_{2} + \cdots + \beta_{p}\bar x_{p} + 
\beta_{1}^{\star}z_{i1} + \beta_{2}^{\star}z_{i2} + \cdots + \beta_{p}^{\star}z_{ip} + \varepsilon_{i}\\
&amp;=\beta_{0}^{\star} + \beta_{1}^{\star}z_{i1} + \beta_{2}^{\star}z_{i2} + \cdots + \beta_{p}^{\star}z_{ip} + \varepsilon_{i},~ i = 1,2,\dots,n,
\end{align*}
\end{split}\]</div>
<p>donde <span class="math notranslate nohighlight">\(\beta_{0}^{\star}=\beta_{0}+\beta_{1}\bar x_{1}+\beta_{2}\bar x_{2}+\cdots+\beta_{p}\bar x_{p}~\text{y}~\beta_{j}^{\star}=s_{j}\beta_{j}\)</span>. Por lo tanto, podemos expresar el modelo de regresión lineal basados en los datos estandarizados para la variable predictora como</p>
<div class="math notranslate nohighlight" id="equation-reg-ridge-model">
<span class="eqno">(6)<a class="headerlink" href="#equation-reg-ridge-model" title="Permalink to this equation">#</a></span>\[
\boldsymbol{y}=\beta_{0}^{\star}\boldsymbol{1}+Z\boldsymbol{\beta}_{s}+\boldsymbol{\varepsilon},
\]</div>
<p>en forma matricial</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{pmatrix}
y_{1}\\
y_{2}\\
\vdots\\
y_{i}\\
\vdots\\
y_{n}
\end{pmatrix}
=
\beta_{0}^{\star}
\begin{pmatrix}
1\\
1\\
\vdots\\
1\\
\vdots\\
1
\end{pmatrix}
+
\begin{pmatrix}
z_{11} &amp; z_{12} &amp; \cdots &amp; z_{1p}\\
z_{21} &amp; z_{22} &amp; \cdots &amp; z_{2p}\\
\vdots\\
z_{31} &amp; z_{32} &amp; \cdots &amp; z_{3p}\\
\vdots\\
z_{n1} &amp; z_{n2} &amp; \cdots &amp; z_{np}
\end{pmatrix}
\begin{pmatrix}
\beta_{0}\\[2mm]
\beta_{1}\\[2mm]
\beta_{2}\\
\vdots\\[2mm]
\beta_{p}
\end{pmatrix}
+
\begin{pmatrix}
\varepsilon_{1}\\
\varepsilon_{2}\\
\vdots\\
\varepsilon_{i}\\
\vdots\\
\varepsilon_{n}
\end{pmatrix}
\end{split}\]</div>
<p>donde <span class="math notranslate nohighlight">\(\boldsymbol{1}\)</span> es un vector <span class="math notranslate nohighlight">\(n\)</span>-dimensional de unos, <span class="math notranslate nohighlight">\(\boldsymbol{\beta}_{s}=(s_{1}\beta_{1}, s_{2}\beta_{2},\dots,s_{p}\beta_{p}^{T})\)</span>, y <span class="math notranslate nohighlight">\(Z\)</span> es una matriz de <span class="math notranslate nohighlight">\(n\times p\)</span> que contiene los datos estandarizados <span class="math notranslate nohighlight">\(z_{ij}=(x_{ij}-\bar x_{j})/s_{j},~ i=1,2,\dots,n; j=1,2,\dots,p\)</span> en su posición <span class="math notranslate nohighlight">\((i,j)\)</span>.</p>
<p>El estimador <code class="docutils literal notranslate"><span class="pre">ridge</span></code> para el vector de coeficientes esta dado entonces por minimización de:</p>
<div class="math notranslate nohighlight" id="equation-ridge-coeff-stand">
<span class="eqno">(7)<a class="headerlink" href="#equation-ridge-coeff-stand" title="Permalink to this equation">#</a></span>\[
S_{\lambda}(\beta_{0}^{\star}, \boldsymbol{\beta}_{s})=(\boldsymbol{y}-\beta_{0}^{\star}\boldsymbol{1}-Z\boldsymbol{\beta}_{s})^{T}(\boldsymbol{y}-\beta_{0}^{\star}\boldsymbol{1}-Z\boldsymbol{\beta}_{s})+\lambda\boldsymbol{\beta}_{s}^{T}\boldsymbol{\beta}_{s}
\]</div>
<p>donde el termino de regularización <span class="math notranslate nohighlight">\(L^2\)</span>: (<span class="math notranslate nohighlight">\(\lambda\boldsymbol{\beta}_{s}^{T}\boldsymbol{\beta}_{s}\)</span>) con parámetro de regularización <span class="math notranslate nohighlight">\(\lambda\)</span> ha sido agregado al vector de coeficientes de regresión, excepto el intercepto. Este término es conocido como <code class="docutils literal notranslate"><span class="pre">weight</span> <span class="pre">decay</span></code>. Ecuación <a class="reference internal" href="#equation-ridge-coeff-stand">(7)</a> puede reescribirse de la siguiente forma al desarrollar los productos asociados y se aplican propiedades de la transpuesta</p>
<div class="math notranslate nohighlight">
\[
S_{\lambda}(\beta_{0}^{\star}, \boldsymbol{\beta}_{s})=\boldsymbol{y}^{T}\boldsymbol{y}-2\boldsymbol{y}^{T}\beta_{0}^{\star}\boldsymbol{1}-2\boldsymbol{y}^{T}Z\boldsymbol{\beta}_{s}+2\beta_{0}\boldsymbol{1}^{T}Z\boldsymbol{\beta}_{s}+n\beta_{0}^{\star^{2}}+\boldsymbol{\beta}_{s}^{T}Z^{T}Z\boldsymbol{\beta}_{s}+\lambda\boldsymbol{\beta}_{s}^{T}\boldsymbol{\beta}_{s}
\]</div>
<p>Diferenciando con respecto a <span class="math notranslate nohighlight">\(\beta_{0}^{\star}\)</span> y <span class="math notranslate nohighlight">\(\boldsymbol{\beta}_{s}\)</span> para resolver el problema de minimización, obtenemos las siguientes ecuaciones:</p>
<div class="math notranslate nohighlight" id="equation-eq-betaz">
<span class="eqno">(8)<a class="headerlink" href="#equation-eq-betaz" title="Permalink to this equation">#</a></span>\[
\begin{align*}
\frac{\partial S_{\lambda}(\beta_{0}^{\star}, \boldsymbol{\beta}_{s})}{\partial\beta_{0}^{\star}}&amp;=-2n\overline{y}+2n\beta_{0}^{\star}=0
\end{align*}
\]</div>
<p>Nótese que <span class="math notranslate nohighlight">\(Z^{T}\boldsymbol{1}=Z^{T}\boldsymbol{1}=0\)</span> <code class="docutils literal notranslate"><span class="pre">(verifíquelo)</span></code>. Para el caso de la derivada parcial con respecto a <span class="math notranslate nohighlight">\(\boldsymbol{\beta}_{s}\)</span> se requiere antes, estudiar la derivada de una forma cuadratica de la forma <span class="math notranslate nohighlight">\(\boldsymbol{x}^{T}A\boldsymbol{x}\)</span>. Nótese que</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align*}
\boldsymbol{x}^{T}A\boldsymbol{x}&amp;=(x_{1}, x_{2},\dots, x_{p})
\begin{pmatrix}
A_{11} &amp; A_{12} &amp; \cdots &amp; A_{1p}\\
A_{21} &amp; A_{22} &amp; \cdots &amp; A_{2p}\\
\vdots\\
A_{31} &amp; A_{32} &amp; \cdots &amp; A_{3p}\\
\vdots\\
A_{p1} &amp; A_{p2} &amp; \cdots &amp; A_{pp}
\end{pmatrix}
\begin{pmatrix}
x_{1}\\
x_{2}\\
\vdots\\
x_{p}
\end{pmatrix}
% &amp;=\left(\sum_{i=1}^{p}x_{i}A_{i1}, \sum_{i=1}^{p}x_{i}A_{i2},\dots, \sum_{i=1}^{p}x_{i}A_{ip}\right)
% \begin{pmatrix}
% x_{1}\\
% x_{2}\\
% \vdots\\
% x_{p}
% \end{pmatrix}\\
=\sum_{j=1}^{p}\left(\sum_{i=1}^{p}x_{i}A_{ij}\right)x_{j}
\end{align*}
\end{split}\]</div>
<p>Derivando con respecto a <span class="math notranslate nohighlight">\(x_{k}\)</span> para obtener la <span class="math notranslate nohighlight">\(k\)</span>-ésima componente del gradiente <span class="math notranslate nohighlight">\(\nabla_{\boldsymbol{x}}(\boldsymbol{x}^{T}A\boldsymbol{x})\)</span></p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align*}
\frac{\partial(\boldsymbol{x}^{T}A\boldsymbol{x})}{\partial x_{k}}&amp;=
\frac{\partial}{\partial x_{k}}\left[\sum_{j=1}^{p}\left(\sum_{i=1}^{p}x_{i}A_{ij}\right)x_{j}\right]\\
&amp;=\sum_{j=1}^{p}\left(\sum_{i=1}^{p}\frac{\partial x_{i}}{\partial x_{k}}A_{ij}\right)x_{j}+
\sum_{j=1}^{p}\frac{\partial x_{j}}{\partial x_{k}}\left(\sum_{i=1}^{p}x_{i}A_{ij}\right)\\
&amp;=\sum_{j=1}^{p}A_{kj}x_{j}+\sum_{i=1}^{p}x_{i}A_{ik}
\end{align*}
\end{split}\]</div>
<p>Por lo tanto, para <span class="math notranslate nohighlight">\(k=1,2,\dots,p\)</span>, bajo el supesto de simetría para <span class="math notranslate nohighlight">\(A\)</span> se tiene que</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align*}
\frac{\partial(\boldsymbol{x}^{T}A\boldsymbol{x})}{\partial\boldsymbol{x}}&amp;=
\begin{pmatrix}
\displaystyle{\sum_{j=1}^{p}A_{1j}x_{j}+\sum_{i=1}^{p}x_{i}A_{i1}}\\
\displaystyle{\sum_{j=1}^{p}A_{2j}x_{j}+\sum_{i=1}^{p}x_{i}A_{i2}}\\
\vdots\\
\displaystyle{\sum_{j=1}^{p}A_{pj}x_{j}+\sum_{i=1}^{p}x_{i}A_{ip}}
\end{pmatrix}\\
&amp;=A\boldsymbol{x}+A^{T}\boldsymbol{x}\\
&amp;=(A+A^{T})\boldsymbol{x}\\
&amp;=2A\boldsymbol{x}
\end{align*}
\end{split}\]</div>
<p>Nótese que <span class="math notranslate nohighlight">\(A:=Z^{T}Z\)</span>, es simétrica, en efecto: <span class="math notranslate nohighlight">\(A^{T}=(Z^{T}Z)^{T}=Z^{T}(Z^{T})^{T}=Z^{T}Z=A\)</span>, entonces <span class="math notranslate nohighlight">\(\partial_{\boldsymbol{\beta}_{s}}(\boldsymbol{\beta}_{s}^{T}Z^{T}Z\boldsymbol{\beta}_{s})=2Z^{T}Z\boldsymbol{\beta}_{s}\)</span>, por lo tanto</p>
<div class="math notranslate nohighlight" id="equation-eq-betas">
<span class="eqno">(9)<a class="headerlink" href="#equation-eq-betas" title="Permalink to this equation">#</a></span>\[
\begin{align*}
\frac{\partial S_{\lambda}(\beta_{0}^{\star},\boldsymbol{\beta}_{s})}{\partial\boldsymbol{\beta}_{s}}=-2Z^{T}\boldsymbol{y}+2Z^{T}Z\boldsymbol{\beta}_{s}+2\lambda\boldsymbol{\beta}_{s}=\boldsymbol{0}
\end{align*}
\]</div>
<p>Resolviendo las ecuaciones <a class="reference internal" href="#equation-eq-betaz">(8)</a> y <a class="reference internal" href="#equation-eq-betas">(9)</a> para <span class="math notranslate nohighlight">\(\beta_{0}^{\star}\)</span> y <span class="math notranslate nohighlight">\(\boldsymbol{\beta}_{s}\)</span>, se tienen estimadores ridge para el modelo de regresión <a class="reference internal" href="#equation-eq-reg-li-z">(5)</a></p>
<div class="math notranslate nohighlight">
\[
\hat{\beta}_{0}^{\star}=\overline{y}\quad\text{y}\quad\hat{\boldsymbol{\beta}}_{s}=(Z^{T}Z+\lambda I_{p})^{-1}Z^{T}\boldsymbol{y}
\]</div>
<p>Dado que <span class="math notranslate nohighlight">\(\beta_{0}^{\star}=\beta_{0}+\beta_{1}\bar x_{1}+\beta_{2}\bar x_{2}+\cdots+\beta_{p}\bar x_{p}\)</span> usando la estimación obtenida <span class="math notranslate nohighlight">\(\hat{\beta}_{0}^{\star}\)</span> se tiene que</p>
<div class="math notranslate nohighlight">
\[
\hat{\beta}_{0}=\overline{y}-\hat{\beta}_{1}\bar x_{1}-\hat{\beta}_{2}\bar x_{2}-\cdots-\hat{\beta}_{p}\bar x_{p}.
\]</div>
<p>Además, la estimación ridge del vector de coeficientes de regresión, está dada separadamente por la minimización de la función</p>
<div class="math notranslate nohighlight">
\[
S_{\lambda}(\boldsymbol{\beta}_{s})=(\boldsymbol{y}-Z\boldsymbol{\beta}_{s})^{T}(\boldsymbol{y}-Z\boldsymbol{\beta}_{s})+\lambda\boldsymbol{\beta}_{s}^{T}\boldsymbol{\beta}_{s}.
\]</div>
<p>En efecto, para obtener estimación ridge del vector de coeficientes <span class="math notranslate nohighlight">\(\boldsymbol{\beta}_{s}=(\hat{\beta}_{1}, \hat{\beta}_{2},\dots, \hat{\beta}_{p})\)</span>, primero, nótese que al reemplazar <span class="math notranslate nohighlight">\(\hat{\beta}_{0}^{\star}=\overline{y}\)</span> en Ecuación <a class="reference internal" href="#equation-reg-ridge-model">(6)</a> se tiene que <span class="math notranslate nohighlight">\(y=\overline{y}\boldsymbol{1}+Z\boldsymbol{\beta}_{s}+\varepsilon\)</span>, entonces <span class="math notranslate nohighlight">\(\boldsymbol{y}-\overline{y}\boldsymbol{1}\)</span> esta centrando los datos en relación a la variable respuesta.</p>
<p>Estandarizando las variables predictoras y respuesta en nuestro modelo inicial Ecuación <a class="reference internal" href="#equation-linear-model-comp">(3)</a>, mediante <span class="math notranslate nohighlight">\(y_{i}-\overline{y}\)</span> y <span class="math notranslate nohighlight">\((x_{ij}-\bar x_{j})/s_{j}\)</span> se tienen las siguientes igualdades, <code class="docutils literal notranslate"><span class="pre">verifiquelas</span></code></p>
<div class="math notranslate nohighlight" id="equation-ridge-normalization">
<span class="eqno">(10)<a class="headerlink" href="#equation-ridge-normalization" title="Permalink to this equation">#</a></span>\[
\sum_{i=1}^{n}y_{i}=0,\quad\sum_{i=1}^{n}x_{ij}=0,~j=1,2,\dots,p,\quad\sum_{i=1}^{n}x_{ij}^{2}=n
\]</div>
<p>Entonces,</p>
<div class="math notranslate nohighlight">
\[
\beta_{0}^{\star}=\bar{y}=\frac{1}{n}\sum_{i=1}^{n}y_{i}=0.
\]</div>
<p>En virtud de la implicación de estas igualdades con respecto al parámetro <span class="math notranslate nohighlight">\(\beta_{0}^{\star}\)</span> y la Ecuación <a class="reference internal" href="#equation-eq-reg-li-z">(5)</a>, podemos considerar sin perdida de generalidad, el modelo de regresión</p>
<div class="math notranslate nohighlight">
\[
y=X\boldsymbol{\beta}+\boldsymbol{\varepsilon},
\]</div>
<p>donde <span class="math notranslate nohighlight">\(X\in\mathbb{R}^{n\times p},~\boldsymbol{\beta}\in\mathbb{R}^{p},~E(\boldsymbol{\varepsilon})=0\)</span> y <span class="math notranslate nohighlight">\(\textrm{cov}(\boldsymbol{\varepsilon})=\sigma^2\boldsymbol{I}\)</span>.</p>
<p>Por lo tanto minimizando el operador <span class="math notranslate nohighlight">\(S_{\lambda}(\boldsymbol{\beta})=(y-X\boldsymbol{\beta})^{T}(y-X\boldsymbol{\beta})+\lambda\boldsymbol{\beta}^{T}\boldsymbol{\beta}\)</span>, de forma analoga al procedimiento de optimización para la Ecuación <a class="reference internal" href="#equation-ridge-coeff-stand">(7)</a>, obtenemos el estimador de ridge:</p>
<div class="math notranslate nohighlight">
\[
\hat{\boldsymbol{\beta}}_{R}=(X^{T}X+\lambda\boldsymbol{I}_{p})^{-1}X^{T}\boldsymbol{y}.
\]</div>
<div class="proof property admonition" id="prop_ridge_estimador">
<p class="admonition-title"><span class="caption-number">Property 1 </span> (Propiedades del estimador ridge)</p>
<section class="property-content" id="proof-content">
<p>El estimador ridge satisface las siguientes propiedades:</p>
<div class="math notranslate nohighlight" id="equation-ridge-props">
<span class="eqno">(11)<a class="headerlink" href="#equation-ridge-props" title="Permalink to this equation">#</a></span>\[\begin{split}
\begin{align}
E(\hat{\boldsymbol{\beta}}_{R})&amp;=(X^{T}X+\lambda\boldsymbol{I}_{p})^{-1}X^{T}X\boldsymbol{\beta}\\
\textrm{cov}(\boldsymbol{\beta}_{R})&amp;=\sigma^{2}(X^{T}X+\lambda\boldsymbol{I}_{p})^{-1}X^{T}X(X^{T}X+\lambda\boldsymbol{I}_{p})^{-1}\\
E(\hat{\boldsymbol{\beta}}_{R}-\boldsymbol{\beta})&amp;=-\lambda(X^{T}X+\lambda\boldsymbol{I}_{p})^{-1}\boldsymbol{\beta}\\
E[(\hat{\boldsymbol{\beta}}_{R}-\boldsymbol{\beta})^{T}(\hat{\boldsymbol{\beta}}_{R}-\boldsymbol{\beta})&amp;=\displaystyle{\sigma^{2}\sum_{j=1}^{p}\frac{l_{j}}{(l_{j}+\lambda)^{2}}+\lambda^{2}\boldsymbol{\beta}^{T}(X^{T}X+\lambda\boldsymbol{I}_{p})^{-2}\boldsymbol{\beta}},
\end{align}
\end{split}\]</div>
<p>donde <span class="math notranslate nohighlight">\(l_{1}, l_{2},\dots, l_{p}\)</span> son los autovalores ordenados de <span class="math notranslate nohighlight">\(X^{T}X\)</span>. El primer término del lado derecho de la última ecuación en <a class="reference internal" href="#equation-ridge-props">(11)</a> representa la suma de las varianzas de los componentes del estimador ridge, y el segundo término es el cuadrado del sesgo.</p>
</section>
</div><div class="tip admonition">
<p class="admonition-title">Ejercicio para el lector</p>
<p>Queda como ejercicio para el lector verificar las Propiedades <a class="reference internal" href="#equation-ridge-props">(11)</a> del <code class="docutils literal notranslate"><span class="pre">estimador</span> <span class="pre">ridge</span></code>. <em>Sugerencia: Revisar el texto de Sadanori Konishi</em>, <code class="docutils literal notranslate"><span class="pre">Introduction</span> <span class="pre">to</span> <span class="pre">Multivariate</span> <span class="pre">Analysis:</span> <span class="pre">Linear</span> <span class="pre">and</span> <span class="pre">Nonlinear</span> <span class="pre">Modeling</span></code> <span id="id1">[<a class="reference internal" href="#id38" title="S. Konishi. Introduction to Multivariate Analysis: Linear and Nonlinear Modeling. Chapman &amp; Hall/CRC Texts in Statistical Science. Taylor &amp; Francis, 2014. ISBN 9781466567283. URL: https://books.google.com.co/books?id=fcuuAwAAQBAJ.">Konishi, 2014</a>]</span>.</p>
</div>
<p><strong><code class="docutils literal notranslate"><span class="pre">Aplicación</span></code></strong></p>
<ul class="simple">
<li><p>La regresión ridge se implementa en <code class="docutils literal notranslate"><span class="pre">linear_model.Ridge</span></code>. Veamos qué tal lo hace en el conjunto de datos ampliado de <code class="docutils literal notranslate"><span class="pre">Boston</span> <span class="pre">Housing</span></code>:</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">Ridge</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">ridge</span> <span class="o">=</span> <span class="n">Ridge</span><span class="p">()</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Training set score: </span><span class="si">{:.2f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">ridge</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Test set score: </span><span class="si">{:.2f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">ridge</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Training set score: 0.89
Test set score: 0.75
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Como puede ver, la puntuación del conjunto de entrenamiento de <code class="docutils literal notranslate"><span class="pre">Ridge</span></code> es menor que la de la regresión lineal, mientras que la puntuación del conjunto de prueba es mayor. Esto es coherente con nuestras expectativas. Con la regresión, nos ajustamos demasiado a los datos. <code class="docutils literal notranslate"><span class="pre">Ridge</span></code> es un modelo más restringido, por lo que existe menos probabilidad de overfitting. Un modelo menos complejo significa un peor rendimiento en el conjunto de de entrenamiento, pero una mejor generalización. Como sólo nos interesa el rendimiento de la generalización, deberíamos elegir el modelo <code class="docutils literal notranslate"><span class="pre">Ridge</span></code> en lugar del modelo de regresión lineal.</p></li>
<li><p>El modelo <code class="docutils literal notranslate"><span class="pre">Ridge</span></code> hace un balance entre la simplicidad del modelo (coeficientes casi nulos coeficientes) y su rendimiento en el conjunto de entrenamiento. La importancia que el modelo da a la simplicidad frente al rendimiento del conjunto de entrenamiento, puede ser especificada por el usuario, utilizando el parámetro <code class="docutils literal notranslate"><span class="pre">alfa</span></code>. En el ejemplo anterior, hemos utilizado el parámetro por defecto <code class="docutils literal notranslate"><span class="pre">alpha=1,0</span></code>. Sin embargo, no hay ninguna razón por la que este nos dió la mejor compensación. El ajuste óptimo de <code class="docutils literal notranslate"><span class="pre">alfa</span></code> depende del conjunto de datos concreto que estemos utilizando. Aumentar <code class="docutils literal notranslate"><span class="pre">alfa</span></code> obliga a los coeficientes a acercarse más a cero, lo que disminuye el rendimiento del conjunto de entrenamiento, pero puede ayudar a la generalización.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">ridge10</span> <span class="o">=</span> <span class="n">Ridge</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Training set score: </span><span class="si">{:.2f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">ridge10</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Test set score: </span><span class="si">{:.2f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">ridge10</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Training set score: 0.79
Test set score: 0.64
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>La disminución de <code class="docutils literal notranslate"><span class="pre">alfa</span></code> permite que los coeficientes estén menos restringidos. Para valores muy pequeños de <code class="docutils literal notranslate"><span class="pre">alfa</span></code>, los coeficientes apenas están restringidos, y terminamos con un modelo que se parece a <code class="docutils literal notranslate"><span class="pre">LinearRegression</span></code></p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">ridge01</span> <span class="o">=</span> <span class="n">Ridge</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Training set score: </span><span class="si">{:.2f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">ridge01</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Test set score: </span><span class="si">{:.2f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">ridge01</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Training set score: 0.93
Test set score: 0.77
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Aquí, <code class="docutils literal notranslate"><span class="pre">alfa=0.1</span></code> parece funcionar bien. Podríamos intentar disminuir <code class="docutils literal notranslate"><span class="pre">alfa</span></code> aún más para mejorar la generalización. Por ahora, observe cómo el parámetro <code class="docutils literal notranslate"><span class="pre">alfa</span></code> se corresponde con la complejidad del modelo. Discutiremos los métodos para seleccionar adecuadamente los parámetros en el capítulo de <code class="docutils literal notranslate"><span class="pre">evaluación</span> <span class="pre">de</span> <span class="pre">modelos</span></code>. También podemos obtener una visión más cualitativa de cómo el parámetro <code class="docutils literal notranslate"><span class="pre">alfa</span></code> cambia el modelo, inspeccionando el atributo <code class="docutils literal notranslate"><span class="pre">coef_</span></code> de los modelos con diferentes valores de <code class="docutils literal notranslate"><span class="pre">alfa</span></code>. Un <code class="docutils literal notranslate"><span class="pre">alfa</span></code> más alto significa un modelo más restringido, por lo que esperamos que las entradas de <code class="docutils literal notranslate"><span class="pre">coef_</span></code> tengan una magnitud menor para un valor alto de <code class="docutils literal notranslate"><span class="pre">alfa</span></code> que para un valor bajo de <code class="docutils literal notranslate"><span class="pre">alfa</span></code>.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">ridge</span><span class="o">.</span><span class="n">coef_</span><span class="p">,</span> <span class="s1">&#39;s&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Ridge alpha=1&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">ridge10</span><span class="o">.</span><span class="n">coef_</span><span class="p">,</span> <span class="s1">&#39;^&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Ridge alpha=10&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">ridge01</span><span class="o">.</span><span class="n">coef_</span><span class="p">,</span> <span class="s1">&#39;v&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Ridge alpha=0.1&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">lr</span><span class="o">.</span><span class="n">coef_</span><span class="p">,</span> <span class="s1">&#39;o&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;LinearRegression&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Coefficient index&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Coefficient magnitude&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">hlines</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">lr</span><span class="o">.</span><span class="n">coef_</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="o">-</span><span class="mi">25</span><span class="p">,</span> <span class="mi">25</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">();</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/supervised_learning_155_0.png" src="_images/supervised_learning_155_0.png" />
</div>
</div>
<ul class="simple">
<li><p>Aquí, el eje <span class="math notranslate nohighlight">\(x\)</span> enumera las entradas de <code class="docutils literal notranslate"><span class="pre">coef_</span></code> : <span class="math notranslate nohighlight">\(x=0\)</span> muestra el coeficiente asociado a la primera característica, <span class="math notranslate nohighlight">\(x=1\)</span> el coeficiente asociado a la segunda característica, y así sucesivamente hasta <span class="math notranslate nohighlight">\(x=100\)</span>. El eje <span class="math notranslate nohighlight">\(y\)</span> muestra los valores numéricos de los valores correspondientes de los coeficientes. La principal conclusión es que para <code class="docutils literal notranslate"><span class="pre">alfa=10</span></code>, los coeficientes se sitúan en su mayoría entre -3 y 3. Los coeficientes del modelo <code class="docutils literal notranslate"><span class="pre">Ridge</span></code> con <code class="docutils literal notranslate"><span class="pre">alfa=1</span></code> son algo mayores. Los puntos correspondientes a <code class="docutils literal notranslate"><span class="pre">alfa=0,1</span></code> tienen una magnitud aún mayor, y muchos de los puntos correspondientes a la regresión lineal sin ninguna regularización (que sería <code class="docutils literal notranslate"><span class="pre">alfa=0</span></code>), son tan grandes que quedan fuera del gráfico.</p></li>
<li><p>Otra forma de entender la influencia de la regularización es fijar un valor de <code class="docutils literal notranslate"><span class="pre">alfa</span></code> pero variando la cantidad de datos de entrenamiento disponibles. Si submuestreamos el conjunto de datos de <code class="docutils literal notranslate"><span class="pre">Boston</span> <span class="pre">Housing</span></code> y evaluamos <code class="docutils literal notranslate"><span class="pre">LinearRegression</span></code> y <code class="docutils literal notranslate"><span class="pre">Ridge(alpha=1)</span></code> en subconjuntos de tamaño creciente, obtenemos la siguiente <code class="docutils literal notranslate"><span class="pre">curva</span> <span class="pre">de</span> <span class="pre">aprendizaje</span></code></p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">mglearn</span><span class="o">.</span><span class="n">plots</span><span class="o">.</span><span class="n">plot_ridge_n_samples</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/supervised_learning_157_0.png" src="_images/supervised_learning_157_0.png" />
</div>
</div>
<ul class="simple">
<li><p>Como era de esperarse, la puntuación de entrenamiento es mayor que la de prueba para todos los tamaños de conjuntos de datos, tanto para la regresión lineal como para la ridge. Debido a que la regresión ridge está regularizada, la puntuación de entrenamiento es inferior a la de la regresión lineal en todos los casos. Sin embargo, la puntuación de la prueba de la regresión ridge es mejor, en particular, para los subconjuntos pequeños de datos. Para menos de 400 puntos de datos, la regresión lineal no es capaz de aprender nada. A medida que el modelo dispone de más datos, ambos modelos mejoran, y la regresión lineal alcanza a la ridge.</p></li>
</ul>
</section>
<section id="lasso">
<h3>Lasso<a class="headerlink" href="#lasso" title="Permalink to this headline">#</a></h3>
<p><strong><code class="docutils literal notranslate"><span class="pre">Observación</span></code></strong></p>
<ul class="simple">
<li><p>Una alternativa a <code class="docutils literal notranslate"><span class="pre">Ridge</span></code> para regularizar la regresión lineal es <code class="docutils literal notranslate"><span class="pre">Lasso</span></code>. Al igual que con la regresión <code class="docutils literal notranslate"><span class="pre">Ridge</span></code>, el uso de <code class="docutils literal notranslate"><span class="pre">lasso</span></code> también restringe los coeficientes para que sean cercanos a cero, pero de una forma ligeramente diferente, llamada regularización <span class="math notranslate nohighlight">\(L^1\)</span>.</p></li>
<li><p>La consecuencia de la regularización <span class="math notranslate nohighlight">\(L^1\)</span> es que cuando se utiliza lasso, algunos coeficientes son exactamente cero. Esto significa que algunas características son totalmente ignoradas por el modelo. Esto puede verse como una forma de selección automática de de características.</p></li>
<li><p>El hecho de que algunos coeficientes sean exactamente cero a menudo hace que un modelo sea más fácil de interpretar, y puede revelar las características más importantes de un modelo.</p></li>
</ul>
<p><strong><code class="docutils literal notranslate"><span class="pre">Formulación</span></code></strong></p>
<p>El método <code class="docutils literal notranslate"><span class="pre">Lasso</span></code> es un método de estimación de parámetros del modelo mediante la minimización de la siguiente función objetivo, que impone la suma de valores absolutos (normas <span class="math notranslate nohighlight">\(L^{1}\)</span>) de los coeficientes de regresión como una restricción a la suma de errores al cuadrado:</p>
<div class="math notranslate nohighlight">
\[
S_{\lambda}(\boldsymbol{\beta})=(y-X\boldsymbol{\beta})^{T}(y-X\boldsymbol{\beta})+\lambda\sum_{i=1}^{p}|\beta_{j}|,
\]</div>
<p>donde los datos observados están normalizados como en la Ecuación <a class="reference internal" href="#equation-ridge-normalization">(10)</a>. A diferencia de la contracción de los coeficientes de regresión hacia cero, que se produce en la regresión de <code class="docutils literal notranslate"><span class="pre">ridge</span></code>, <code class="docutils literal notranslate"><span class="pre">lasso</span></code> da lugar a una estimación exactamente igual a cero para algunos de los coeficientes.</p>
<p>Una ventaja de la regresión <code class="docutils literal notranslate"><span class="pre">ridge</span></code> es que si <span class="math notranslate nohighlight">\(p &lt; n\)</span>, entonces con una selección adecuada del parámetro de regularización <span class="math notranslate nohighlight">\(\lambda\)</span>, es posible obtener estimaciones estables de los coeficientes de regresión, incluso en casos que impliquen multicolinealidad entre las variables predictoras o en los que <span class="math notranslate nohighlight">\(X^{T}X\)</span> es aproximadamente singular para la matriz de diseño <span class="math notranslate nohighlight">\(X\)</span>. Sin embargo, debido a que, a diferencia de <code class="docutils literal notranslate"><span class="pre">lasso</span></code>, la regresión <code class="docutils literal notranslate"><span class="pre">ridge</span></code> no puede producir estimaciones exactamente iguales a cero, entonces, la regresión <code class="docutils literal notranslate"><span class="pre">ridge</span></code> no puede utilizarse como método de selección de variables.</p>
<figure class="align-center" id="fig-ridge-lasso">
<img alt="_images/ridge_lasso.png" src="_images/ridge_lasso.png" />
<figcaption>
<p><span class="caption-number">Fig. 2 </span><span class="caption-text">Estimación ridge (izquierda) y estimación lasso (derecha).</span><a class="headerlink" href="#fig-ridge-lasso" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<p>La diferencia entre la estimación lasso y la estimación ridge puede demostrarse, para simplificar, para el caso de sólo dos variables predictoras <span class="math notranslate nohighlight">\(x_{1}\)</span> y <span class="math notranslate nohighlight">\(x_{2}\)</span>. En la estimación ridge, la solución se basa en la restricción <span class="math notranslate nohighlight">\(\beta_{1}^{2}+\beta_{2}^{2}\leq c_{1}\)</span> de minimizar</p>
<div class="math notranslate nohighlight">
\[
S(\beta_{1}, \beta_{2})=\sum_{i=1}^{n}\left(y_{i}-\sum_{j=1}^{2}\beta_{j}x_{ij}\right)^{2},
\]</div>
<p>para datos centrados, mientras que la estimación lasso se basa en la restricción <span class="math notranslate nohighlight">\(|\beta_{1}|+|\beta_{2}|\leq c_{2}\)</span>.</p>
<ul class="simple">
<li><p>Dado que la estimación por mínimos cuadrados es la solución que minimiza <span class="math notranslate nohighlight">\(S(\beta_{1}, \beta_{2})\)</span>, esta se produce en el centro de una elipse. Sin embargo, como se muestra en la <a class="reference internal" href="#fig-ridge-lasso"><span class="std std-numref">Fig. 2</span></a>, las soluciones que satisfacen las restricciones en las estimaciones ridge se encuentran en regiones diferentes de las que satisfacen las restricciones en las estimaciones lasso.</p></li>
<li><p>La diferencia esencial entre la estimación ridge y la estimación lasso como se muestra en la <a class="reference internal" href="#fig-ridge-lasso"><span class="std std-numref">Fig. 2</span></a>, es que <code class="docutils literal notranslate"><span class="pre">la</span> <span class="pre">estimación</span> <span class="pre">ridge</span> <span class="pre">reduce</span> <span class="pre">todas</span> <span class="pre">las</span> <span class="pre">estimaciones</span> <span class="pre">del</span> <span class="pre">coeficiente</span> <span class="pre">de</span> <span class="pre">regresión</span> <span class="pre">hacia,</span> <span class="pre">pero</span> <span class="pre">no</span> <span class="pre">exactamente</span> <span class="pre">cero,</span> <span class="pre">en</span> <span class="pre">relación</span> <span class="pre">con</span> <span class="pre">las</span> <span class="pre">correspondientes</span> <span class="pre">a</span> <span class="pre">los</span> <span class="pre">mínimos</span> <span class="pre">cuadrados,</span> <span class="pre">mientras</span> <span class="pre">que</span> <span class="pre">la</span> <span class="pre">estimación</span> <span class="pre">lasso</span> <span class="pre">localiza</span> <span class="pre">algunas</span> <span class="pre">de</span> <span class="pre">las</span> <span class="pre">estimaciones</span> <span class="pre">del</span> <span class="pre">coeficiente</span> <span class="pre">de</span> <span class="pre">regresión</span> <span class="pre">exactamente</span> <span class="pre">iguales</span> <span class="pre">a</span> <span class="pre">cero</span></code>. Debido a su característica de reducir algunos coeficientes a exactamente cero, <code class="docutils literal notranslate"><span class="pre">lasso</span> <span class="pre">también</span> <span class="pre">puede</span> <span class="pre">utilizarse</span> <span class="pre">para</span> <span class="pre">la</span> <span class="pre">selección</span> <span class="pre">de</span> <span class="pre">variables</span> <span class="pre">en</span> <span class="pre">modelos</span> <span class="pre">a</span> <span class="pre">gran</span> <span class="pre">escala</span> <span class="pre">con</span> <span class="pre">muchas</span> <span class="pre">variables</span> <span class="pre">predictoras</span></code>, para las que el parámetro de regularización <span class="math notranslate nohighlight">\(\lambda\)</span> afecta al grado de de esparcimiento de la solución.</p></li>
</ul>
<div class="tip admonition">
<p class="admonition-title">Ejercicio para el lector</p>
<p>Queda como ejercicio para el lector, encontrar parametros de estimación lasso, tal como se realizó en el caso de la regresión ridge. ¿Pueden ser obtenidos analíticamente?. Se sugiere investigar sobre el algoritmo LARS (Least Angle Regression) de Efron et al. (2004).</p>
</div>
<p><strong><code class="docutils literal notranslate"><span class="pre">Aplicación</span></code></strong></p>
<ul class="simple">
<li><p>Apliquemos <code class="docutils literal notranslate"><span class="pre">lasso</span></code> al conjunto de datos ampliado de <code class="docutils literal notranslate"><span class="pre">Boston</span> <span class="pre">Housing</span></code></p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">Lasso</span>
<span class="n">lasso</span> <span class="o">=</span> <span class="n">Lasso</span><span class="p">()</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Training set score: </span><span class="si">{:.2f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">lasso</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Test set score: </span><span class="si">{:.2f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">lasso</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Number of features used: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">lasso</span><span class="o">.</span><span class="n">coef_</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Training set score: 0.29
Test set score: 0.21
Number of features used: 4
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Como se puede ver, <code class="docutils literal notranslate"><span class="pre">Lasso</span></code> lo hace bastante mal, tanto en el conjunto de entrenamiento como en el de prueba. Esto indica <code class="docutils literal notranslate"><span class="pre">underfitting</span></code>, pero, nótese que sólo utilizó 4 de las 105 características (<code class="docutils literal notranslate"><span class="pre">feature</span> <span class="pre">selection</span></code>). De forma similar a <code class="docutils literal notranslate"><span class="pre">Ridge</span></code>, <code class="docutils literal notranslate"><span class="pre">Lasso</span></code> también tiene un parámetro de regularización, <code class="docutils literal notranslate"><span class="pre">alpha</span></code>, que controla la fuerza con la que los coeficientes son empujados hacia cero. En el ejemplo anterior, utilizamos el valor por defecto de <code class="docutils literal notranslate"><span class="pre">alpha=1.0</span></code>. Para reducir <code class="docutils literal notranslate"><span class="pre">underfitting</span></code>, intentemos disminuir <code class="docutils literal notranslate"><span class="pre">alpha</span></code>. Cuando hacemos esto, también necesitamos aumentar el ajuste por defecto de <code class="docutils literal notranslate"><span class="pre">max_iter</span></code> (el número máximo de iteraciones a ejecutar)</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">lasso001</span> <span class="o">=</span> <span class="n">Lasso</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">100000</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Training set score: </span><span class="si">{:.2f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">lasso001</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Test set score: </span><span class="si">{:.2f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">lasso001</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Number of features used: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">lasso001</span><span class="o">.</span><span class="n">coef_</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Training set score: 0.90
Test set score: 0.77
Number of features used: 33
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Un <code class="docutils literal notranslate"><span class="pre">alpha</span></code> más bajo nos permitió ajustar un modelo más complejo, que funcionó mejor en los datos de entrenamiento y de prueba. El rendimiento es ligeramente mejor que utilizando <code class="docutils literal notranslate"><span class="pre">Ridge</span></code>, y estamos utilizando sólo 33 de las 105 características. Esto hace que este modelo sea potencialmente más fácil de entender. Sin embargo, si fijamos <code class="docutils literal notranslate"><span class="pre">alpha</span></code> demasiado bajo, volvemos a eliminar el efecto de la regularización y acabamos en <code class="docutils literal notranslate"><span class="pre">overfitting</span></code>, con un resultado similar al de <code class="docutils literal notranslate"><span class="pre">LinearRegression</span></code></p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">lasso00001</span> <span class="o">=</span> <span class="n">Lasso</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.0001</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">100000</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Training set score: </span><span class="si">{:.2f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">lasso00001</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Test set score: </span><span class="si">{:.2f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">lasso00001</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Number of features used: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">lasso00001</span><span class="o">.</span><span class="n">coef_</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Training set score: 0.95
Test set score: 0.64
Number of features used: 96
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Una vez más, podemos trazar los coeficientes de los diferentes modelos</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">lasso</span><span class="o">.</span><span class="n">coef_</span><span class="p">,</span> <span class="s1">&#39;s&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Lasso alpha=1&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">lasso001</span><span class="o">.</span><span class="n">coef_</span><span class="p">,</span> <span class="s1">&#39;^&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Lasso alpha=0.01&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">lasso00001</span><span class="o">.</span><span class="n">coef_</span><span class="p">,</span> <span class="s1">&#39;v&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Lasso alpha=0.0001&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">ridge01</span><span class="o">.</span><span class="n">coef_</span><span class="p">,</span> <span class="s1">&#39;o&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Ridge alpha=0.1&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">ncol</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mf">1.05</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="o">-</span><span class="mi">25</span><span class="p">,</span> <span class="mi">25</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Coefficient index&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Coefficient magnitude&quot;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/supervised_learning_179_0.png" src="_images/supervised_learning_179_0.png" />
</div>
</div>
<ul class="simple">
<li><p>Para <code class="docutils literal notranslate"><span class="pre">alpha</span> <span class="pre">=</span> <span class="pre">1</span></code>, no sólo vemos que la mayoría de los coeficientes son cero (algo que ya sabíamos), sino que los coeficientes restantes también son de pequeña magnitud. Disminuyendo <code class="docutils literal notranslate"><span class="pre">alpha</span></code> a 0.01 , obtenemos la solución mostrada como los puntos verdes, que hace que la mayoría de las características sean exactamente cero. Utilizando <code class="docutils literal notranslate"><span class="pre">alpha</span> <span class="pre">=</span> <span class="pre">0.00001</span></code>, obtenemos un modelo bastante poco regularizado, con la mayoría de los coeficientes no nulos y de gran magnitud. A modo de comparación, la mejor solución <code class="docutils literal notranslate"><span class="pre">Ridge</span></code> se muestra en color verde azulado. El modelo <code class="docutils literal notranslate"><span class="pre">Ridge</span></code> con <code class="docutils literal notranslate"><span class="pre">alpha</span> <span class="pre">=</span> <span class="pre">0.1</span></code> tiene un rendimiento predictivo similar al del modelo <code class="docutils literal notranslate"><span class="pre">lasso</span></code> con <code class="docutils literal notranslate"><span class="pre">alpha</span> <span class="pre">=</span> <span class="pre">0.01</span></code>, pero utilizando <code class="docutils literal notranslate"><span class="pre">Ridge</span></code>, todos los coeficientes son distintos de cero.</p></li>
<li><p>En la práctica, la regresión ridge suele ser la primera opción entre estos dos modelos. Sin embargo, si tiene una gran cantidad de características y espera que sólo unas pocas sean importantes, <code class="docutils literal notranslate"><span class="pre">Lasso</span></code> podría ser una mejor opción. Del mismo modo, si desea tener un modelo que es fácil de interpretar, <code class="docutils literal notranslate"><span class="pre">Lasso</span></code> proporcionará un modelo que es más fácil de entender, ya que seleccionará sólo un subconjunto de las características de entrada. <code class="docutils literal notranslate"><span class="pre">scikit-learn</span></code> también proporciona la clase <code class="docutils literal notranslate"><span class="pre">ElasticNet</span></code>, que combina las penalizaciones de <code class="docutils literal notranslate"><span class="pre">Lasso</span></code> y <code class="docutils literal notranslate"><span class="pre">Ridge</span></code>. En la práctica, esta combinación funciona mejor, aunque al precio de tener dos parámetros que ajustar: uno para la regularización <span class="math notranslate nohighlight">\(L^1\)</span>, y otro para la regularización <span class="math notranslate nohighlight">\(L^2\)</span>.</p></li>
</ul>
</section>
<section id="modelos-lineales-para-clasificacion">
<h3>Modelos lineales para clasificación<a class="headerlink" href="#modelos-lineales-para-clasificacion" title="Permalink to this headline">#</a></h3>
<ul class="simple">
<li><p>Los modelos lineales también se utilizan ampliamente para la clasificación. Veamos primero la clasificación binaria. En este caso, la predicción se realiza mediante la siguiente fórmula</p></li>
</ul>
<div class="math notranslate nohighlight" id="equation-linear-class">
<span class="eqno">(12)<a class="headerlink" href="#equation-linear-class" title="Permalink to this equation">#</a></span>\[
\hat{y}=\beta_{0}+\beta_{1}\cdot x_{1}+\beta_{2}\cdot x_{2}+\cdots+\beta_{p}\cdot x_{p}
\]</div>
<ul class="simple">
<li><p>La fórmula es muy similar a la de la regresión lineal, pero en lugar de devolver simplemente la suma ponderada de las características, ponemos un umbral al valor predicho en cero. Si la función es menor que cero, predecimos la clase -1; si es mayor que cero, predecimos la clase +1. Esta regla de predicción es común a todos los modelos lineales de clasificación. De nuevo, hay muchas formas diferentes de encontrar los coeficientes <span class="math notranslate nohighlight">\(\boldsymbol{\beta}\)</span>.</p></li>
<li><p>En los modelos lineales de regresión, la salida, <span class="math notranslate nohighlight">\(\hat{y}\)</span>, es una función lineal de las características: una <code class="docutils literal notranslate"><span class="pre">línea</span></code>, un <code class="docutils literal notranslate"><span class="pre">plano</span></code> o un <code class="docutils literal notranslate"><span class="pre">hiperplano</span></code>. En los modelos lineales de clasificación, la frontera de decisión es una función lineal de la entrada. En otras palabras, un <code class="docutils literal notranslate"><span class="pre">clasificador</span> <span class="pre">lineal</span> <span class="pre">(binario)</span></code> es un clasificador que separa dos clases utilizando una línea, un plano o un hiperplano.</p></li>
<li><p>Hay muchos algoritmos para aprender modelos lineales. Todos estos algoritmos difieren en los dos aspectos siguientes:</p>
<ul>
<li><p>La forma en que miden que tan bien una combinación particular de coeficientes se ajusta a los datos de entrenamiento.</p></li>
<li><p>Si utilizan regularización, de que tipo utilizan</p></li>
</ul>
</li>
</ul>
<ul class="simple">
<li><p>Los distintos algoritmos eligen diferentes formas de medir lo que significa <code class="docutils literal notranslate"><span class="pre">&quot;ajustarse</span> <span class="pre">bien</span> <span class="pre">al</span> <span class="pre">conjunto</span> <span class="pre">de</span> <span class="pre">entrenamiento&quot;</span></code>. Por razones técnicas matemáticas, no es posible ajustar <span class="math notranslate nohighlight">\(\boldsymbol{\beta}\)</span> para minimizar el número de clasificaciones erróneas que producen los algoritmos, como cabría esperar.</p></li>
<li><p>Los dos algoritmos de clasificación lineal más comunes son la <code class="docutils literal notranslate"><span class="pre">regresión</span> <span class="pre">logística</span></code>, implementada en <code class="docutils literal notranslate"><span class="pre">linear_model.LogisticRegression</span></code>, y las <code class="docutils literal notranslate"><span class="pre">máquinas</span> <span class="pre">de</span> <span class="pre">vectores</span> <span class="pre">de</span> <span class="pre">soporte</span> <span class="pre">lineales</span> <span class="pre">(SVMs</span> <span class="pre">lineales)</span></code>, implementadas en <code class="docutils literal notranslate"><span class="pre">svm.LinearSVC</span> <span class="pre">(SVC</span> <span class="pre">significa</span> <span class="pre">clasificador</span> <span class="pre">de</span> <span class="pre">vectores</span> <span class="pre">de</span> <span class="pre">soporte)</span></code>.</p></li>
<li><p>A pesar de su nombre, <code class="docutils literal notranslate"><span class="pre">LogisticRegression</span></code> es un algoritmo de clasificación y no de regresión, por lo tanto no debe confundirse con <code class="docutils literal notranslate"><span class="pre">LinearRegression</span></code>. Podemos aplicar los modelos <code class="docutils literal notranslate"><span class="pre">LogisticRegression</span></code> y <code class="docutils literal notranslate"><span class="pre">LinearSVC</span></code> al conjunto de datos <code class="docutils literal notranslate"><span class="pre">forge</span></code> y visualizar la forntera de decisión encontrado por los modelos lineales.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LogisticRegression</span>
<span class="kn">from</span> <span class="nn">sklearn.svm</span> <span class="kn">import</span> <span class="n">LinearSVC</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">mglearn</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">make_forge</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>

<span class="k">for</span> <span class="n">model</span><span class="p">,</span> <span class="n">ax</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">([</span><span class="n">LinearSVC</span><span class="p">(),</span> <span class="n">LogisticRegression</span><span class="p">()],</span> <span class="n">axes</span><span class="p">):</span>
    <span class="n">clf</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
    <span class="n">mglearn</span><span class="o">.</span><span class="n">plots</span><span class="o">.</span><span class="n">plot_2d_separator</span><span class="p">(</span><span class="n">clf</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">fill</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">.7</span><span class="p">)</span>
    <span class="n">mglearn</span><span class="o">.</span><span class="n">discrete_scatter</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">y</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;</span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">clf</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="p">))</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;Feature 0&quot;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;Feature 1&quot;</span><span class="p">)</span>
    <span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/supervised_learning_188_0.png" src="_images/supervised_learning_188_0.png" />
</div>
</div>
<ul class="simple">
<li><p>En esta figura, tenemos la primera característica del conjunto de datos <code class="docutils literal notranslate"><span class="pre">forge</span></code> en el eje <span class="math notranslate nohighlight">\(x\)</span> y la segunda característica en el eje <span class="math notranslate nohighlight">\(y\)</span>, como antes. Se muestran las fronteras de decisión encontrados por <code class="docutils literal notranslate"><span class="pre">LinearSVC</span></code> y <code class="docutils literal notranslate"><span class="pre">LogisticRegression</span></code> respectivamente como líneas rectas, separando el área clasificada como clase 1 en la parte superior, del área clasificada como clase 0 en la parte inferior. En otras palabras, cualquier nuevo punto de datos que se encuentre por encima de la línea negra será clasificado como clase 1 por el clasificador respectivo, mientras que cualquier punto que se encuentre por debajo de la línea negra será clasificado como clase 0.</p></li>
<li><p>Los dos modelos entregan fronteras de decisión similares. Obsérvese que ambos clasifican erróneamente dos de los puntos. Por defecto, ambos modelos aplican una regularización <span class="math notranslate nohighlight">\(L^{2}\)</span>, de la misma manera que lo hace <code class="docutils literal notranslate"><span class="pre">Ridge</span></code> para la regresión. Para <code class="docutils literal notranslate"><span class="pre">LogisticRegression</span></code> y <code class="docutils literal notranslate"><span class="pre">LinearSVC</span></code> el parámetro de compensación que determina la fuerza de la regularización se llama <code class="docutils literal notranslate"><span class="pre">C</span></code>, y los valores más altos de <code class="docutils literal notranslate"><span class="pre">C</span></code> corresponden a menor regularización. En otras palabras, cuando se utiliza un valor alto para el parámetro <code class="docutils literal notranslate"><span class="pre">C</span></code>, <code class="docutils literal notranslate"><span class="pre">LogisticRegression</span></code> y <code class="docutils literal notranslate"><span class="pre">LinearSVC</span></code> intentan ajustarse al conjunto de entrenamiento lo mejor posible, mientras que con valores bajos del parámetro <code class="docutils literal notranslate"><span class="pre">C</span></code>, los modelos ponen más énfasis en encontrar un vector de coeficientes <span class="math notranslate nohighlight">\(\boldsymbol{\beta}\)</span> que se acerque a cero.</p></li>
<li><p>Hay otro aspecto interesante de cómo actúa el parámetro <code class="docutils literal notranslate"><span class="pre">C</span></code>. El uso de valores bajos de <code class="docutils literal notranslate"><span class="pre">C</span></code> hará que los algoritmos traten de ajustarse a la “mayoría” de los puntos de datos, mientras que el uso de un valor más alto de <code class="docutils literal notranslate"><span class="pre">C</span></code> enfatiza la importancia de que cada punto de datos individual sea clasificado correctamente. Veamos una ilustración utilizando <code class="docutils literal notranslate"><span class="pre">LinearSVC</span></code></p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">mglearn</span><span class="o">.</span><span class="n">plots</span><span class="o">.</span><span class="n">plot_linear_svc_regularization</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/supervised_learning_190_0.png" src="_images/supervised_learning_190_0.png" />
</div>
</div>
<ul class="simple">
<li><p>En el lado izquierdo, tenemos una <span class="math notranslate nohighlight">\(C\)</span> muy pequeña que corresponde a una gran regularización. La mayoría de los puntos de la clase 0 están en la parte superior, y la mayoría de los puntos de la clase 1 están en la parte inferior. El modelo fuertemente regularizado elige una línea relativamente horizontal, clasificando erróneamente dos puntos.</p></li>
<li><p>En el gráfico central, <span class="math notranslate nohighlight">\(C\)</span> es ligeramente más alto, y el modelo se centra más en las dos muestras mal clasificadas, inclinando el límite de decisión. Por último, en el lado derecho, el valor muy alto de <span class="math notranslate nohighlight">\(C\)</span> en el modelo inclina mucho la frontera de decisión, clasificando ahora correctamente todos los puntos de la clase 0. Uno de los puntos de la clase 1 sigue estando mal clasificado, ya que no es posible clasificar correctamente todos los puntos de este conjunto de datos utilizando una línea recta.</p></li>
<li><p>El modelo ilustrado en la parte derecha se esfuerza por clasificar correctamente todos los puntos, pero puede que no capte bien la disposición general de las clases. En otras palabras, es probable que este modelo presente overfitting. Al igual que en el caso de la regresión, los modelos lineales de clasificación pueden parecer muy restrictivos en espacios de baja dimensión, ya que sólo permiten límites de decisión que sean líneas rectas o planos. De nuevo, en dimensiones altas, los modelos lineales de clasificación se vuelven muy potentes, y la protección contra el overfitting es cada vez más importante cuando se consideran más características.</p></li>
</ul>
<ul class="simple">
<li><p>Analicemos <code class="docutils literal notranslate"><span class="pre">LinearLogistic</span></code> con más detalle en el conjunto de datos del cáncer de mama:</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_breast_cancer</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">cancer</span> <span class="o">=</span> <span class="n">load_breast_cancer</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">cancer</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> 
                                                    <span class="n">cancer</span><span class="o">.</span><span class="n">target</span><span class="p">,</span> 
                                                    <span class="n">stratify</span><span class="o">=</span><span class="n">cancer</span><span class="o">.</span><span class="n">target</span><span class="p">,</span> 
                                                    <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="n">logreg</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">()</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Training set score: </span><span class="si">{:.3f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">logreg</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Test set score: </span><span class="si">{:.3f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">logreg</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Training set score: 0.948
Test set score: 0.958
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>El valor por defecto de <span class="math notranslate nohighlight">\(C=1\)</span> proporciona un rendimiento bastante bueno, con una precisión del 95% tanto en el conjunto de entrenamiento como en el de prueba. Pero como el rendimiento de los conjuntos de entrenamiento y de prueba es muy parecidos, es probable que el ajuste sea insuficiente. Intentemos aumentar <span class="math notranslate nohighlight">\(C\)</span> para ajustar un modelo más flexible:</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">logreg100</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">C</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Training set score: </span><span class="si">{:.3f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">logreg100</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Test set score: </span><span class="si">{:.3f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">logreg100</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Training set score: 0.953
Test set score: 0.965
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>El uso de <span class="math notranslate nohighlight">\(C=100\)</span> da lugar a una mayor precisión en el conjunto de entrenamiento y también a un ligero aumento de la precisión en el conjunto de prueba, lo que confirma nuestra intuición de que un modelo más complejo debería funcionar mejor. También podemos investigar qué ocurre si utilizamos un modelo aún más regularizado que el predeterminado de <span class="math notranslate nohighlight">\(C=1\)</span>, estableciendo <span class="math notranslate nohighlight">\(C=0.01\)</span></p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">logreg001</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">C</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Training set score: </span><span class="si">{:.3f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">logreg001</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Test set score: </span><span class="si">{:.3f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">logreg001</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Training set score: 0.934
Test set score: 0.930
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Como era de esperar, cuando se desplaza más hacia la izquierda en la escala mostrada en la <a class="reference internal" href="#fig-sweet-spot"><span class="std std-numref">Fig. 1</span></a> a partir de un modelo ya subjustado, tanto la precisión del conjunto de entrenamiento como la de la prueba disminuyen en relación con los parámetros por defecto. Por último, veamos los coeficientes aprendidos por los modelos con las tres configuraciones diferentes de los parámetros de regularización <span class="math notranslate nohighlight">\(C\)</span></p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">logreg</span><span class="o">.</span><span class="n">coef_</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="s1">&#39;o&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;C=1&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">logreg100</span><span class="o">.</span><span class="n">coef_</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="s1">&#39;^&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;C=100&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">logreg001</span><span class="o">.</span><span class="n">coef_</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="s1">&#39;v&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;C=0.001&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">cancer</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]),</span> <span class="n">cancer</span><span class="o">.</span><span class="n">feature_names</span><span class="p">,</span> <span class="n">rotation</span><span class="o">=</span><span class="mi">90</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">hlines</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">cancer</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Coefficient index&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Coefficient magnitude&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">();</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/supervised_learning_201_0.png" src="_images/supervised_learning_201_0.png" />
</div>
</div>
<ul class="simple">
<li><p>Si deseamos un modelo más interpretable, el uso de la regularización <span class="math notranslate nohighlight">\(L^{1}\)</span> podría ayudar, ya que limita el modelo a utilizar sólo unas pocas características. El siguiente es el gráfico de coeficientes y las precisiones de clasificación para la regularización <span class="math notranslate nohighlight">\(L^{1}\)</span></p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">C</span><span class="p">,</span> <span class="n">marker</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">([</span><span class="mf">0.001</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">100</span><span class="p">],</span> <span class="p">[</span><span class="s1">&#39;o&#39;</span><span class="p">,</span> <span class="s1">&#39;^&#39;</span><span class="p">,</span> <span class="s1">&#39;v&#39;</span><span class="p">]):</span>
    <span class="n">lr_l1</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">C</span><span class="o">=</span><span class="n">C</span><span class="p">,</span> 
                               <span class="n">penalty</span><span class="o">=</span><span class="s2">&quot;l1&quot;</span><span class="p">,</span> 
                               <span class="n">solver</span><span class="o">=</span><span class="s1">&#39;liblinear&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Training accuracy of l1 logreg with C=</span><span class="si">{:.3f}</span><span class="s2">: </span><span class="si">{:.2f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
        <span class="n">C</span><span class="p">,</span> <span class="n">lr_l1</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)))</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Test accuracy of l1 logreg with C=</span><span class="si">{:.3f}</span><span class="s2">: </span><span class="si">{:.2f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
        <span class="n">C</span><span class="p">,</span> <span class="n">lr_l1</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)))</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">lr_l1</span><span class="o">.</span><span class="n">coef_</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">marker</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;C=</span><span class="si">{:.3f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">C</span><span class="p">))</span>

<span class="n">plt</span><span class="o">.</span><span class="n">xticks</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">cancer</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]),</span> <span class="n">cancer</span><span class="o">.</span><span class="n">feature_names</span><span class="p">,</span> <span class="n">rotation</span><span class="o">=</span><span class="mi">90</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">hlines</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">cancer</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Coefficient index&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Coefficient magnitude&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="mi">3</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Training accuracy of l1 logreg with C=0.001: 0.91
Test accuracy of l1 logreg with C=0.001: 0.92
Training accuracy of l1 logreg with C=1.000: 0.96
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Test accuracy of l1 logreg with C=1.000: 0.96
Training accuracy of l1 logreg with C=100.000: 0.99
Test accuracy of l1 logreg with C=100.000: 0.98
</pre></div>
</div>
<img alt="_images/supervised_learning_203_2.png" src="_images/supervised_learning_203_2.png" />
</div>
</div>
<ul class="simple">
<li><p>Como puede ver, hay muchos paralelismos entre los modelos lineales de clasificación binaria y los modelos lineales de regresión. Como en la regresión, la principal diferencia entre los modelos es el parámetro de penalización, que influye en la regularización, y en si el modelo utilizará todas las características disponibles o seleccionará sólo un subconjunto.</p></li>
</ul>
</section>
<section id="modelos-lineales-para-la-clasificacion-multiclase">
<h3>Modelos lineales para la clasificación multiclase<a class="headerlink" href="#modelos-lineales-para-la-clasificacion-multiclase" title="Permalink to this headline">#</a></h3>
<ul class="simple">
<li><p>Muchos modelos de clasificación lineal sólo sirven para la clasificación binaria y no se extienden de forma natural al caso multiclase (con la excepción de la regresión logística). Una técnica común para extender un algoritmo de clasificación binaria a un <code class="docutils literal notranslate"><span class="pre">algoritmo</span> <span class="pre">de</span> <span class="pre">clasificación</span> <span class="pre">multiclase</span></code> es el enfoque <code class="docutils literal notranslate"><span class="pre">one-vs.-rest</span></code>. En el enfoque <code class="docutils literal notranslate"><span class="pre">one-vs.-rest</span></code>, se aprende un modelo binario, para cada clase que intenta separar esa clase de todas las demás, lo que da lugar a tantos modelos binarios como clases haya. Para hacer una predicción, se ejecutan todos los clasificadores binarios en un punto de prueba. El clasificador que tenga la mayor puntuación en su clase “gana”, y esta etiqueta de clase se devuelve como predicción. - Al tener un clasificador binario por clase, se tiene un vector de coeficientes <span class="math notranslate nohighlight">\(\boldsymbol{\beta}\)</span> para cada clase. La clase para la que el resultado de la fórmula de confianza de clasificación da aquí es la más alta, es la etiqueta de clase asignada:</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
\beta_{0}+\beta_{1}\cdot x_{1}+\beta_{2}\cdot x_{2}+\cdots+\beta_{p}\cdot x_{p}
\]</div>
<ul class="simple">
<li><p>Las matemáticas que subyacen a la regresión logística multiclase difieren en cierta medida del enfoque de una sola clase, pero también dan como resultado un vector de coeficientes y un intercepto por clase, y se aplica el mismo método para hacer una predicción. Apliquemos el método de <code class="docutils literal notranslate"><span class="pre">one-vs.-rest</span></code> a un conjunto de datos de clasificación de tres clases. Utilizamos un conjunto de datos bidimensional, en el que cada clase viene dada por datos muestreados de una distribución gaussiana.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">make_blobs</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">make_blobs</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="n">mglearn</span><span class="o">.</span><span class="n">discrete_scatter</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">y</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Feature 0&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Feature 1&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">([</span><span class="s2">&quot;Class 0&quot;</span><span class="p">,</span> <span class="s2">&quot;Class 1&quot;</span><span class="p">,</span> <span class="s2">&quot;Class 2&quot;</span><span class="p">]);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/supervised_learning_210_0.png" src="_images/supervised_learning_210_0.png" />
</div>
</div>
<ul class="simple">
<li><p>Ahora, entrenamos un clasificador <code class="docutils literal notranslate"><span class="pre">LinearSVC</span></code> en el conjunto de datos</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">linear_svm</span> <span class="o">=</span> <span class="n">LinearSVC</span><span class="p">()</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Coefficient shape: &quot;</span><span class="p">,</span> <span class="n">linear_svm</span><span class="o">.</span><span class="n">coef_</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Intercept shape: &quot;</span><span class="p">,</span> <span class="n">linear_svm</span><span class="o">.</span><span class="n">intercept_</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Coefficient shape:  (3, 2)
Intercept shape:  (3,)
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Vemos que la forma de <code class="docutils literal notranslate"><span class="pre">coef_</span></code> es <code class="docutils literal notranslate"><span class="pre">(3,</span> <span class="pre">2)</span></code>, lo que significa que cada fila de <code class="docutils literal notranslate"><span class="pre">coef_</span></code> contiene el vector de coeficientes para una de las tres clases y cada columna contiene el valor del coeficiente para una característica específica (hay dos en este conjunto de datos). La matriz <code class="docutils literal notranslate"><span class="pre">intercept_</span></code> es ahora una matriz unidimensional que almacena los interceptos de cada clase. Visualicemos las líneas dadas por los tres clasificadores binarios</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">mglearn</span><span class="o">.</span><span class="n">discrete_scatter</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">y</span><span class="p">)</span>
<span class="n">line</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">15</span><span class="p">,</span> <span class="mi">15</span><span class="p">)</span>

<span class="k">for</span> <span class="n">coef</span><span class="p">,</span> <span class="n">intercept</span><span class="p">,</span> <span class="n">color</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">linear_svm</span><span class="o">.</span><span class="n">coef_</span><span class="p">,</span> <span class="n">linear_svm</span><span class="o">.</span><span class="n">intercept_</span><span class="p">,</span> <span class="p">[</span><span class="s1">&#39;b&#39;</span><span class="p">,</span> <span class="s1">&#39;r&#39;</span><span class="p">,</span> <span class="s1">&#39;g&#39;</span><span class="p">]):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">line</span><span class="p">,</span> <span class="o">-</span><span class="p">(</span><span class="n">line</span> <span class="o">*</span> <span class="n">coef</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="n">intercept</span><span class="p">)</span> <span class="o">/</span> <span class="n">coef</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="n">color</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylim</span><span class="p">(</span><span class="o">-</span><span class="mi">10</span><span class="p">,</span> <span class="mi">15</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlim</span><span class="p">(</span><span class="o">-</span><span class="mi">10</span><span class="p">,</span> <span class="mi">8</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Feature 0&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Feature 1&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">([</span><span class="s1">&#39;Class 0&#39;</span><span class="p">,</span> <span class="s1">&#39;Class 1&#39;</span><span class="p">,</span> <span class="s1">&#39;Class 2&#39;</span><span class="p">,</span> <span class="s1">&#39;Line class 0&#39;</span><span class="p">,</span> <span class="s1">&#39;Line class 1&#39;</span><span class="p">,</span> 
                <span class="s1">&#39;Line class 2&#39;</span><span class="p">],</span> <span class="n">loc</span><span class="o">=</span><span class="p">(</span><span class="mf">1.01</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/supervised_learning_214_0.png" src="_images/supervised_learning_214_0.png" />
</div>
</div>
<ul class="simple">
<li><p>Se puede ver que todos los puntos que pertenecen a la clase 0 en los datos de entrenamiento están por encima de la línea correspondiente a la clase 0, lo que significa que están en el lado de la “clase 0” de este clasificador binario. Los puntos de la clase 0 están por encima de la línea correspondiente a la clase 2, lo que significa que son clasificados como “resto” por el clasificador binario de la clase 2. Los puntos que pertenecen a la clase 0 están a la izquierda de la línea correspondiente a la clase 1, lo que significa que el clasificador binario para la clase 1 también los clasifica como “descanso”. Por tanto, cualquier punto de esta zona será clasificado como clase 0 por el clasificador final (el resultado de la fórmula de confianza de la clasificación para el clasificador 0 es mayor que cero, mientras que es menor que cero para las otras dos clases).</p></li>
<li><p>Pero, ¿qué ocurre con el triángulo del centro del gráfico? Los tres clasificadores binarios clasifican los puntos allí como “resto”. ¿A qué clase se asignaría un punto allí? La respuesta La respuesta es la que tiene el valor más alto de la fórmula de clasificación: la clase de la línea más cercana. línea.</p></li>
<li><p>El siguiente ejemplo muestra las predicciones para todas las regiones del espacio 2D de la zona</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">mglearn</span><span class="o">.</span><span class="n">plots</span><span class="o">.</span><span class="n">plot_2d_classification</span><span class="p">(</span><span class="n">linear_svm</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">fill</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">.7</span><span class="p">)</span>
<span class="n">mglearn</span><span class="o">.</span><span class="n">discrete_scatter</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">y</span><span class="p">)</span>
<span class="n">line</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">15</span><span class="p">,</span> <span class="mi">15</span><span class="p">)</span>

<span class="k">for</span> <span class="n">coef</span><span class="p">,</span> <span class="n">intercept</span><span class="p">,</span> <span class="n">color</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">linear_svm</span><span class="o">.</span><span class="n">coef_</span><span class="p">,</span> <span class="n">linear_svm</span><span class="o">.</span><span class="n">intercept_</span><span class="p">,</span> <span class="p">[</span><span class="s1">&#39;b&#39;</span><span class="p">,</span> <span class="s1">&#39;r&#39;</span><span class="p">,</span> <span class="s1">&#39;g&#39;</span><span class="p">]):</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">line</span><span class="p">,</span> <span class="o">-</span><span class="p">(</span><span class="n">line</span> <span class="o">*</span> <span class="n">coef</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="n">intercept</span><span class="p">)</span> <span class="o">/</span> <span class="n">coef</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="n">color</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">([</span><span class="s1">&#39;Class 0&#39;</span><span class="p">,</span> <span class="s1">&#39;Class 1&#39;</span><span class="p">,</span> <span class="s1">&#39;Class 2&#39;</span><span class="p">,</span> <span class="s1">&#39;Line class 0&#39;</span><span class="p">,</span> <span class="s1">&#39;Line class 1&#39;</span><span class="p">,</span>
                <span class="s1">&#39;Line class 2&#39;</span><span class="p">],</span> <span class="n">loc</span><span class="o">=</span><span class="p">(</span><span class="mf">1.01</span><span class="p">,</span> <span class="mf">0.3</span><span class="p">))</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Feature 0&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Feature 1&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/supervised_learning_216_0.png" src="_images/supervised_learning_216_0.png" />
</div>
</div>
</section>
<section id="id2">
<h3>Puntos fuertes, puntos débiles y parámetros<a class="headerlink" href="#id2" title="Permalink to this headline">#</a></h3>
<ul class="simple">
<li><p>El parámetro principal de los modelos lineales es el parámetro de regularización, llamado <code class="docutils literal notranslate"><span class="pre">alpha</span></code> en los modelos de regresión y <code class="docutils literal notranslate"><span class="pre">C</span></code> en <code class="docutils literal notranslate"><span class="pre">LinearSVC</span></code> y <code class="docutils literal notranslate"><span class="pre">LogisticRegression</span></code>. Los valores grandes de <code class="docutils literal notranslate"><span class="pre">alpha</span></code> o valores pequeños de <code class="docutils literal notranslate"><span class="pre">C</span></code> significan modelos simples. En particular, para los modelos de regresión, el ajuste de estos parámetros es bastante importante. Normalmente, <code class="docutils literal notranslate"><span class="pre">C</span></code> y <code class="docutils literal notranslate"><span class="pre">alpha</span></code> se buscan en una escala logarítmica.</p></li>
<li><p>La otra decisión que hay que tomar es si se quiere utilizar la regularización <span class="math notranslate nohighlight">\(L^1\)</span> o la regularización <span class="math notranslate nohighlight">\(L^2\)</span>. Si se supone que sólo unas pocas características son realmente importantes, se debería utilizar la regularización <span class="math notranslate nohighlight">\(L^1\)</span>, de lo contrario, debería utilizar <span class="math notranslate nohighlight">\(L^2\)</span> por defecto. <span class="math notranslate nohighlight">\(L^1\)</span> también puede ser útil si la interpretabilidad del modelo es importante. Como <span class="math notranslate nohighlight">\(L^1\)</span> utilizará sólo unas pocas características, es más fácil explicar qué características son importantes para el modelo, y cuáles son los efectos de esas características.</p></li>
<li><p>Los modelos lineales son muy rápidos de entrenar y de predecir. Se adaptan a conjuntos de datos muy grandes y funcionan bien con datos dispersos. Si sus datos constan de cientos de miles o millones de muestras, es posible que desee investigar el uso de la opción <code class="docutils literal notranslate"><span class="pre">solver='sag'</span></code> en <code class="docutils literal notranslate"><span class="pre">LogisticRegression</span></code> y <code class="docutils literal notranslate"><span class="pre">Ridge</span></code>, que puede ser más rápida que la predeterminada en grandes conjuntos de datos. Otras opciones son la clase <code class="docutils literal notranslate"><span class="pre">SGDClassifier</span></code> y la clase <code class="docutils literal notranslate"><span class="pre">SGDRegressor</span></code> que implementan versiones aún más escalables de los modelos lineales descritos aquí.</p></li>
<li><p>Otro punto fuerte de los modelos lineales es que permiten entender con relativa facilidad cómo se hace una predicción, utilizando las fórmulas que vimos antes para la regresión y la clasificación. Por desgracia, a menudo, no está del todo claro por qué los coeficientes son como son. Esto es particularmente cierto si su conjunto de datos tiene características altamente correlacionadas; en estos casos, los coeficientes pueden ser difíciles de interpretar.</p></li>
<li><p>Los modelos lineales suelen funcionar bien cuando el número de características es grande en comparación con el número de muestras. También se utilizan a menudo en conjuntos de datos muy grandes, simplemente porque no es factible entrenar otros modelos. Sin embargo, en espacios de menor dimensión otros modelos pueden ofrecer un mejor rendimiento de generalización. Veremos algunos ejemplos en los que los modelos lineales fallan cuando abordemos <strong><code class="docutils literal notranslate"><span class="pre">Máquinas</span> <span class="pre">de</span> <span class="pre">vectores</span> <span class="pre">de</span> <span class="pre">soporte</span> <span class="pre">kernelizadas</span></code></strong></p></li>
</ul>
</section>
</section>
<section id="clasificadores-naive-bayes">
<h2>Clasificadores Naive Bayes<a class="headerlink" href="#clasificadores-naive-bayes" title="Permalink to this headline">#</a></h2>
<p><strong><code class="docutils literal notranslate"><span class="pre">Observación</span></code></strong></p>
<ul class="simple">
<li><p>Los <code class="docutils literal notranslate"><span class="pre">clasificadores</span> <span class="pre">Naive</span> <span class="pre">Bayes</span></code> son una familia de clasificadores que son bastante similares a los modelos lineales discutidos en la sección anterior. Sin embargo, tienden a ser incluso más rápidos en entrenamiento. El precio que se paga por esta eficiencia es que los modelos de Naive Bayes suelen proporcionar rendimiento de generalización que es ligeramente peor que el de los clasificadores lineales como <code class="docutils literal notranslate"><span class="pre">LogisticRegression</span></code> y <code class="docutils literal notranslate"><span class="pre">LinearSVC</span></code>.</p></li>
<li><p>La razón por la que los modelos de Naive Bayes son tan eficientes es que aprenden los parámetros observando cada característica individualmente y recogen estadísticas simples por clase de cada característica. Hay tres tipos de clasificadores Naive Bayes implementados en <code class="docutils literal notranslate"><span class="pre">scikit-learn</span></code>: <code class="docutils literal notranslate"><span class="pre">GaussianNB</span></code>, <code class="docutils literal notranslate"><span class="pre">BernoulliNB</span></code>, y <code class="docutils literal notranslate"><span class="pre">MultinomialNB</span></code>. <code class="docutils literal notranslate"><span class="pre">GaussianNB</span></code> puede aplicarse a cualquier dato continuo, mientras que <code class="docutils literal notranslate"><span class="pre">BernoulliNB</span></code> asume datos binarios y <code class="docutils literal notranslate"><span class="pre">MultinomialNB</span></code> supone datos de recuento (es decir, que cada característica representa un recuento entero, como por ejemplo la frecuencia de aparición de una palabra). <code class="docutils literal notranslate"><span class="pre">BernoulliNB</span></code> y <code class="docutils literal notranslate"><span class="pre">MultinomialNB</span></code> se utilizan sobre todo en la clasificación de datos de texto. El clasificador <code class="docutils literal notranslate"><span class="pre">BernoulliNB</span></code> cuenta la frecuencia con la que cada característica de cada clase es distinta de cero.</p></li>
</ul>
<p><strong><code class="docutils literal notranslate"><span class="pre">Formulación</span></code></strong></p>
<p>En la clasificación mediante el <code class="docutils literal notranslate"><span class="pre">enfoque</span> <span class="pre">bayesiano</span></code>, el concepto básico está plasmado en el <code class="docutils literal notranslate"><span class="pre">Teorema</span> <span class="pre">de</span> <span class="pre">Bayes</span></code>. Como ejemplo, supongamos que hemos observado la aparición de un síntoma en un determinado paciente en forma de fiebre y necesitamos evaluar si ha sido causado por un resfriado o por la inﬂuenza. Si la probabilidad de que un resfriado sea la causa de la fiebre es mayor que la de la inﬂuenza, entonces podemos atribuir, al menos tentativamente, la fiebre de este paciente a un resfriado. Este es el concepto subyacente de la <code class="docutils literal notranslate"><span class="pre">clasificación</span> <span class="pre">de</span> <span class="pre">Bayes</span></code>. El <code class="docutils literal notranslate"><span class="pre">Teorema</span> <span class="pre">de</span> <span class="pre">Bayes</span></code> da la relación entre la probabilidad condicional de un evento basado en la información adquirida, que en este caso puede describirse descrito de la siguiente manera</p>
<p>En primer lugar, denotamos la probabilidad de fiebre (<span class="math notranslate nohighlight">\(D\)</span>) como síntoma de un resfriado (<span class="math notranslate nohighlight">\(G1\)</span> ) y de la inﬂuenza (<span class="math notranslate nohighlight">\(G2\)</span>) por</p>
<div class="math notranslate nohighlight">
\[
P(D|G_{1})=\frac{D\cap G_{1}}{P(G_{1})},\quad P(D|G_{2})=\frac{D\cap G_{2}}{P(G_{2})},
\]</div>
<p>respectivamente. <span class="math notranslate nohighlight">\(P(D|G_{1})\)</span> y <span class="math notranslate nohighlight">\(P(D|G_{2})\)</span> representan las probabilidades de que la fiebre sea el resultado de un resfriado y de la inﬂuenza, respectivamente, y se denominan probabilidades condicionales. Aquí, <span class="math notranslate nohighlight">\(P(G_{1})\)</span> y <span class="math notranslate nohighlight">\(P(G_{2})\)</span> <span class="math notranslate nohighlight">\((P(G_{1})+P(G_{2}) =
1)\)</span>, son las incidencias relativas de los resfriados y la inﬂuenza, y se denominan probabilidades a priori. Se supone que estas probabilidades condicionales y a priori pueden estimarse a partir de las observaciones y de la información acumulada. Entonces la probabilidad <span class="math notranslate nohighlight">\(P(D)\)</span> viene dada por</p>
<div class="math notranslate nohighlight" id="equation-eq-prob-total">
<span class="eqno">(13)<a class="headerlink" href="#equation-eq-prob-total" title="Permalink to this equation">#</a></span>\[
P(D)=P(G_{1})P(D|G_{1})+P(G_{1})P(D|G_{2}),
\]</div>
<p>la probabilidad de que la fiebre sea el resultado de un resfriado o de la inﬂuenza, llamada la ley de la probabilidad total.</p>
<p>En nuestro ejemplo, queremos conocer las probabilidades de que la fiebre que se ha producido, haya sido causada por un resfriado o por la inﬂuenza, respectivamente, representadas por las probabilidades condicionales <span class="math notranslate nohighlight">\(P(G_{1}|D)\)</span> y <span class="math notranslate nohighlight">\(P(G_{2}|D)\)</span>. El teorema de Bayes proporciona estas probabilidades sobre la base de las probabilidades concocidas a priori <span class="math notranslate nohighlight">\(P(G_{i})\)</span> y las probabilidades condicionales <span class="math notranslate nohighlight">\(P(D|G_{i})\)</span>. Es decir, las probabilidades condicionales condicionales <span class="math notranslate nohighlight">\(P(G_{i}|D)\)</span> vienen dadas por</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align*}
P(G_{i}|D)&amp;=\frac{P(G_{i}\cap D)}{P(D)}\\
&amp;=\frac{P(G_{i})P(D|G_{i})}{P(G_{1})P(D|G_{1})+P(G_{1})P(D|G_{2})},\quad i=1,2,
\end{align*}
\end{split}\]</div>
<p>donde <span class="math notranslate nohighlight">\(P(D)\)</span> es la probabilidad total Ecuación <a class="reference internal" href="#equation-eq-prob-total">(13)</a>. Tras la aparición del resultado <span class="math notranslate nohighlight">\(D\)</span>, las probabilidades condicionales <span class="math notranslate nohighlight">\(P(G_{i}|D)\)</span> se convierten en probabilidades posteriores. En general, el <code class="docutils literal notranslate"><span class="pre">teorema</span> <span class="pre">de</span> <span class="pre">Bayes</span></code> se formula como sigue.</p>
<p><strong><code class="docutils literal notranslate"><span class="pre">Teorema</span> <span class="pre">de</span> <span class="pre">Bayes</span></code></strong> Suponga que el espacio muestral <span class="math notranslate nohighlight">\(\Omega\)</span> es divido en <span class="math notranslate nohighlight">\(r\)</span> eventos mutualmente disyuntos <span class="math notranslate nohighlight">\(G_{j}\)</span> como <span class="math notranslate nohighlight">\(\Omega=G_{1}\cup G_{2}\cup\cdots\cup G_{r}~(G_{i}\cap G_{j}=\emptyset)\)</span>. Entonces, para cualquier evento <span class="math notranslate nohighlight">\(D\)</span>, la probabilidad condicional <span class="math notranslate nohighlight">\(P(G_{i}|D)\)</span> esta dada por</p>
<div class="math notranslate nohighlight" id="equation-eq-bayes-theorem">
<span class="eqno">(14)<a class="headerlink" href="#equation-eq-bayes-theorem" title="Permalink to this equation">#</a></span>\[
P(G_{i}|D)=\frac{P(G_{i}\cap D)}{P(D)}=\frac{P(G_{i})P(D|G_{i})}{\displaystyle{\sum_{j=1}^{r}P(G_{j})P(D|G_{j})}},~i=1,2,\dots,r,\text{donde}~ \displaystyle{\sum_{j=1}^{r}P(G_{j})=1}.
\]</div>
<p>En esta sección, el propósito es realizar la clasificación para la asignación de clases de datos <span class="math notranslate nohighlight">\(p\)</span>-dimensionales recién observados, basándose en la probabilidad posterior de su pertenencia a cada clase. Discutimos la aplicación del teorema de Bayes y la expresión de la probabilidad posterior mediante un modelo de de probabilidad, y el método de formulación de los <code class="docutils literal notranslate"><span class="pre">análisis</span> <span class="pre">discriminantes</span> <span class="pre">y</span> <span class="pre">cuadrático</span></code>, para la asignación de clases.</p>
<p><strong><code class="docutils literal notranslate"><span class="pre">Distribuciones</span> <span class="pre">de</span> <span class="pre">probabilidad</span> <span class="pre">y</span> <span class="pre">verosimilitud</span></code></strong> Supongamos que tenemos <span class="math notranslate nohighlight">\(n_{1}\)</span> datos <span class="math notranslate nohighlight">\(p\)</span>-dimensionales de la clase <span class="math notranslate nohighlight">\(G_{1}\)</span> y <span class="math notranslate nohighlight">\(n_{2}\)</span> datos <span class="math notranslate nohighlight">\(p\)</span>-dimensionales de la clase <span class="math notranslate nohighlight">\(G_{2}\)</span>, y representamos el total <span class="math notranslate nohighlight">\(n=(n_{1}+n_{2})\)</span> datos de entrenamiento como</p>
<div class="math notranslate nohighlight">
\[
G_{1}:~\boldsymbol{x}_{1}^{(1)}, \boldsymbol{x}_{2}^{(1)},\dots, \boldsymbol{x}_{n_{1}}^{(1)},\quad G_{2}:~\boldsymbol{x}_{1}^{(2)}, \boldsymbol{x}_{2}^{(2)},\dots, \boldsymbol{x}_{n_{2}}^{(2)}
\]</div>
<p>Supongamos que los datos de entrenamiento para las clases <span class="math notranslate nohighlight">\(G_{i}~(i=1,2)\)</span> han sido observados de acuerdo a una distribución normal <span class="math notranslate nohighlight">\(p\)</span>-dimensional <span class="math notranslate nohighlight">\(N_{p}(\boldsymbol{\mu}_{i},\Sigma_{i})\)</span> con vector de medias <span class="math notranslate nohighlight">\(\boldsymbol{\mu}_{i}\)</span> y matrices de varianza-covarianza <span class="math notranslate nohighlight">\(\Sigma_{i}\)</span> como sigue:</p>
<div class="math notranslate nohighlight" id="equation-eq-mean-cov-bayes">
<span class="eqno">(15)<a class="headerlink" href="#equation-eq-mean-cov-bayes" title="Permalink to this equation">#</a></span>\[\begin{split}
\begin{align*}
G_{1}&amp;: N_{p}(\boldsymbol{\mu}_{1}^{(1)}, \Sigma_{1})\sim\boldsymbol{x}_{1}^{(1)},\boldsymbol{x}_{2}^{(1)},\dots, \boldsymbol{x}_{n_{1}}^{(1)},\\
G_{2}&amp;: N_{p}(\boldsymbol{\mu}_{1}^{(2)}, \Sigma_{1})\sim\boldsymbol{x}_{1}^{(1)},\boldsymbol{x}_{2}^{(1)},\dots, \boldsymbol{x}_{n_{1}}^{(1)}.
\end{align*}
\end{split}\]</div>
<p>Dado este tipo de modelo de distribución de probabilidad, entonces, si suponemos que cierto dato <span class="math notranslate nohighlight">\(\boldsymbol{x}_{0}\)</span> pertenece a la clase <span class="math notranslate nohighlight">\(G_{1}\)</span> o <span class="math notranslate nohighlight">\(G_{2}\)</span>, el nivel relativo de ocurrencia de ese dato en cada clase (la <code class="docutils literal notranslate"><span class="pre">verosimilitud</span></code> o grado de certeza) puede ser cuantificado como <span class="math notranslate nohighlight">\(f(\boldsymbol{x}_{0}|\boldsymbol{\mu}_{i},\Sigma_{i})\)</span>, usando la distribución normal <span class="math notranslate nohighlight">\(p\)</span>-dimensional. Esta corresponde a la probabilidad condicional <span class="math notranslate nohighlight">\(P(D|G_{i})\)</span> descrita por el <code class="docutils literal notranslate"><span class="pre">teorema</span> <span class="pre">de</span> <span class="pre">Bayes</span></code> y puede ser denominada la <code class="docutils literal notranslate"><span class="pre">verosimilitud</span> <span class="pre">(likelihood)</span></code> del dato <span class="math notranslate nohighlight">\(\boldsymbol{x}_{0}\)</span>.</p>
<p>Por ejemplo, consideremos una observación, extraida de una distribución normal <span class="math notranslate nohighlight">\(N(170, 6^2)\)</span> asociada con alturas de hombres. Entonces, usando la función de densidad de probabilidad, el nivel relativo de ocurrencia de hombres de 178 cm de altura, puede ser determinado como <span class="math notranslate nohighlight">\(f(178|170, 6^2)\)</span> (ver <a class="reference internal" href="#fig-heights-bayes"><span class="std std-numref">Fig. 3</span></a>).</p>
<figure class="align-center" id="fig-heights-bayes">
<a class="reference internal image-reference" href="_images/heights_bayes.png"><img alt="_images/heights_bayes.png" src="_images/heights_bayes.png" style="width: 405.20000000000005px; height: 310.8px;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 3 </span><span class="caption-text">Verosimilitud de los datos: El nivel relativo de ocurrencia de hombres de 178 cm de altura puede ser determinado como <span class="math notranslate nohighlight">\(f(178|170, 6^{2})\)</span></span><a class="headerlink" href="#fig-heights-bayes" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<p>Para obtener los datos de verosimilitud, reemplazamos los parametros desconocidos, <span class="math notranslate nohighlight">\(\boldsymbol{\mu}_{i}\)</span> y <span class="math notranslate nohighlight">\(\Sigma_{i}\)</span> en (<a class="reference internal" href="#equation-eq-mean-cov-bayes">(15)</a>) con sus respectivas estimaciones de máxima verosimilitud</p>
<div class="math notranslate nohighlight">
\[
\overline{\boldsymbol{x}}_{i}=\frac{1}{n_{i}}\sum_{j=1}^{n_{i}}\boldsymbol{x}_{j}^{(i)},\quad
S_{i}=\frac{1}{n_{i}}\sum_{j=1}^{n_{i}}(\boldsymbol{x}_{j}^{(i)}-\overline{\boldsymbol{x}}_{i})(\boldsymbol{x}_{j}^{(i)}-\overline{\boldsymbol{x}}_{i})^{T},\quad i=1,2,
\]</div>
<p>respectivamente. Aplicando el teorema de Bayes y utilizando la probabilidad posterior, expresada como una distribución de probabilidad, formulamos la clasificación Bayesiana y derivamos las funciones de discriminación cuadrática y lineal, para la asignación de clases.</p>
<p><strong><code class="docutils literal notranslate"><span class="pre">Funciones</span> <span class="pre">discriminantes</span></code></strong> El proposito esencial del análisis discriminante es construir una regla de clasificación basada en datos de entranamiento, y predecir la pertenencia de datos futuros <span class="math notranslate nohighlight">\(\boldsymbol{x}\)</span> a dos o mas clases predeterminadas. Pongamos ahora esto en un marco bayesiano considerando las dos clases <span class="math notranslate nohighlight">\(G_{1}\)</span> y <span class="math notranslate nohighlight">\(G_{2}\)</span>. Nuestro objetivo es obtener la probabilidad posterior <span class="math notranslate nohighlight">\(P(G_{i}|D) = P(G_{i}|x)\)</span> cuando el dato <span class="math notranslate nohighlight">\(D = \{x\}\)</span> es observado. Para ello, aplicamos el teorema de Bayes para para obtener la probabilidad posterior, y asignamos los datos futuros <span class="math notranslate nohighlight">\(x\)</span> a la clase con la probabilidad más alta. Así, realizamos una <code class="docutils literal notranslate"><span class="pre">clasificación</span> <span class="pre">bayesiana</span></code> basada en la razón de las probabilidades posteriores</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\frac{P(G_{1}|\boldsymbol{x})}{P(G_{2}|\boldsymbol{x})}\quad
\begin{cases}
\geq 1 &amp; \Rightarrow~\boldsymbol{x}\in G_{1}\\
&lt; 1 &amp; \Rightarrow~\boldsymbol{x}\in G_{2}.
\end{cases}
\end{split}\]</div>
<p>Tomando logaritmo en ambos lados obtenemos</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\log\frac{P(G_{1}|\boldsymbol{x})}{P(G_{2}|\boldsymbol{x})}\quad
\begin{cases}
\geq 0 &amp; \Rightarrow~\boldsymbol{x}\in G_{1}\\
&lt; 0 &amp; \Rightarrow~\boldsymbol{x}\in G_{2}.
\end{cases}
\end{split}\]</div>
<p>Por el teorema de Bayes (<a class="reference internal" href="#equation-eq-bayes-theorem">(14)</a>), las probabilidades posteriores están dadas por</p>
<div class="math notranslate nohighlight" id="equation-eq-bayes-normal">
<span class="eqno">(16)<a class="headerlink" href="#equation-eq-bayes-normal" title="Permalink to this equation">#</a></span>\[
P(G_{i}|\boldsymbol{x})=\frac{P(G_{i})P(\boldsymbol{x}|G_{i})}{P(G_{1})P(\boldsymbol{x}|G_{1})+P(G_{1})P(\boldsymbol{x}|G_{2})},\quad i=1,2.
\]</div>
<p>Usando las distribuciones normales <span class="math notranslate nohighlight">\(p\)</span>-dimensionales estimadas <span class="math notranslate nohighlight">\(f(\boldsymbol{x}|\overline{\boldsymbol{x}}_{i}, S_{i})~(i=1,2)\)</span>, la probabilidad condicional puede ser escrita como</p>
<div class="math notranslate nohighlight">
\[
P(\boldsymbol{x}|G_{i})=\frac{f(\boldsymbol{x}|\overline{\boldsymbol{x}}_{i}, S_{i})}{f(\boldsymbol{x}|\overline{\boldsymbol{x}}_{1}, S_{1})+f(\boldsymbol{x}|\overline{\boldsymbol{x}}_{2}, S_{2})},\quad i=1,2,
\]</div>
<p>(ver <a class="reference internal" href="#fig-bayes-normal"><span class="std std-numref">Fig. 4</span></a>) representación del nivel relativo de ocurrencia.</p>
<figure class="align-center" id="fig-bayes-normal">
<a class="reference internal image-reference" href="_images/bayes_normal.png"><img alt="_images/bayes_normal.png" src="_images/bayes_normal.png" style="width: 394.0px; height: 303.6px;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 4 </span><span class="caption-text">Probabilidad <span class="math notranslate nohighlight">\(P(\boldsymbol{x}|G_{i})\)</span> para el nivel relativo de ocurrencia del dato <span class="math notranslate nohighlight">\(\boldsymbol{x}\)</span> en cada clase.</span><a class="headerlink" href="#fig-bayes-normal" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<p>Sustituyendo estas ecuaciones en <a class="reference internal" href="#equation-eq-bayes-normal">(16)</a>, el radio de probabilidades posteriores es expresado como</p>
<div class="math notranslate nohighlight">
\[
\frac{P(G_{1}|\boldsymbol{x})}{P(G_{2}|\boldsymbol{x})}=
\frac{P(G_{1})P(\boldsymbol{x}|G_{1})}{P(G_{2})P(\boldsymbol{x}|G_{2})}=
\frac{P(G_{1})f(\boldsymbol{x}|\overline{\boldsymbol{x}}_{1}, S_{1})}{P(G_{2})f(\boldsymbol{x}|\overline{\boldsymbol{x}}_{2}, S_{2})}
\]</div>
<p>Tomando el logaritmo de esta expresión, bajo el supuesto de que las probabilidades a priori son iguales, obtenemos la clasificación Bayesiana basada en la distribución de probabilidad</p>
<div class="math notranslate nohighlight" id="equation-bayes-class-rule">
<span class="eqno">(17)<a class="headerlink" href="#equation-bayes-class-rule" title="Permalink to this equation">#</a></span>\[\begin{split}
h(\boldsymbol{x})=\log\frac{f(\boldsymbol{x}|\overline{\boldsymbol{x}}_{1}, S_{1})}{f(\boldsymbol{x}|\overline{\boldsymbol{x}}_{2}, S_{2})}\quad
\begin{cases}
\geq 0 &amp;\Rightarrow~\boldsymbol{x}\in G_{1}\\
&lt; 0 &amp;\Rightarrow~\boldsymbol{x}\in G_{2}
\end{cases}
\end{split}\]</div>
<p>La función discriminante <span class="math notranslate nohighlight">\(h(\boldsymbol{x})\)</span> con la distribución normal <span class="math notranslate nohighlight">\(p\)</span>-dimensional estimada <span class="math notranslate nohighlight">\(N_{p}(\overline{\boldsymbol{x}}_{i}, S_{i})~(i=1,2)\)</span> esta dado por</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align}
h(\boldsymbol{x})&amp;=\log f(\boldsymbol{x}|\overline{\boldsymbol{x}}_{1}, S_{1})-\log f(\boldsymbol{x}|\overline{\boldsymbol{x}}_{2}, S_{2})\\
&amp;=\frac{1}{2}\left\{(\boldsymbol{x}-\boldsymbol{x}_{2})^{T}S_{2}^{-1}(\boldsymbol{x}-\overline{\boldsymbol{x}}_{2})-(\boldsymbol{x}-\boldsymbol{x}_{1})^{T}S_{1}^{-1}(\boldsymbol{x}-\overline{\boldsymbol{x}}_{1})-\log\left(\frac{|S_{1}|}{|S_{2}|}\right)\right\},
\end{align}
\end{split}\]</div>
<p>conocida como <code class="docutils literal notranslate"><span class="pre">función</span> <span class="pre">discriminante</span> <span class="pre">cuadratica</span></code>. Reemplazando <span class="math notranslate nohighlight">\(S_{i}\)</span> con la matriz de varianza-covarianza de la muestra conjunta <span class="math notranslate nohighlight">\(S=(n_{1}S_{1}+n_{2}S_{2})/(n_{1}+n_{2})\)</span>, la función discriminante es además reducida a la <code class="docutils literal notranslate"><span class="pre">función</span> <span class="pre">discriminante</span> <span class="pre">lineal</span></code></p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align}
h(\boldsymbol{x})&amp;=(\boldsymbol{x}-\boldsymbol{x}_{2})^{T}S^{-1}(\boldsymbol{x}-\overline{\boldsymbol{x}}_{2})-(\boldsymbol{x}-\boldsymbol{x}_{1})^{T}S^{-1}(\boldsymbol{x}-\overline{\boldsymbol{x}}_{1})\\
&amp;=(\boldsymbol{x}-\boldsymbol{x}_{2})^{T}S^{-1}\boldsymbol{x}-\frac{1}{2}(\overline{\boldsymbol{x}}_{1}^{T}S^{-1}\overline{\boldsymbol{x}}_{1}-\overline{\boldsymbol{x}}_{2}^{T}S^{-1}\overline{\boldsymbol{x}}_{2})
\end{align}
\end{split}\]</div>
<p>Obtenemos la regla de clasificación de Bayes <a class="reference internal" href="#equation-bayes-class-rule">(17)</a> basada en el signo del logaritmo de la razón entre la distribución de probabilidad estimada que caracteriza la clase. la función <span class="math notranslate nohighlight">\(h(\boldsymbol{x})\)</span> expresada por la distribución normal <span class="math notranslate nohighlight">\(p\)</span>-dimensional entrega las funciones discriminantes lineales y cuadraticas.</p>
<p><strong><code class="docutils literal notranslate"><span class="pre">Aplicación</span></code></strong></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">sklearn.naive_bayes</span> <span class="kn">import</span> <span class="n">GaussianNB</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">accuracy_score</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">raw_data</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;./data/titanic.csv&#39;</span><span class="p">)</span>
<span class="n">raw_data</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>PassengerId</th>
      <th>Survived</th>
      <th>Pclass</th>
      <th>Name</th>
      <th>Sex</th>
      <th>Age</th>
      <th>SibSp</th>
      <th>Parch</th>
      <th>Ticket</th>
      <th>Fare</th>
      <th>Cabin</th>
      <th>Embarked</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>0</td>
      <td>3</td>
      <td>Braund, Mr. Owen Harris</td>
      <td>male</td>
      <td>22.0</td>
      <td>1</td>
      <td>0</td>
      <td>A/5 21171</td>
      <td>7.2500</td>
      <td>NaN</td>
      <td>S</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2</td>
      <td>1</td>
      <td>1</td>
      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>
      <td>female</td>
      <td>38.0</td>
      <td>1</td>
      <td>0</td>
      <td>PC 17599</td>
      <td>71.2833</td>
      <td>C85</td>
      <td>C</td>
    </tr>
    <tr>
      <th>2</th>
      <td>3</td>
      <td>1</td>
      <td>3</td>
      <td>Heikkinen, Miss. Laina</td>
      <td>female</td>
      <td>26.0</td>
      <td>0</td>
      <td>0</td>
      <td>STON/O2. 3101282</td>
      <td>7.9250</td>
      <td>NaN</td>
      <td>S</td>
    </tr>
    <tr>
      <th>3</th>
      <td>4</td>
      <td>1</td>
      <td>1</td>
      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>
      <td>female</td>
      <td>35.0</td>
      <td>1</td>
      <td>0</td>
      <td>113803</td>
      <td>53.1000</td>
      <td>C123</td>
      <td>S</td>
    </tr>
    <tr>
      <th>4</th>
      <td>5</td>
      <td>0</td>
      <td>3</td>
      <td>Allen, Mr. William Henry</td>
      <td>male</td>
      <td>35.0</td>
      <td>0</td>
      <td>0</td>
      <td>373450</td>
      <td>8.0500</td>
      <td>NaN</td>
      <td>S</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<ul class="simple">
<li><p>Eliminamos columnas innecesarias para nuestro ejemplo de clasificación</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">data</span> <span class="o">=</span> <span class="n">raw_data</span><span class="o">.</span><span class="n">drop</span><span class="p">([</span><span class="s1">&#39;PassengerId&#39;</span><span class="p">,</span><span class="s1">&#39;Name&#39;</span><span class="p">,</span><span class="s1">&#39;SibSp&#39;</span><span class="p">,</span><span class="s1">&#39;Parch&#39;</span><span class="p">,</span><span class="s1">&#39;Ticket&#39;</span><span class="p">,</span><span class="s1">&#39;Cabin&#39;</span><span class="p">,</span><span class="s1">&#39;Embarked&#39;</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="s1">&#39;columns&#39;</span><span class="p">)</span>
<span class="n">data</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Survived</th>
      <th>Pclass</th>
      <th>Sex</th>
      <th>Age</th>
      <th>Fare</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0</td>
      <td>3</td>
      <td>male</td>
      <td>22.0</td>
      <td>7.2500</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1</td>
      <td>1</td>
      <td>female</td>
      <td>38.0</td>
      <td>71.2833</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1</td>
      <td>3</td>
      <td>female</td>
      <td>26.0</td>
      <td>7.9250</td>
    </tr>
    <tr>
      <th>3</th>
      <td>1</td>
      <td>1</td>
      <td>female</td>
      <td>35.0</td>
      <td>53.1000</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0</td>
      <td>3</td>
      <td>male</td>
      <td>35.0</td>
      <td>8.0500</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>Identificamos si existen datos faltantes o nulos para luego eliminarlos</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">data</span><span class="o">.</span><span class="n">isnull</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Survived      0
Pclass        0
Sex           0
Age         177
Fare          0
dtype: int64
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">data_new</span> <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">dropna</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">data_new</span><span class="o">.</span><span class="n">isnull</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Survived    0
Pclass      0
Sex         0
Age         0
Fare        0
dtype: int64
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">data_new</span><span class="o">.</span><span class="n">describe</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Survived</th>
      <th>Pclass</th>
      <th>Age</th>
      <th>Fare</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>714.000000</td>
      <td>714.000000</td>
      <td>714.000000</td>
      <td>714.000000</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>0.406162</td>
      <td>2.236695</td>
      <td>29.699118</td>
      <td>34.694514</td>
    </tr>
    <tr>
      <th>std</th>
      <td>0.491460</td>
      <td>0.838250</td>
      <td>14.526497</td>
      <td>52.918930</td>
    </tr>
    <tr>
      <th>min</th>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>0.420000</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>25%</th>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>20.125000</td>
      <td>8.050000</td>
    </tr>
    <tr>
      <th>50%</th>
      <td>0.000000</td>
      <td>2.000000</td>
      <td>28.000000</td>
      <td>15.741700</td>
    </tr>
    <tr>
      <th>75%</th>
      <td>1.000000</td>
      <td>3.000000</td>
      <td>38.000000</td>
      <td>33.375000</td>
    </tr>
    <tr>
      <th>max</th>
      <td>1.000000</td>
      <td>3.000000</td>
      <td>80.000000</td>
      <td>512.329200</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>Convertimos a valores numéricos, los valores categóricos en la columna <code class="docutils literal notranslate"><span class="pre">Sex</span></code></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">data_dumms</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">get_dummies</span><span class="p">(</span><span class="n">data_new</span><span class="p">,</span> <span class="n">drop_first</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">data_dumms</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Survived</th>
      <th>Pclass</th>
      <th>Age</th>
      <th>Fare</th>
      <th>Sex_male</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0</td>
      <td>3</td>
      <td>22.0</td>
      <td>7.2500</td>
      <td>1</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1</td>
      <td>1</td>
      <td>38.0</td>
      <td>71.2833</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1</td>
      <td>3</td>
      <td>26.0</td>
      <td>7.9250</td>
      <td>0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>1</td>
      <td>1</td>
      <td>35.0</td>
      <td>53.1000</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0</td>
      <td>3</td>
      <td>35.0</td>
      <td>8.0500</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>Calculamos la <code class="docutils literal notranslate"><span class="pre">matriz</span> <span class="pre">de</span> <span class="pre">correlación</span></code> para medir relaciones lineales entre las variables</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">corr_matrix</span> <span class="o">=</span> <span class="n">data_dumms</span><span class="o">.</span><span class="n">corr</span><span class="p">()</span><span class="o">.</span><span class="n">round</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span> 
<span class="n">sns</span><span class="o">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">corr_matrix</span><span class="p">,</span> <span class="n">annot</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/supervised_learning_265_0.png" src="_images/supervised_learning_265_0.png" />
</div>
</div>
<p>De la matriz de correlación anterior, podemos observar que <code class="docutils literal notranslate"><span class="pre">Pclass</span></code> y <code class="docutils literal notranslate"><span class="pre">Fare</span></code> tienen una correlación de -0.55. Esto sugiere que estos pares de características están correlacionados entre sí. Teniendo en cuenta la multicolinealidad, vamos a eliminar la columna <code class="docutils literal notranslate"><span class="pre">Fare</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">data_nomulticol</span> <span class="o">=</span> <span class="n">data_dumms</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="s1">&#39;Fare&#39;</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">data_nomulticol</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Survived</th>
      <th>Pclass</th>
      <th>Age</th>
      <th>Sex_male</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0</td>
      <td>3</td>
      <td>22.0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1</td>
      <td>1</td>
      <td>38.0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1</td>
      <td>3</td>
      <td>26.0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>1</td>
      <td>1</td>
      <td>35.0</td>
      <td>0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0</td>
      <td>3</td>
      <td>35.0</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<ul class="simple">
<li><p>Dado que nuestra columna <code class="docutils literal notranslate"><span class="pre">Age</span></code> tiene valores numéricos continuos, podemos trazar su distribución de frecuencias</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sns</span><span class="o">.</span><span class="n">distplot</span><span class="p">(</span><span class="n">data_nomulticol</span><span class="p">[</span><span class="s1">&#39;Age&#39;</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/supervised_learning_269_0.png" src="_images/supervised_learning_269_0.png" />
</div>
</div>
<ul class="simple">
<li><p>A partir del gráfico anterior, parece que <code class="docutils literal notranslate"><span class="pre">Age</span></code> tiene una distribución bastante cercana a la Gaussiana. Por tanto, aplicar el modelo Gaussiano de Naive Bayes a los datos podría ser una buena idea. Por último, podemos construir nuestro modelo de clasificación Gaussiano Naive Bayes a partir del conjunto de datos Titanic</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">features</span> <span class="o">=</span> <span class="n">data_nomulticol</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="s1">&#39;Survived&#39;</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">label</span> <span class="o">=</span> <span class="n">data_nomulticol</span><span class="p">[</span><span class="s1">&#39;Survived&#39;</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Dividimos los datos en conjuntos de entrenamiento y de prueba, en una proporción de 80:20</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">features</span><span class="p">,</span> <span class="n">label</span><span class="p">,</span> <span class="n">test_size</span> <span class="o">=</span> <span class="mf">0.2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> 
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Construimos y ajustamos el modelo <code class="docutils literal notranslate"><span class="pre">GaussianNB</span></code></p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">clf</span> <span class="o">=</span> <span class="n">GaussianNB</span><span class="p">()</span>
<span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>GaussianNB()
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Realizamos predicciones sobre el conjunto de prueba y luego medimos la precisión del modelo</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pred</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">pred</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.7692307692307693
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">GaussianNB</span></code> se utiliza sobre todo con datos de muy alta dimensión, mientras que las otras dos variants de Bayes <code class="docutils literal notranslate"><span class="pre">MultinomialNB</span></code> y <code class="docutils literal notranslate"><span class="pre">BinaryNB</span></code>, se utilizan ampliamente para datos de recuento dispersos, como el texto. <code class="docutils literal notranslate"><span class="pre">MultinomialNB</span></code> suele funcionar mejor que <code class="docutils literal notranslate"><span class="pre">BinaryNB</span></code>, especialmente en conjuntos de datos con un número relativamente grande de características no nulas.</p></li>
<li><p>Los modelos Bayesianos comparten muchos de los puntos fuertes y débiles de los modelos lineales. Son muy rápidos de entrenar y predecir, y el procedimiento de entrenamiento es fácil de entender. Los modelos funcionan muy bien con datos dispersos de alta dimensión y son relativamente robustos a los parámetros. Los modelos Naive Bayes son excelentes modelos de referencia y se utilizan a menudo en conjuntos de datos muy grandes, donde el entrenamiento incluso de un modelo lineal podría llevar demasiado tiempo.</p></li>
</ul>
</section>
<section id="arboles-de-decision">
<h2>Árboles de decisión<a class="headerlink" href="#arboles-de-decision" title="Permalink to this headline">#</a></h2>
<p><strong><code class="docutils literal notranslate"><span class="pre">Observación</span></code></strong></p>
<ul class="simple">
<li><p>Los árboles de clasificación se basan en una idea simple, pero poderosa, y se encuentran entre las técnicas más populares de clasificación. Son sistemas de varias etapas, y la clasificación de un patrón en una clase se realiza de forma secuencial. A través de una serie de pruebas, las clases se rechazan de forma secuencial hasta que se llega a una decisión a favor de una clase restante.</p></li>
<li><p>Cada una de las pruebas, cuyo resultado decide qué clases se rechazan, es de tipo binario <code class="docutils literal notranslate"><span class="pre">&quot;Sí&quot;</span></code> o <code class="docutils literal notranslate"><span class="pre">&quot;No&quot;</span></code> y se aplica a una sola característica. Nuestro objetivo es presentar la filosofía principal en torno a un tipo especial de árboles conocidos como <code class="docutils literal notranslate"><span class="pre">árboles</span> <span class="pre">de</span> <span class="pre">clasificación</span> <span class="pre">binarios</span> <span class="pre">ordinarios</span> <span class="pre">(OBCT)</span></code>. Estos, pertenecen a una clase más general de métodos que construyen árboles, tanto para la clasificación como para la regresión, conocidos como <code class="docutils literal notranslate"><span class="pre">árboles</span> <span class="pre">de</span> <span class="pre">clasificación</span> <span class="pre">y</span> <span class="pre">regresión</span> <span class="pre">(CART)</span></code>.</p></li>
</ul>
<p><strong><code class="docutils literal notranslate"><span class="pre">Formulación</span></code></strong></p>
<ul class="simple">
<li><p>La idea básica de los <code class="docutils literal notranslate"><span class="pre">OBCT</span></code> es dividir el espacio de características en (hiper) rectángulos; es decir, el espacio se divide mediante hiperplanos, que son paralelos a los ejes. Esto se ilustra en la <a class="reference internal" href="#fig-decision-hypplanes-obct"><span class="std std-numref">Fig. 5</span></a></p></li>
</ul>
<figure class="align-center" id="fig-decision-hypplanes-obct">
<a class="reference internal image-reference" href="_images/decision_hypplanes_obct.png"><img alt="_images/decision_hypplanes_obct.png" src="_images/decision_hypplanes_obct.png" style="width: 334.0px; height: 344.5px;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 5 </span><span class="caption-text">Partición del espacio de características bidimensional, correspondiente a tres clases, mediante un árbol de clasificación (OBCT).</span><a class="headerlink" href="#fig-decision-hypplanes-obct" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<ul class="simple">
<li><p>La partición del espacio en (hiper) rectángulos se realiza mediante una serie de <code class="docutils literal notranslate"><span class="pre">&quot;preguntas&quot;</span></code> de esta forma: ¿es el valor de la característica <span class="math notranslate nohighlight">\(x_{i} &lt; a\)</span>?. Este también se conoce como el <code class="docutils literal notranslate"><span class="pre">criterio</span> <span class="pre">de</span> <span class="pre">división</span></code>. La secuencia de preguntas puede realizarse de forma agradable mediante el uso de un árbol. La <a class="reference internal" href="#fig-decision-tree-obct"><span class="std std-numref">Fig. 6</span></a> muestra el árbol correspondiente al caso ilustrado
en la <a class="reference internal" href="#fig-decision-hypplanes-obct"><span class="std std-numref">Fig. 5</span></a>.</p></li>
</ul>
<figure class="align-center" id="fig-decision-tree-obct">
<a class="reference internal image-reference" href="_images/decision_tree_obct.png"><img alt="_images/decision_tree_obct.png" src="_images/decision_tree_obct.png" style="width: 405.59999999999997px; height: 362.4px;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 6 </span><span class="caption-text">Árbol de clasificación que realiza la partición del espacio para la tarea indicada en la <a class="reference internal" href="#fig-decision-hypplanes-obct"><span class="std std-numref">Fig. 5</span></a>.</span><a class="headerlink" href="#fig-decision-tree-obct" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">Cada</span> <span class="pre">nodo</span> <span class="pre">del</span> <span class="pre">árbol</span> <span class="pre">realiza</span> <span class="pre">una</span> <span class="pre">prueba</span> <span class="pre">contra</span> <span class="pre">una</span> <span class="pre">característica</span> <span class="pre">individual</span> <span class="pre">y,</span> <span class="pre">si</span> <span class="pre">este</span> <span class="pre">no</span> <span class="pre">es</span> <span class="pre">un</span> <span class="pre">nodo</span> <span class="pre">hoja</span> <span class="pre">(sin</span> <span class="pre">división</span> <span class="pre">adicional),</span> <span class="pre">este</span> <span class="pre">es</span> <span class="pre">conectado</span> <span class="pre">a</span> <span class="pre">dos</span> <span class="pre">nodos</span> <span class="pre">descendientes</span> <span class="pre">(nodo</span> <span class="pre">de</span> <span class="pre">decisión):</span> <span class="pre">uno</span> <span class="pre">está</span> <span class="pre">asociado</span> <span class="pre">a</span> <span class="pre">la</span> <span class="pre">respuesta</span> <span class="pre">&quot;Yes&quot;</span> <span class="pre">y</span> <span class="pre">el</span> <span class="pre">otro</span> <span class="pre">a</span> <span class="pre">la</span> <span class="pre">respuesta</span> <span class="pre">&quot;No&quot;</span></code>.</p></li>
</ul>
<ul class="simple">
<li><p>Partiendo del nodo raíz, se realiza un recorrido de decisiones sucesivas hasta llegar a un nodo hoja. <code class="docutils literal notranslate"><span class="pre">Cada</span> <span class="pre">nodo</span> <span class="pre">hoja</span> <span class="pre">está</span> <span class="pre">asociado</span> <span class="pre">a</span> <span class="pre">una</span> <span class="pre">única</span> <span class="pre">clase.</span> <span class="pre">La</span> <span class="pre">asignación</span> <span class="pre">de</span> <span class="pre">un</span> <span class="pre">punto</span> <span class="pre">a</span> <span class="pre">una</span> <span class="pre">clase</span> <span class="pre">se</span> <span class="pre">realiza</span> <span class="pre">según</span> <span class="pre">la</span> <span class="pre">etiqueta</span> <span class="pre">del</span> <span class="pre">nodo</span> <span class="pre">hoja</span> <span class="pre">correspondiente</span></code>. Este tipo de clasificación es conceptualmente simple y fácil de interpretar. Por ejemplo, en un sistema de diagnóstico médico, se puede empezar con una pregunta: ¿la temperatura es alta? Si la respuesta es afirmativa, una segunda pregunta puede ser: ¿presenta moquea? El proceso continúa hasta que se llega a una decisión final sobre la enfermedad.</p></li>
<li><p>Además, los árboles son útiles para construir sistemas de razonamiento en la inteligencia artificial. Por ejemplo, la existencia de objetos específicos, que se deduce a través de una serie de preguntas relacionadas, basadas en los valores de ciertas características (de alto nivel), puede conducir al reconocimiento de una escena o de un objeto representado en una imagen.</p></li>
<li><p>Una vez desarrollado el árbol, la clasificación es sencilla. El mayor reto consiste en construir el árbol, explotando la información que reside en el conjunto de datos de entrenamiento. Las principales preguntas a las que uno se enfrenta al diseñar un árbol, entreo otras que se discutiran más adelante, son:</p>
<ul>
<li><p>¿Qué criterio de división debe adoptarse?</p></li>
<li><p>¿Cuándo se debe detener el crecimiento de un árbol y declarar un nodo como final?</p></li>
<li><p>¿Cómo se asocia un nodo hoja a una clase concreta?</p></li>
</ul>
</li>
</ul>
<p><strong><code class="docutils literal notranslate"><span class="pre">Criterio</span> <span class="pre">de</span> <span class="pre">división</span></code></strong>: Ya hemos dicho que las preguntas que se hacen en cada nodo son del tipo</p>
<div class="math notranslate nohighlight">
\[
\text{¿es}~x_{i} &lt; a\text{?}
\]</div>
<ul class="simple">
<li><p>El objetivo es seleccionar un valor adecuado para el umbral <span class="math notranslate nohighlight">\(a\)</span>. Supongamos que, partiendo del nodo raíz, el árbol ha crecido hasta el nodo actual, <span class="math notranslate nohighlight">\(t\)</span>. Cada nodo, <span class="math notranslate nohighlight">\(t\)</span>, está asociado a un subconjunto <span class="math notranslate nohighlight">\(X_{t}\subseteq X\)</span> del conjunto de datos de entrenamiento, <span class="math notranslate nohighlight">\(X\)</span>. Este es el conjunto de los puntos de entrenamiento que han sobrevivido a este nodo, después de las pruebas que han tenido lugar en los nodos anteriores del árbol.</p></li>
<li><p>Por ejemplo, en la <a class="reference internal" href="#fig-decision-tree-obct"><span class="std std-numref">Fig. 6</span></a>, un número de puntos, que pertenecen, digamos, a la clase <span class="math notranslate nohighlight">\(\omega_{1}\)</span>, no participarán en el nodo <span class="math notranslate nohighlight">\(t_{1}\)</span> porque ya han sido asignados en un nodo hoja previamente etiquetado. El propósito de un criterio de división es dividir <span class="math notranslate nohighlight">\(X_{t}\)</span> en dos subconjuntos disyuntos, digamos <span class="math notranslate nohighlight">\(X_{tY}\)</span>, y <span class="math notranslate nohighlight">\(X_{tN}\)</span>, dependiendo de la respuesta a la pregunta específica en el nodo <span class="math notranslate nohighlight">\(t\)</span>. Para cada división, se cumple lo siguiente:</p></li>
</ul>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align}
X_{tY}\cap X_{tN}&amp;=\emptyset\\
X_{tY}\cup X_{tN}&amp;=X_{t}
\end{align}
\end{split}\]</div>
<ul class="simple">
<li><p>El objetivo en cada nodo es seleccionar qué característica se va a probar y también cuál es el mejor valor del umbral <span class="math notranslate nohighlight">\(a\)</span>. La filosofía adoptada es hacer la elección de manera que cada división genere conjuntos, <span class="math notranslate nohighlight">\(X_{tY}\)</span>,  <span class="math notranslate nohighlight">\(X_{tN}\)</span>, que sean más homogéneos en cuanto a la clase en comparación con <span class="math notranslate nohighlight">\(X_{t}\)</span>. En otras palabras, los datos en cada uno de los dos conjuntos descendientes deben mostrar una mayor preferencia por clases específicas, en comparación con el conjunto antecesor.</p></li>
<li><p>Por ejemplo, supongamos que los datos de <span class="math notranslate nohighlight">\(X_{t}\)</span> consisten en puntos que pertenecen a cuatro clases, <span class="math notranslate nohighlight">\(\omega_{1}, \omega_{2}, \omega_{3}, \omega_{4}\)</span>. La idea es realizar la división de forma que la mayoría de los datos de <span class="math notranslate nohighlight">\(X_{tY}\)</span> pertenezcan, por ejemplo, a <span class="math notranslate nohighlight">\(\omega_{1}, \omega_{2}\)</span> y la mayoría de los datos de <span class="math notranslate nohighlight">\(X_{tN}\)</span> a <span class="math notranslate nohighlight">\(\omega_{3}, \omega_{4}\)</span>. En la terminología adoptada, los conjuntos <span class="math notranslate nohighlight">\(X_{tY}\)</span> y <span class="math notranslate nohighlight">\(X_{tN}\)</span> deben ser más puros en comparación con <span class="math notranslate nohighlight">\(X_{t}\)</span> . Así pues, primero debemos seleccionar un criterio que mida la impureza y, a continuación, calcular el valor umbral y elegir la característica específica (que se va a probar) para maximizar la disminución de la impureza del nodo.</p></li>
<li><p>Por ejemplo, una medida común para cuantificar la impureza del nodo, <span class="math notranslate nohighlight">\(t\)</span>, es la entropía, definida como</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
I(t)=-\sum_{m=1}^{M}P(\omega_{m}|t)\log_{2}P(\omega_{m}|t)
\]</div>
<ul class="simple">
<li><p>El valor máximo de <span class="math notranslate nohighlight">\(I(t)\)</span> se produce si todas las probabilidades son iguales (máxima impureza), y el valor más pequeño, que es igual a cero, cuando sólo uno de los valores de probabilidad es uno y el resto es igual a cero. Las probabilidades se aproximan como</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
P(\omega_{m}|t)=\frac{N_{t}^{m}}{N_{t}},\quad m=1,2,\dots,M,
\]</div>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(N_{t}^{m}\)</span> es el número de puntos de la clase <span class="math notranslate nohighlight">\(m\)</span> en <span class="math notranslate nohighlight">\(X_{t}\)</span>, y <span class="math notranslate nohighlight">\(N_{t}\)</span> el número total de puntos en <span class="math notranslate nohighlight">\(X_{t}\)</span>. La disminución de la impureza del nodo, después de dividir los datos en dos conjuntos, se define como</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
I(t)=\sum_{m=1}^{M}P(\omega_{m}|t)(1-P(\omega_{m}|t)),
\]</div>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(I(t_{Y})\)</span> y <span class="math notranslate nohighlight">\(I(t_{N})\)</span> son las impurezas asociadas a los dos nuevos conjuntos, respectivamente. El objetivo ahora se convierte en seleccionar la característica específica, <span class="math notranslate nohighlight">\(x_{i}\)</span>, y el umbral <span class="math notranslate nohighlight">\(a_{t}\)</span> para que <span class="math notranslate nohighlight">\(\Delta I(t)\)</span> sea máximo. Este definirá ahora dos nodos descendientes de <span class="math notranslate nohighlight">\(t\)</span>, a saber, <span class="math notranslate nohighlight">\(t_{N}\)</span> y <span class="math notranslate nohighlight">\(t_{Y}\)</span>; de este modo, el árbol crece con dos nuevos nodos.</p></li>
<li><p>Una forma de buscar diferentes valores de umbral es la siguiente: Para cada una de las características <span class="math notranslate nohighlight">\(x_{i}, i = 1, 2,\dots, l\)</span>, clasifique los valores, <span class="math notranslate nohighlight">\(x_{in}, n = 1, 2,\dots, N_{t}\)</span>, que toma esta característica entre los puntos de entrenamiento en <span class="math notranslate nohighlight">\(X_{t}\)</span>. A continuación, defina una secuencia de valores de umbral correspondientes, <span class="math notranslate nohighlight">\(a_{in}\)</span>, que esté a medio camino entre valores distintos consecutivos de <span class="math notranslate nohighlight">\(x_{in}\)</span>.</p></li>
<li><p>A continuación, se comprueba el cambio de impureza que se produce para cada uno de estos valores de umbral y nos quedamos con el que consiga la máxima disminución. Repita el proceso para todas las características y, por último, quédese con la combinación que dé lugar a la mejor disminución máxima. Además de la entropía, se pueden utilizar otros índices de medición de impurezas. Una alternativa popular, que da como resultado  un máximo ligeramente más agudo en comparación con el de la entropía, es el llamado <code class="docutils literal notranslate"><span class="pre">índice</span> <span class="pre">de</span> <span class="pre">Gini</span></code>, definido como</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
I(t)=\sum_{m=1}^{M}P(\omega_{m}|t)(1-P(\omega_{m}|t)).
\]</div>
<ul class="simple">
<li><p>Este índice también es cero si uno de los valores de la probabilidad es igual a 1 y el resto son cero, y toma su valor máximo cuando todas las clases son equiprobables.</p></li>
</ul>
<p><strong><code class="docutils literal notranslate"><span class="pre">Regla</span> <span class="pre">de</span> <span class="pre">detención</span> <span class="pre">de</span> <span class="pre">división</span> <span class="pre">(stop-splitting)</span></code></strong>: La pregunta obvia cuando crece un árbol es cuándo dejar de cultivarlo. Una forma posible es adoptar un valor umbral, <span class="math notranslate nohighlight">\(T\)</span>, y dejar de dividir un nodo una vez que el valor máximo <span class="math notranslate nohighlight">\(\Delta I(t)\)</span>, para todas las divisiones posibles, sea menor que <span class="math notranslate nohighlight">\(T\)</span>. Otra posibilidad es parar cuando la cardinalidad de <span class="math notranslate nohighlight">\(X_{t}\)</span> es menor que un número determinado o si el <code class="docutils literal notranslate"><span class="pre">nodo</span> <span class="pre">es</span> <span class="pre">puro,</span> <span class="pre">en</span> <span class="pre">el</span> <span class="pre">sentido</span> <span class="pre">de</span> <span class="pre">que</span> <span class="pre">todos</span> <span class="pre">los</span> <span class="pre">puntos</span> <span class="pre">que</span> <span class="pre">lo</span> <span class="pre">componen</span> <span class="pre">pertenecen</span> <span class="pre">a</span> <span class="pre">una</span> <span class="pre">única</span> <span class="pre">clase</span></code>.</p>
<p><strong><code class="docutils literal notranslate"><span class="pre">Podado</span> <span class="pre">del</span> <span class="pre">árbol</span></code></strong>: La experiencia ha demostrado que el crecimiento de un árbol y el uso de una regla de parada no siempre funciona bien en la práctica; el crecimiento puede detenerse antes de tiempo o puede dar lugar a árboles de tamaño muy grande. Una práctica común es hacer crecer primero un árbol hasta un tamaño grande y luego adoptar una técnica de poda para eliminar nodos. Se pueden utilizar diferentes criterios de poda; uno muy popular es combinar una estimación de la probabilidad de error con un índice de medición de la complejidad <span id="id3">[<a class="reference internal" href="#id20" title="L Breiman, J Friedman, R Olshen, and C Stone. Cart. Classification and Regression Trees, 1984.">Breiman <em>et al.</em>, 1984</a>, <a class="reference internal" href="#id21" title="Brian D Ripley. Pattern recognition and neural networks. Cambridge university press, 2007.">Ripley, 2007</a>]</span>.</p>
<p><strong><code class="docutils literal notranslate"><span class="pre">Observaciones</span></code></strong></p>
<ul class="simple">
<li><p>Entre las notables ventajas de los árboles de decisión está el hecho de que pueden tratar de forma natural mezclas de variables numéricas y categóricas. Además, se adaptan bien a grandes conjuntos de datos. Además, pueden tratar eficazmente datos faltantes. En muchos dominios, no se conocen todos los valores de las características para cada patrón. Los valores pueden no haber sido registrados, o pueden ser demasiado costosos de obtener.</p></li>
<li><p>Por último, debido a su simplicidad estructural, son fácilmente interpretables; en otras palabras, es posible que un humano entienda la razón de la salida del algoritmo de aprendizaje. En algunas, como en las decisiones financieras, esto es un requisito legal. Por otro lado, el rendimiento de predicción de los clasificadores de árbol no es tan bueno como el de otros métodos, como las <code class="docutils literal notranslate"><span class="pre">máquinas</span> <span class="pre">de</span> <span class="pre">soporte</span> <span class="pre">vectorial</span></code> y las <code class="docutils literal notranslate"><span class="pre">redes</span> <span class="pre">neuronales</span></code>, que se tratarán en posteriores capítulos</p></li>
<li><p>Uno de los principales inconvenientes asociados a los clasificadores de árbol es que son inestables. Es decir, un pequeño cambio en el conjunto de datos de entrenamiento puede dar lugar a un árbol muy diferente. La razón de esto radica en la naturaleza jerárquica de los clasificadores de árbol. Un error que se produce en un nodo en un nivel alto del árbol se propaga hasta las hojas inferiores.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">Bagging</span> <span class="pre">(Bootstrap</span> <span class="pre">Aggregating)</span></code> es una técnica que puede reducir la varianza y mejorar el rendimiento del error de generalización. La idea básica es crear un número de variantes <span class="math notranslate nohighlight">\(B\)</span>, <span class="math notranslate nohighlight">\(~X_{1}, X_{2},\dots, X_{B}\)</span>, del conjunto de entrenamiento, <span class="math notranslate nohighlight">\(X\)</span>, utilizando técnicas de bootstrap, mediante un muestreo uniforme de <span class="math notranslate nohighlight">\(X\)</span> con reemplasso. Para cada una de las variantes del conjunto de entrenamiento, <span class="math notranslate nohighlight">\(X_{i}\)</span>, se construye un árbol, <span class="math notranslate nohighlight">\(T_{i}\)</span>. La decisión final para la clasificación de un punto dado es a favor de la clase predicha por la mayoría de los subclasificadores, <span class="math notranslate nohighlight">\(T_{i}, i = 1, 2,\dots, B\)</span> <span id="id4">[<a class="reference internal" href="#id22" title="Leo Breiman. Bagging predictors. Machine learning, 24(2):123–140, 1996.">Breiman, 1996</a>]</span>.</p></li>
<li><p>Los <code class="docutils literal notranslate"><span class="pre">bosques</span> <span class="pre">aleatorios</span> <span class="pre">(random</span> <span class="pre">forest)</span></code> utilizan la idea de <code class="docutils literal notranslate"><span class="pre">bagging</span></code> junto con la selección aleatoria de características <span id="id5">[<a class="reference internal" href="#id23" title="Leo Breiman. Random forests. Machine learning, 45(1):5–32, 2001.">Breiman, 2001</a>]</span>. La diferencia con el bagging radica en la forma en que se construyen los árboles de decisión. La característica a dividir en cada nodo se selecciona como la mejor entre un conjunto de <span class="math notranslate nohighlight">\(F\)</span> características elegidas al azar, donde <span class="math notranslate nohighlight">\(F\)</span> es un parámetro definido por el usuario. Esta aleatoriedad adicional introducida tiene un efecto sustancial en la mejora del rendimiento. Los bosques aleatorios suelen tener una precisión predictiva muy buena y se han utilizado en una serie de aplicaciones, como el reconocimiento de la postura del cuerpo en términos del popular <code class="docutils literal notranslate"><span class="pre">sensor</span> <span class="pre">Kinect</span> <span class="pre">de</span> <span class="pre">Microsoft</span></code> <span id="id6">[<a class="reference internal" href="#id24" title="Jamie Shotton, Andrew Fitzgibbon, Mat Cook, Toby Sharp, Mark Finocchio, Richard Moore, Alex Kipman, and Andrew Blake. Real-time human pose recognition in parts from single depth images. In CVPR 2011, 1297–1304. Ieee, 2011.">Shotton <em>et al.</em>, 2011</a>]</span>.</p></li>
<li><p>Además de los métodos anteriores, recientemente, también se han sugerido técnicas bayesianas y utilizadas para estabilizar el rendimiento de los árboles; véase <span id="id7">[<a class="reference internal" href="#id25" title="Hugh A Chipman, Edward I George, and Robert E McCulloch. Bart: bayesian additive regression trees. The Annals of Applied Statistics, 4(1):266–298, 2010.">Chipman <em>et al.</em>, 2010</a>, <a class="reference internal" href="#id26" title="Yuhong Wu, Håkon Tjelmeland, and Mike West. Bayesian cart: prior specification and posterior simulation. Journal of Computational and Graphical Statistics, 16(1):44–66, 2007.">Wu <em>et al.</em>, 2007</a>]</span>. Por supuesto, el efecto de utilizar múltiples árboles, es perder una de las principales ventajas de los árboles, es decir, su facilidad de interpretación.</p></li>
</ul>
<section id="combinacion-de-clasificadores">
<h3>Combinación de clasificadores<a class="headerlink" href="#combinacion-de-clasificadores" title="Permalink to this headline">#</a></h3>
<ul class="simple">
<li><p>Hasta ahora, hemos discutido una serie de clasificadores, y se presentarán más métodos en las siguientes secciones, relativos a las <code class="docutils literal notranslate"><span class="pre">máquinas</span> <span class="pre">de</span> <span class="pre">vectores</span> <span class="pre">de</span> <span class="pre">soporte</span></code> y las <code class="docutils literal notranslate"><span class="pre">redes</span> <span class="pre">neuronales</span></code>. La pregunta obvia a la que se enfrenta un profesional/investigador sin experiencia es: ¿qué método entonces? Por desgracia, no hay una respuesta definitiva.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">No</span> <span class="pre">free</span> <span class="pre">lunch</span> <span class="pre">theorem</span></code>: El objetivo del diseño de cualquier clasificador, y en general de cualquier esquema de aprendizaje es proporcionar un buen rendimiento de generalización. Sin embargo, no hay razones independientes del contexto o del uso para apoyar una técnica de aprendizaje en lugar de otra. Cada tarea de aprendizaje, representada por el conjunto de datos disponible, mostrará una preferencia por un esquema de aprendizaje específico que se ajuste a las especificidades del problema en cuestión. Un algoritmo que obtiene la máxima puntuación en un problema puede obtener una puntuación baja en otro. Esto se resume a veces como el <code class="docutils literal notranslate"><span class="pre">teorema</span> <span class="pre">de</span> <span class="pre">la</span> <span class="pre">no</span> <span class="pre">gratuidad</span> <span class="pre">(No</span> <span class="pre">free</span> <span class="pre">lunch</span> <span class="pre">theorem)</span></code> [57].</p></li>
<li><p>En la práctica, hay que probar diferentes métodos de aprendizaje de la paleta disponible, cada uno optimizado para la tarea específica, y probar su rendimiento de generalización con un conjunto de datos independiente distinto del utilizado para el entrenamiento, utilizando, por ejemplo, el método de exclusión o cualquiera de sus variantes. A continuación, se mantiene y se utiliza el método que ha obtenido la mejor puntuación para la tarea específica. Con este fin, hay una serie de esfuerzos importantes para comparar diferentes clasificadores contra diferentes conjuntos de datos y medir el rendimiento “medio”, mediante el uso de diferentes índices estadísticos para cuantificar el rendimiento global de cada clasificador frente a los conjuntos de datos.</p></li>
</ul>
<p><strong><code class="docutils literal notranslate"><span class="pre">Esquemas</span> <span class="pre">de</span> <span class="pre">combinación</span> <span class="pre">de</span> <span class="pre">clasificadores</span></code></strong></p>
<ul class="simple">
<li><p>Una tendencia para mejorar el rendimiento es combinar diferentes clasificadores y explotar sus ventajas individuales. Una observación que justifica este enfoque es que, durante las pruebas, hay patrones en los que incluso el mejor clasificador para una tarea concreta no logra predecir su verdadera clase. En cambio, los mismos patrones pueden ser clasificados correctamente por otros clasificadores, con un rendimiento global inferior. Esto muestra que puede haber cierta complementariedad entre los distintos clasificadores, y la combinación puede conducir  a un mayor rendimiento en comparación con el obtenido por el mejor (único) clasificador.</p></li>
<li><p>Recordemos que el bagging mencionado anteriormente, es un tipo de combinación de clasificadores. La cuestión que se plantea ahora es seleccionar un esquema de combinación. Hay diferentes esquemas, y los resultados que proporcionan pueden ser diferentes. A continuación, resumimos los esquemas de combinación más populares.</p></li>
</ul>
<p><strong><code class="docutils literal notranslate"><span class="pre">Regla</span> <span class="pre">de</span> <span class="pre">la</span> <span class="pre">media</span> <span class="pre">aritmética</span></code></strong>: Suponiendo que utilizamos <span class="math notranslate nohighlight">\(L\)</span> clasificadores, en los que cada uno da un valor de probabilidad posterior, <span class="math notranslate nohighlight">\(P_{j}(\omega_{i}|\boldsymbol{x}), i = 1,2,\dots,M,~j = 1, 2, . . . L\)</span>, la decisión sobre la asignación de la clase se basa en la siguiente regla:</p>
<div class="math notranslate nohighlight">
\[
\text{Asignar}~\boldsymbol{x}~\text{a la clase}~\omega_{i}=\textrm{arg}\max_{k}\frac{1}{L}\sum_{j=1}^{L}P_{j}(\omega_{k}|\boldsymbol{x}),\quad k=1,2,\dots,M.
\]</div>
<p>Esta regla equivale a calcular la probabilidad posterior “final”, <span class="math notranslate nohighlight">\(P(\omega_{i}|\boldsymbol{x})\)</span>, para minimizar la distancia media de Kullback-Leibler</p>
<div class="math notranslate nohighlight">
\[
D_{av}=\frac{1}{L}\sum_{j=1}^{L}D_{j},~\text{donde}~D_{j}=\sum_{i=1}^{M}P_{j}(\omega_{i}|\boldsymbol{x})\ln\frac{P_{j}(\omega_{i}|\boldsymbol{x})}{P(\omega_{i}|\boldsymbol{x})}.
\]</div>
<p><strong><code class="docutils literal notranslate"><span class="pre">Regla</span> <span class="pre">de</span> <span class="pre">promediación</span> <span class="pre">geométrica</span></code></strong>: Esta regla es el resultado de minimizar la formulación alternativa de distancia de Kullback-Leibler (nótese que esta distancia no es simétrica); en otras palabras</p>
<div class="math notranslate nohighlight">
\[
D_{j}=\sum_{i=1}^{M}P(\omega_{i}|\boldsymbol{x})\ln\frac{P(\omega_{i}|\boldsymbol{x})}{P_{j}(\omega_{i}|\boldsymbol{x})},
\]</div>
<p>lo que da lugar a</p>
<div class="math notranslate nohighlight">
\[
\text{Asignar}~\boldsymbol{x}~\text{a la clase}~\omega_{i}=\textrm{arg}\max_{k}\prod_{j=1}^{L} P_{j}(\omega_{k}|\boldsymbol{x}),\quad k=1,2,\dots,M.
\]</div>
<p><strong><code class="docutils literal notranslate"><span class="pre">Apilamiento</span></code></strong>: Una forma alternativa es utilizar una media ponderada de las salidas de los clasificadores individuales, donde los pesos de la combinación se obtienen de forma óptima utilizando los datos de entrenamiento. Supongamos que la salida de cada clasificador individual, <span class="math notranslate nohighlight">\(f_{j}(x)\)</span>, es de tipo suave; por ejemplo, una estimación de probabilidad posterior, como antes. Entonces, la salida combinada viene dada por</p>
<div class="math notranslate nohighlight">
\[
f(\boldsymbol{x})=\sum_{j=1}^{L}\omega_{j}f_{j}(\boldsymbol{x}),
\]</div>
<p>donde los pesos son estimados vía la siguiente tarea de optimización:</p>
<div class="math notranslate nohighlight">
\[
\hat{\boldsymbol{\omega}}=\textrm{arg}\min_{\boldsymbol{\omega}}\sum_{n=1}^{N}\mathcal{L}(y_{n}, f(\boldsymbol{x}_{n}))=\textrm{arg}\min_{\boldsymbol{\omega}}\sum_{n=1}^{N}\mathcal{L}\left(y_{n}, \sum_{j=1}^{L}\omega_{j}f_{j}(\boldsymbol{x})\right)
\]</div>
<p>donde, <span class="math notranslate nohighlight">\(\mathcal{L}(\cdot,\cdot)\)</span> es una función de pérdida; por ejemplo, la del error al cuadratico.</p>
<p><strong><code class="docutils literal notranslate"><span class="pre">Regla</span> <span class="pre">de</span> <span class="pre">la</span> <span class="pre">mediana</span></code></strong>: Cuando valores atípicos están presentes, se puede utilizar en su lugar el valor de la mediana:</p>
<div class="math notranslate nohighlight">
\[
\text{Asignar}~\boldsymbol{x}~\text{a la clase}~\omega_{i}=\textrm{arg}\max_{k}\textrm{median}\{P_{j}(\omega_{k}|\boldsymbol{x})\},\quad k=1,2,\dots,M.
\]</div>
<p>Resulta que el <code class="docutils literal notranslate"><span class="pre">no</span> <span class="pre">free</span> <span class="pre">lunch</span> <span class="pre">theorem</span></code> también es válido para las reglas de combinación; no hay una regla universalmente óptima. Todo depende de los datos de que se disponga; véase <span id="id8">[<a class="reference internal" href="#id27" title="Anil K Jain, Robert P. W. Duin, and Jianchang Mao. Statistical pattern recognition: a review. IEEE Transactions on pattern analysis and machine intelligence, 22(1):4–37, 2000.">Jain <em>et al.</em>, 2000</a>]</span>.</p>
</section>
<section id="control-de-complejidad">
<h3>Control de complejidad<a class="headerlink" href="#control-de-complejidad" title="Permalink to this headline">#</a></h3>
<ul class="simple">
<li><p>Al construir un árbol como se describe en esta sección, hasta que todas las hojas sean puras, da lugar a modelos muy complejos y muy ajustados a los datos de entrenamiento. <code class="docutils literal notranslate"><span class="pre">La</span> <span class="pre">presencia</span> <span class="pre">de</span> <span class="pre">hojas</span> <span class="pre">puras</span> <span class="pre">significa</span> <span class="pre">que</span> <span class="pre">un</span> <span class="pre">árbol</span> <span class="pre">es</span> <span class="pre">100%</span> <span class="pre">preciso</span> <span class="pre">en</span> <span class="pre">el</span> <span class="pre">conjunto</span> <span class="pre">de</span> <span class="pre">entrenamiento</span></code>; cada punto de datos del conjunto de entrenamiento está en una hoja que tiene la clase mayoritaria correcta.</p></li>
<li><p>Hay dos estrategias comunes para evitar el overfitting: <code class="docutils literal notranslate"><span class="pre">detener</span> <span class="pre">la</span> <span class="pre">creación</span> <span class="pre">del</span> <span class="pre">árbol</span> <span class="pre">antes</span> <span class="pre">de</span> <span class="pre">tiempo</span> <span class="pre">(también</span> <span class="pre">llamada</span> <span class="pre">prepoda),</span> <span class="pre">o</span> <span class="pre">construir</span> <span class="pre">el</span> <span class="pre">árbol,</span> <span class="pre">pero</span> <span class="pre">luego</span> <span class="pre">eliminar</span> <span class="pre">o</span> <span class="pre">colapsar</span> <span class="pre">nodos</span> <span class="pre">que</span> <span class="pre">contienen</span> <span class="pre">poca</span> <span class="pre">información</span> <span class="pre">(también</span> <span class="pre">llamada</span> <span class="pre">poda</span> <span class="pre">posterior</span> <span class="pre">o</span> <span class="pre">simplemente</span> <span class="pre">poda)</span></code>. Los posibles criterios para la <code class="docutils literal notranslate"><span class="pre">prepoda</span></code> incluyen la <code class="docutils literal notranslate"><span class="pre">limitación</span> <span class="pre">de</span> <span class="pre">la</span> <span class="pre">profundidad</span> <span class="pre">máxima</span> <span class="pre">del</span> <span class="pre">árbol,</span> <span class="pre">limitar</span> <span class="pre">el</span> <span class="pre">número</span> <span class="pre">máximo</span> <span class="pre">de</span> <span class="pre">hojas,</span> <span class="pre">o</span> <span class="pre">exigir</span> <span class="pre">un</span> <span class="pre">número</span> <span class="pre">mínimo</span> <span class="pre">de</span> <span class="pre">puntos</span> <span class="pre">en</span> <span class="pre">un</span> <span class="pre">nodo</span> <span class="pre">para</span> <span class="pre">seguir</span> <span class="pre">dividiéndolo</span></code>.</p></li>
<li><p>Los árboles de decisión en <code class="docutils literal notranslate"><span class="pre">scikit-learn</span></code> se implementan en las clases <code class="docutils literal notranslate"><span class="pre">DecisionTreeRegressor</span></code> y <code class="docutils literal notranslate"><span class="pre">DecisionTreeClassifier</span></code>. <code class="docutils literal notranslate"><span class="pre">scikit-learn</span></code> sólo implementa la pre-poda, no la post-poda. Veamos el efecto de la poda a priori con más detalle en el conjunto de datos de cáncer de mama. Como siempre, importamos el conjunto de datos y lo dividimos en una parte de entrenamiento y otra de prueba. A continuación, construimos un  modelo utilizando la configuración por defecto de desarrollo completo del árbol (extendiendo el árbol hasta que todas las hojas sean puras). Fijamos el <code class="docutils literal notranslate"><span class="pre">random_state</span></code> en el árbol, que se utiliza para ruptura interna de de los lazos. Nótese que seleccionamos <code class="docutils literal notranslate"><span class="pre">stratify=cancer.target</span></code>, los datos se dividen de forma estratificada, utilizando <code class="docutils literal notranslate"><span class="pre">cancer.target</span></code> como las etiquetas de clase (ver <a class="reference external" href="https://scikit-learn.org/stable/modules/cross_validation.html#stratification">stratified</a>).</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.tree</span> <span class="kn">import</span> <span class="n">DecisionTreeClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_breast_cancer</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">cancer</span> <span class="o">=</span> <span class="n">load_breast_cancer</span><span class="p">()</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">cancer</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">cancer</span><span class="o">.</span><span class="n">target</span><span class="p">,</span> 
                                                    <span class="n">stratify</span><span class="o">=</span><span class="n">cancer</span><span class="o">.</span><span class="n">target</span><span class="p">,</span> 
                                                    <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">tree</span> <span class="o">=</span> <span class="n">DecisionTreeClassifier</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">tree</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Accuracy on training set: </span><span class="si">{:.3f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">tree</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Accuracy on test set: </span><span class="si">{:.3f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">tree</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Accuracy on training set: 1.000
Accuracy on test set: 0.937
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Aquí la función <code class="docutils literal notranslate"><span class="pre">score</span></code> como en la mayoría de clasificadores, devuelve la precisión media en los datos de prueba y las etiquetas dadas. Como era de esperar, <code class="docutils literal notranslate"><span class="pre">la</span> <span class="pre">precisión</span> <span class="pre">en</span> <span class="pre">el</span> <span class="pre">conjunto</span> <span class="pre">de</span> <span class="pre">entrenamiento</span> <span class="pre">es</span> <span class="pre">del</span> <span class="pre">100%</span></code>, ya que las hojas son puras, el árbol creció lo suficiente como para poder memorizar perfectamente todas las etiquetas de los datos de entrenamiento. <code class="docutils literal notranslate"><span class="pre">La</span> <span class="pre">precisión</span> <span class="pre">del</span> <span class="pre">conjunto</span> <span class="pre">de</span> <span class="pre">prueba</span> <span class="pre">es</span> <span class="pre">ligeramente</span> <span class="pre">peor</span> <span class="pre">que</span> <span class="pre">la</span> <span class="pre">de</span> <span class="pre">los</span> <span class="pre">modelos</span> <span class="pre">lineales</span></code> que vimos anteriormente, que tenían una precisión de alrededor del 95%.</p></li>
<li><p>Si no restringimos la profundidad de un árbol de decisión, el árbol puede llegar a ser arbitrariamente profundo y complejo. <code class="docutils literal notranslate"><span class="pre">Los</span> <span class="pre">árboles</span> <span class="pre">no</span> <span class="pre">podados</span> <span class="pre">son,</span> <span class="pre">por</span> <span class="pre">tanto,</span> <span class="pre">son</span> <span class="pre">propensos</span> <span class="pre">a</span> <span class="pre">sobreajustarse</span> <span class="pre">y</span> <span class="pre">a</span> <span class="pre">no</span> <span class="pre">generalizar</span> <span class="pre">bien</span> <span class="pre">a</span> <span class="pre">los</span> <span class="pre">nuevos</span> <span class="pre">datos</span></code>. Ahora apliquemos la pre-poda, la cual que dejará de desarrollar el árbol antes de ajustarse perfectamente a los datos de entrenamiento. Una opción es dejar de construir el árbol después de alcanzar una cierta profundidad. En este caso,<code class="docutils literal notranslate"><span class="pre">establecemos</span> <span class="pre">que</span> <span class="pre">la</span> <span class="pre">profundidad</span> <span class="pre">máxima</span> <span class="pre">sea</span> <span class="pre">de</span> <span class="pre">4</span> <span class="pre">(max_depth=4),</span> <span class="pre">lo</span> <span class="pre">que</span> <span class="pre">significa</span> <span class="pre">que</span> <span class="pre">sólo</span> <span class="pre">se</span> <span class="pre">pueden</span> <span class="pre">formular</span> <span class="pre">cuatro</span> <span class="pre">preguntas</span> <span class="pre">consecutivas</span></code>. La limitación de la profundidad del árbol disminuye el sobreajuste. Esto conduce a una menor precisión en el conjunto de entrenamiento, pero una mejora en el conjunto de prueba</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">tree</span> <span class="o">=</span> <span class="n">DecisionTreeClassifier</span><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">tree</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Accuracy on training set: </span><span class="si">{:.3f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">tree</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Accuracy on test set: </span><span class="si">{:.3f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">tree</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Accuracy on training set: 0.988
Accuracy on test set: 0.951
</pre></div>
</div>
</div>
</div>
</section>
<section id="analisis-de-los-arboles-de-decision">
<h3>Análisis de los árboles de decisión<a class="headerlink" href="#analisis-de-los-arboles-de-decision" title="Permalink to this headline">#</a></h3>
<ul class="simple">
<li><p>Podemos visualizar un árbol de decisión utilizando la función <code class="docutils literal notranslate"><span class="pre">export_graphviz</span></code> del módulo <code class="docutils literal notranslate"><span class="pre">tree</span></code>. Esta función escribe un archivo en el formato <code class="docutils literal notranslate"><span class="pre">.dot</span></code> de archivo de texto para almacenar gráficos. Establecemos una opción para colorear los nodos, para reflejar la clase mayoritaria en cada nodo y pasamos los nombres de las clases y las características para que el árbol pueda ser etiquetado correctamente. El argumento <code class="docutils literal notranslate"><span class="pre">impurity</span></code> está relacionado con la probabilidad de que clasifiquemos incorrectamente un nuevo punto de datos de forma incorrecta, normalmente calculada mediante la métrica de entropia <code class="docutils literal notranslate"><span class="pre">giny</span></code> la cual se aborda teóricamente en la sección anterior.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.tree</span> <span class="kn">import</span> <span class="n">export_graphviz</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">export_graphviz</span><span class="p">(</span><span class="n">tree</span><span class="p">,</span>
                <span class="n">out_file</span><span class="o">=</span><span class="s2">&quot;tree.dot&quot;</span><span class="p">,</span> 
                <span class="n">class_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;malignant&quot;</span><span class="p">,</span> <span class="s2">&quot;benign&quot;</span><span class="p">],</span>
                <span class="n">feature_names</span><span class="o">=</span><span class="n">cancer</span><span class="o">.</span><span class="n">feature_names</span><span class="p">,</span> 
                <span class="n">impurity</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> 
                <span class="n">filled</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Podemos leer este archivo y visualizarlo, utilizando el modulo <code class="docutils literal notranslate"><span class="pre">graphviz</span></code> (o puede utilizar cualquier programa que pueda leer archivos <code class="docutils literal notranslate"><span class="pre">.dot</span></code>)</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">graphviz</span>
<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s2">&quot;tree.dot&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">dot_graph</span> <span class="o">=</span> <span class="n">f</span><span class="o">.</span><span class="n">read</span><span class="p">()</span>
<span class="n">graphviz</span><span class="o">.</span><span class="n">Source</span><span class="p">(</span><span class="n">dot_graph</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/supervised_learning_318_0.svg" src="_images/supervised_learning_318_0.svg" /></div>
</div>
<ul class="simple">
<li><p>La visualización del árbol proporciona una <code class="docutils literal notranslate"><span class="pre">gran</span> <span class="pre">visión</span> <span class="pre">en</span> <span class="pre">profundidad</span> <span class="pre">de</span> <span class="pre">cómo</span> <span class="pre">el</span> <span class="pre">algoritmo</span> <span class="pre">realiza</span> <span class="pre">predicciones,</span> <span class="pre">y</span> <span class="pre">es</span> <span class="pre">un</span> <span class="pre">buen</span> <span class="pre">ejemplo</span> <span class="pre">de</span> <span class="pre">un</span> <span class="pre">algoritmo</span> <span class="pre">de</span> <span class="pre">aprendizaje</span> <span class="pre">automático</span> <span class="pre">que</span> <span class="pre">puede</span> <span class="pre">fácilmente</span> <span class="pre">explicarse</span> <span class="pre">a</span> <span class="pre">no</span> <span class="pre">expertos</span></code>. Sin embargo, incluso con un árbol de profundidad cuatro, como se ve aquí, el árbol puede resultar un poco abrumador. Los árboles más profundos (una profundidad de 10 puede ser común) son aún más difíciles de entender.</p></li>
<li><p>Un método de inspección del árbol que puede ser útil es, averiguar qué camino toma realmente la mayoría de los datos. <code class="docutils literal notranslate"><span class="pre">Las</span> <span class="pre">n_samples</span> <span class="pre">que</span> <span class="pre">se</span> <span class="pre">muestran</span> <span class="pre">en</span> <span class="pre">cada</span> <span class="pre">nodo</span> <span class="pre">de</span> <span class="pre">la</span> <span class="pre">figura,</span> <span class="pre">entregan</span> <span class="pre">el</span> <span class="pre">número</span> <span class="pre">de</span> <span class="pre">muestras</span> <span class="pre">en</span> <span class="pre">ese</span> <span class="pre">nodo</span></code>, mientras que <code class="docutils literal notranslate"><span class="pre">value</span> <span class="pre">provee</span> <span class="pre">el</span> <span class="pre">número</span> <span class="pre">de</span> <span class="pre">muestras</span> <span class="pre">por</span> <span class="pre">clase</span></code>. Siguiendo las ramas hacia la derecha, vemos que el <code class="docutils literal notranslate"><span class="pre">worst</span> <span class="pre">radius</span></code> <span class="math notranslate nohighlight">\(\leq\)</span> <code class="docutils literal notranslate"><span class="pre">16.795</span></code> crea un nodo que contiene sólo <code class="docutils literal notranslate"><span class="pre">8</span> <span class="pre">muestras</span> <span class="pre">benignas</span> <span class="pre">pero</span> <span class="pre">134</span> <span class="pre">muestras</span> <span class="pre">malignas.</span> <span class="pre">El</span> <span class="pre">resto</span> <span class="pre">de</span> <span class="pre">este</span> <span class="pre">lado</span> <span class="pre">del</span> <span class="pre">árbol</span> <span class="pre">utiliza</span> <span class="pre">entonces</span> <span class="pre">algunas</span> <span class="pre">distinciones</span> <span class="pre">más</span> <span class="pre">finas</span> <span class="pre">para</span> <span class="pre">separar</span> <span class="pre">estas</span> <span class="pre">8</span> <span class="pre">muestras</span> <span class="pre">benignas</span> <span class="pre">restantes</span></code>. De las 142 muestras que fueron a la derecha en la división inicial, casi todas ellas (132) terminan en la hoja de la derecha. Tomando la izquierda en la raíz, para el <code class="docutils literal notranslate"><span class="pre">worst</span> <span class="pre">radio</span> <span class="pre">&gt;</span> <span class="pre">16.795</span></code> terminamos con <code class="docutils literal notranslate"><span class="pre">25</span> <span class="pre">muestras</span> <span class="pre">malignas</span> <span class="pre">y</span> <span class="pre">259</span> <span class="pre">muestras</span> <span class="pre">benignas</span></code>. Casi todas las muestras benignas acaban en la segunda hoja de la derecha, y la mayoría de las demás hojas contienen muy pocas muestras.</p></li>
</ul>
</section>
<section id="caracteristicas-importantes-en-los-arboles">
<h3>Características importantes en los árboles<a class="headerlink" href="#caracteristicas-importantes-en-los-arboles" title="Permalink to this headline">#</a></h3>
<ul class="simple">
<li><p>En lugar de mirar todo el árbol, lo que puede ser agotador, hay algunas <code class="docutils literal notranslate"><span class="pre">propiedades</span> <span class="pre">útiles</span> <span class="pre">que</span> <span class="pre">podemos</span> <span class="pre">derivar</span> <span class="pre">para</span> <span class="pre">resumir</span> <span class="pre">el</span> <span class="pre">funcionamiento</span> <span class="pre">del</span> <span class="pre">árbol</span></code>. El resumen más utilizado es el de las <code class="docutils literal notranslate"><span class="pre">características</span> <span class="pre">importantes,</span> <span class="pre">que</span> <span class="pre">califica</span> <span class="pre">la</span> <span class="pre">importancia</span> <span class="pre">de</span> <span class="pre">cada</span> <span class="pre">característica</span> <span class="pre">para</span> <span class="pre">la</span> <span class="pre">decisión</span> <span class="pre">que</span> <span class="pre">toma</span> <span class="pre">el</span> <span class="pre">árbol</span></code>. Es un número entre 0 y 1 para cada característica, donde 0 significa “no se utiliza en absoluto” y 1 significa “predice perfectamente el objetivo”. Las características siempre suman 1</p></li>
</ul>
<ul class="simple">
<li><p>Otra <code class="docutils literal notranslate"><span class="pre">excelente</span> <span class="pre">manera</span> <span class="pre">de</span> <span class="pre">visualizar</span> <span class="pre">predicciones</span> <span class="pre">a</span> <span class="pre">partir</span> <span class="pre">de</span> <span class="pre">un</span> <span class="pre">random</span> <span class="pre">forest</span> <span class="pre">por</span> <span class="pre">ejemplo,</span> <span class="pre">es</span> <span class="pre">utilizando</span> <span class="pre">la</span> <span class="pre">librería</span></code> <a class="reference external" href="https://www.kaggle.com/code/prashant111/explain-your-model-predictions-with-lime/notebook">LIME</a> <code class="docutils literal notranslate"><span class="pre">de</span> <span class="pre">Python</span></code>. Con esta librería se pueden generar por cada instancias, figuras de cartaterísticas importantes y representar sus probabilidades de pertenecer a la clase predicha (<code class="docutils literal notranslate"><span class="pre">pruebela</span></code>).</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Feature importances:</span><span class="se">\n</span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">tree</span><span class="o">.</span><span class="n">feature_importances_</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Feature importances:
[0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.01019737 0.04839825
 0.         0.         0.0024156  0.         0.         0.
 0.         0.         0.72682851 0.0458159  0.         0.
 0.0141577  0.         0.018188   0.1221132  0.01188548 0.        ]
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Podemos visualizar las importancias de las características de forma similar a la forma en que visualizamos los coeficientes en el modelo lineal</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">plot_feature_importances_cancer</span><span class="p">(</span><span class="n">model</span><span class="p">):</span>
    <span class="n">n_features</span> <span class="o">=</span> <span class="n">cancer</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">barh</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">n_features</span><span class="p">),</span> <span class="n">model</span><span class="o">.</span><span class="n">feature_importances_</span><span class="p">,</span> <span class="n">align</span><span class="o">=</span><span class="s1">&#39;center&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">yticks</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">n_features</span><span class="p">),</span> <span class="n">cancer</span><span class="o">.</span><span class="n">feature_names</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Feature importance&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Feature&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plot_feature_importances_cancer</span><span class="p">(</span><span class="n">tree</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/supervised_learning_327_0.png" src="_images/supervised_learning_327_0.png" />
</div>
</div>
<ul class="simple">
<li><p>Aquí vemos que la característica utilizada en la división superior <code class="docutils literal notranslate"><span class="pre">(&quot;worst</span> <span class="pre">radio&quot;)</span></code> es, con mucho, la más importante. Esto confirma nuestra observación al analizar el árbol de que el primer nivel ya separa bastante bien las dos clases. Sin embargo, si una característica tiene un <code class="docutils literal notranslate"><span class="pre">feature_importance</span></code> bajo, no significa que esta característica sea poco informativa. Sólo significa que la característica no fue elegida por el árbol, probablemente porque otra característica codifica la misma información.</p></li>
<li><p>A diferencia de los coeficientes de los modelos lineales, <code class="docutils literal notranslate"><span class="pre">las</span> <span class="pre">importancias</span> <span class="pre">de</span> <span class="pre">las</span> <span class="pre">características</span> <span class="pre">son</span> <span class="pre">siempre</span> <span class="pre">positivas</span> <span class="pre">y</span> <span class="pre">no</span> <span class="pre">codifican</span> <span class="pre">la</span> <span class="pre">clase</span> <span class="pre">de</span> <span class="pre">la</span> <span class="pre">que</span> <span class="pre">es</span> <span class="pre">indicativa</span> <span class="pre">una</span> <span class="pre">característica</span></code>. Las <code class="docutils literal notranslate"><span class="pre">feature_importance</span></code> nos dicen que el <code class="docutils literal notranslate"><span class="pre">&quot;worst</span> <span class="pre">radio&quot;</span></code> es importante, pero no si un radio alto es indicativo de que una muestra es benigna o maligna. De hecho, puede que no haya una relación tan sencilla entre las características y la clase, como se puede ver en el siguiente ejemplo. La siguiente figura muestra un conjunto de datos bidimensional en el que <code class="docutils literal notranslate"><span class="pre">la</span> <span class="pre">característica</span> <span class="pre">en</span> <span class="pre">el</span> <span class="pre">eje</span></code> <span class="math notranslate nohighlight">\(y\)</span> <code class="docutils literal notranslate"><span class="pre">tiene</span> <span class="pre">una</span> <span class="pre">relación</span> <span class="pre">no</span> <span class="pre">monótona</span> <span class="pre">con</span> <span class="pre">la</span> <span class="pre">etiqueta</span> <span class="pre">de</span> <span class="pre">clase,</span> <span class="pre">y</span> <span class="pre">los</span> <span class="pre">límites</span> <span class="pre">de</span> <span class="pre">decisión</span> <span class="pre">encontrados</span> <span class="pre">por</span> <span class="pre">un</span> <span class="pre">árbol</span> <span class="pre">de</span> <span class="pre">decisión</span></code></p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">tree</span> <span class="o">=</span> <span class="n">mglearn</span><span class="o">.</span><span class="n">plots</span><span class="o">.</span><span class="n">plot_tree_not_monotone</span><span class="p">()</span>
<span class="n">display</span><span class="p">(</span><span class="n">tree</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Feature importances: [0. 1.]
</pre></div>
</div>
<img alt="_images/supervised_learning_329_1.svg" src="_images/supervised_learning_329_1.svg" /><img alt="_images/supervised_learning_329_2.png" src="_images/supervised_learning_329_2.png" />
</div>
</div>
<ul class="simple">
<li><p>El gráfico muestra un conjunto de datos con dos características y dos clases. Aquí, toda la información está contenida en <code class="docutils literal notranslate"><span class="pre">X[1]</span></code> , y <code class="docutils literal notranslate"><span class="pre">X[0]</span></code> no se utiliza en absoluto. Pero la relación entre X[1] y la clase de salida no es monótona, lo que significa que no podemos decir <code class="docutils literal notranslate"><span class="pre">&quot;un</span> <span class="pre">valor</span> <span class="pre">alto</span> <span class="pre">de</span> <span class="pre">X[0]</span> <span class="pre">significa</span> <span class="pre">la</span> <span class="pre">clase</span> <span class="pre">0,</span> <span class="pre">y</span> <span class="pre">un</span> <span class="pre">valor</span> <span class="pre">bajo</span> <span class="pre">significa</span> <span class="pre">la</span> <span class="pre">clase</span> <span class="pre">1&quot;</span> <span class="pre">(o</span> <span class="pre">viceversa)</span></code>. Aunque hemos centrado nuestra discusión aquí en los árboles de decisión para la clasificación, todo lo que se ha dicho es igualmente cierto para los árboles de decisión para la regresión, como se implementa en <code class="docutils literal notranslate"><span class="pre">DecisionTreeRegressor</span></code>.</p></li>
<li><p>El uso y análisis de los árboles de regresión es muy similar al de los árboles de clasificación. Hay una propiedad particular del uso de modelos basados en árboles para regresión que queremos señalar, sin embargo, <code class="docutils literal notranslate"><span class="pre">DecisionTreeRegressor</span> <span class="pre">(y</span> <span class="pre">todos</span> <span class="pre">los</span> <span class="pre">otros</span> <span class="pre">modelos</span> <span class="pre">de</span> <span class="pre">regresión</span> <span class="pre">basados</span> <span class="pre">en</span> <span class="pre">árboles)</span> <span class="pre">no</span> <span class="pre">son</span> <span class="pre">capaces</span> <span class="pre">de</span> <span class="pre">extrapolar,</span> <span class="pre">o</span> <span class="pre">hacer</span> <span class="pre">predicciones</span> <span class="pre">fuera</span> <span class="pre">del</span> <span class="pre">rango</span> <span class="pre">de</span> <span class="pre">los</span> <span class="pre">datos</span> <span class="pre">de</span> <span class="pre">entrenamiento</span></code>. Veamos esto con más detalle, utilizando un conjunto de datos de los precios históricos de la memoria de los ordenadores (RAM). La siguiente figura muestra el conjunto de datos, con la fecha en el eje <span class="math notranslate nohighlight">\(x\)</span> y el precio de un megabyte de RAM en ese año en el eje <span class="math notranslate nohighlight">\(y\)</span>:</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="n">ram_prices</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;data/ram_price.csv&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">semilogy</span><span class="p">(</span><span class="n">ram_prices</span><span class="o">.</span><span class="n">date</span><span class="p">,</span> <span class="n">ram_prices</span><span class="o">.</span><span class="n">price</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Year&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Price in $/Mbyte&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Text(0, 0.5, &#39;Price in $/Mbyte&#39;)
</pre></div>
</div>
<img alt="_images/supervised_learning_331_1.png" src="_images/supervised_learning_331_1.png" />
</div>
</div>
<ul class="simple">
<li><p>Nótese que en la escala logarítmica del eje <span class="math notranslate nohighlight">\(y\)</span>, <code class="docutils literal notranslate"><span class="pre">la</span> <span class="pre">relación</span> <span class="pre">parece</span> <span class="pre">ser</span> <span class="pre">bastante</span> <span class="pre">lineal</span> <span class="pre">y,</span> <span class="pre">por</span> <span class="pre">tanto,</span> <span class="pre">debería</span> <span class="pre">ser</span> <span class="pre">relativamente</span> <span class="pre">fácil</span> <span class="pre">de</span> <span class="pre">predecir</span></code>. Vamos a hacer una predicción para los años posteriores al 2000 utilizando los datos históricos hasta esa fecha como única característica. Compararemos dos modelos sencillos: un <code class="docutils literal notranslate"><span class="pre">DecisionTreeRegressor</span></code> y <code class="docutils literal notranslate"><span class="pre">LinearRegression</span></code>.</p></li>
<li><p>Cambiamos la escala de los precios utilizando un logaritmo, para que la relación sea relativamente lineal. Esto no supone ninguna diferencia para el <code class="docutils literal notranslate"><span class="pre">DecisionTreeRegressor</span></code>, pero supone una gran diferencia para el <code class="docutils literal notranslate"><span class="pre">LinearRegression</span></code>. Después de entrenar los modelos y hacer predicciones, aplicamos la función exponencial para deshacer la transformación del logaritmo. Realizamos predicciones sobre todo el conjunto de datos para su visualización, pero para una evaluación cuantitativa, sólo consideraríamos el conjunto de datos de prueba</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.tree</span> <span class="kn">import</span> <span class="n">DecisionTreeRegressor</span>
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Utilizamos los datos históricos para prever los precios después del año 2000. <code class="docutils literal notranslate"><span class="pre">Realizamos</span> <span class="pre">predicción</span> <span class="pre">de</span> <span class="pre">los</span> <span class="pre">precios</span> <span class="pre">en</span> <span class="pre">función</span> <span class="pre">de</span> <span class="pre">la</span> <span class="pre">fecha</span></code>. Utilizamos una transformación logarítmica para obtener una relación más sencilla de los datos con el objetivo</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">data_train</span> <span class="o">=</span> <span class="n">ram_prices</span><span class="p">[</span><span class="n">ram_prices</span><span class="o">.</span><span class="n">date</span> <span class="o">&lt;</span> <span class="mi">2000</span><span class="p">]</span>
<span class="n">data_test</span>  <span class="o">=</span> <span class="n">ram_prices</span><span class="p">[</span><span class="n">ram_prices</span><span class="o">.</span><span class="n">date</span> <span class="o">&gt;=</span> <span class="mi">2000</span><span class="p">]</span>

<span class="n">X_train</span> <span class="o">=</span> <span class="n">data_train</span><span class="o">.</span><span class="n">date</span><span class="p">[:,</span> <span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">]</span> <span class="c1"># Vector columna</span>
<span class="n">y_train</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">data_train</span><span class="o">.</span><span class="n">price</span><span class="p">)</span>

<span class="n">tree</span> <span class="o">=</span> <span class="n">DecisionTreeRegressor</span><span class="p">()</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">linear_reg</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">()</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="n">X_all</span> <span class="o">=</span> <span class="n">ram_prices</span><span class="o">.</span><span class="n">date</span><span class="p">[:,</span> <span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">]</span>
<span class="n">pred_tree</span> <span class="o">=</span> <span class="n">tree</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_all</span><span class="p">)</span>
<span class="n">pred_lr</span> <span class="o">=</span> <span class="n">linear_reg</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_all</span><span class="p">)</span>

<span class="n">price_tree</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">pred_tree</span><span class="p">)</span>
<span class="n">price_lr</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">pred_lr</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Realizamos una figura para comparar las predicciones del árbol de decisión y del modelo de regresión lineal con la los datos reales de entrenamiento y de prueba</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">semilogy</span><span class="p">(</span><span class="n">data_train</span><span class="o">.</span><span class="n">date</span><span class="p">,</span> <span class="n">data_train</span><span class="o">.</span><span class="n">price</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Training data&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">semilogy</span><span class="p">(</span><span class="n">data_test</span><span class="o">.</span><span class="n">date</span><span class="p">,</span> <span class="n">data_test</span><span class="o">.</span><span class="n">price</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Test data&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">semilogy</span><span class="p">(</span><span class="n">ram_prices</span><span class="o">.</span><span class="n">date</span><span class="p">,</span> <span class="n">price_tree</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Tree prediction&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">semilogy</span><span class="p">(</span><span class="n">ram_prices</span><span class="o">.</span><span class="n">date</span><span class="p">,</span> <span class="n">price_lr</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Linear prediction&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">();</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/supervised_learning_337_0.png" src="_images/supervised_learning_337_0.png" />
</div>
</div>
<ul class="simple">
<li><p>La diferencia entre los modelos es bastante sorprendente. El modelo lineal se aproxima a los datos con una línea, como sabíamos que haría. Esta línea proporciona una previsión bastante buena para los datos de prueba (los años posteriores al 2000), mientras que pasa por alto algunas de las variaciones más finas en los datos de entrenamiento y de prueba. <code class="docutils literal notranslate"><span class="pre">El</span> <span class="pre">modelo</span> <span class="pre">de</span> <span class="pre">árbol,</span> <span class="pre">por</span> <span class="pre">su</span> <span class="pre">parte,</span> <span class="pre">hace</span> <span class="pre">predicciones</span> <span class="pre">perfectas</span> <span class="pre">sobre</span> <span class="pre">los</span> <span class="pre">datos</span> <span class="pre">de</span> <span class="pre">entrenamiento</span></code>, no restringimos la complejidad del árbol, por lo que aprendió de memoria todo el conjunto de datos. Sin embargo, <code class="docutils literal notranslate"><span class="pre">una</span> <span class="pre">vez</span> <span class="pre">que</span> <span class="pre">salimos</span> <span class="pre">del</span> <span class="pre">rango</span> <span class="pre">para</span> <span class="pre">el</span> <span class="pre">que</span> <span class="pre">el</span> <span class="pre">arbol</span> <span class="pre">tiene</span> <span class="pre">datos,</span> <span class="pre">el</span> <span class="pre">modelo</span> <span class="pre">simplemente</span> <span class="pre">sigue</span> <span class="pre">prediciendo</span> <span class="pre">el</span> <span class="pre">último</span> <span class="pre">punto</span> <span class="pre">conocido</span></code>. El árbol no tiene la capacidad para generar <code class="docutils literal notranslate"><span class="pre">&quot;nuevas&quot;</span></code> respuestas, fuera de lo que se vio en los datos de de entrenamiento. Esta deficiencia se aplica a todos los modelos basados en árboles.</p></li>
</ul>
<p><strong><code class="docutils literal notranslate"><span class="pre">Puntos</span> <span class="pre">fuertes,</span> <span class="pre">puntos</span> <span class="pre">débiles</span> <span class="pre">y</span> <span class="pre">parámetros</span></code></strong></p>
<ul class="simple">
<li><p>Como ya se ha comentado, los parámetros que controlan la complejidad del modelo en los árboles de decisión son los parámetros de pre-selección que detienen la construcción del árbol antes de que esté completamente desarrollado. Por lo general, la elección de una de las estrategias de pre-poda y configuración de: <code class="docutils literal notranslate"><span class="pre">max_depth,</span> <span class="pre">max_leaf_nodes,</span> <span class="pre">min_samples_leaf</span></code> es suficiente para evitar el overfitting de la misma.</p></li>
<li><p>Los árboles de decisión tienen dos ventajas sobre muchos de los algoritmos que hemos analizado hasta ahora: <code class="docutils literal notranslate"><span class="pre">el</span> <span class="pre">modelo</span> <span class="pre">resultante</span> <span class="pre">puede</span> <span class="pre">ser</span> <span class="pre">fácilmente</span> <span class="pre">visualizado</span> <span class="pre">y</span> <span class="pre">entendido</span> <span class="pre">por</span> <span class="pre">personas</span> <span class="pre">no</span> <span class="pre">expertas</span> <span class="pre">(al</span> <span class="pre">menos</span> <span class="pre">para</span> <span class="pre">los</span> <span class="pre">árboles</span> <span class="pre">más</span> <span class="pre">pequeños)</span></code>, y los <code class="docutils literal notranslate"><span class="pre">algoritmos</span> <span class="pre">son</span> <span class="pre">completamente</span> <span class="pre">invariables</span> <span class="pre">a</span> <span class="pre">la</span> <span class="pre">escala</span> <span class="pre">de</span> <span class="pre">los</span> <span class="pre">datos</span></code>. Como <code class="docutils literal notranslate"><span class="pre">cada</span> <span class="pre">característica</span> <span class="pre">se</span> <span class="pre">procesa</span> <span class="pre">por</span> <span class="pre">separado</span></code>, y las posibles divisiones de los datos no dependen de la escala, no es necesario un preprocesamiento como la normalización o la estandarización de las características para los algoritmos de árboles de decisión.</p></li>
<li><p>En particular, los árboles de decisión funcionan bien cuando se tienen características que están en escalas completamente diferentes, o una mezcla de características binarias y continuas. <code class="docutils literal notranslate"><span class="pre">El</span> <span class="pre">principal</span> <span class="pre">inconveniente</span> <span class="pre">de</span> <span class="pre">los</span> <span class="pre">árboles</span> <span class="pre">de</span> <span class="pre">decisión</span> <span class="pre">es</span> <span class="pre">que,</span> <span class="pre">incluso</span> <span class="pre">con</span> <span class="pre">el</span> <span class="pre">uso</span> <span class="pre">de</span> <span class="pre">la</span> <span class="pre">pre-poda,</span> <span class="pre">tienden</span> <span class="pre">a</span> <span class="pre">sobreajustarse</span> <span class="pre">y</span> <span class="pre">a</span> <span class="pre">proporcionar</span> <span class="pre">un</span> <span class="pre">pobre</span> <span class="pre">rendimiento</span> <span class="pre">de</span> <span class="pre">generalización</span></code>. Por lo tanto, en la mayoría de las aplicaciones, los <code class="docutils literal notranslate"><span class="pre">métodos</span> <span class="pre">combiandos</span></code> que analizamos a continuación suelen utilizarse en lugar de un único árbol de decisión.</p></li>
</ul>
</section>
<section id="ensamble-de-arboles-de-decision">
<h3>Ensamble de árboles de decisión<a class="headerlink" href="#ensamble-de-arboles-de-decision" title="Permalink to this headline">#</a></h3>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">Los</span> <span class="pre">ensambles</span> <span class="pre">son</span> <span class="pre">métodos</span> <span class="pre">que</span> <span class="pre">combinan</span> <span class="pre">múltiples</span> <span class="pre">modelos</span> <span class="pre">de</span> <span class="pre">aprendizaje</span> <span class="pre">automático</span> <span class="pre">para</span> <span class="pre">crear</span> <span class="pre">modelos</span> <span class="pre">más</span> <span class="pre">potentes</span></code>. Hay muchos modelos en la literatura de aprendizaje automático que pertenecen a esta categoría, pero hay dos modelos de ensamble que han demostrado su eficacia en una amplia gama de conjuntos de datos de clasificación y regresión, ambos utilizan árboles de decisión como bloques de construcción: los <code class="docutils literal notranslate"><span class="pre">random</span> <span class="pre">forest</span></code> y los <code class="docutils literal notranslate"><span class="pre">gradient</span> <span class="pre">boosted</span> <span class="pre">decision</span> <span class="pre">trees.</span></code></p></li>
</ul>
<p><strong><code class="docutils literal notranslate"><span class="pre">Bosques</span> <span class="pre">aleatorios</span></code></strong></p>
<ul class="simple">
<li><p>Como acabamos de observar, uno de los principales inconvenientes de <code class="docutils literal notranslate"><span class="pre">los</span> <span class="pre">árboles</span> <span class="pre">de</span> <span class="pre">decisión</span> <span class="pre">es</span> <span class="pre">que</span> <span class="pre">tienden</span> <span class="pre">a</span> <span class="pre">sobreajustar</span> <span class="pre">los</span> <span class="pre">datos</span> <span class="pre">de</span> <span class="pre">entrenamiento.</span> <span class="pre">Los</span> <span class="pre">bosques</span> <span class="pre">aleatorios</span> <span class="pre">son</span> <span class="pre">una</span> <span class="pre">forma</span> <span class="pre">de</span> <span class="pre">abordar</span> <span class="pre">este</span> <span class="pre">problema</span></code>. Un bosque aleatorio es esencialmente una colección de árboles de decisión, donde cada árbol es ligeramente diferente de de los demás. La idea detrás de los bosques aleatorios es que cada árbol puede hacer un trabajo de predicción relativamente bien, pero es probable que se ajuste demasiado a una parte de los datos. <code class="docutils literal notranslate"><span class="pre">Si</span> <span class="pre">construimos</span> <span class="pre">muchos</span> <span class="pre">árboles,</span> <span class="pre">todos</span> <span class="pre">los</span> <span class="pre">cuales</span> <span class="pre">funcionan</span> <span class="pre">bien</span> <span class="pre">y</span> <span class="pre">se</span> <span class="pre">ajustan</span> <span class="pre">en</span> <span class="pre">exceso</span> <span class="pre">de</span> <span class="pre">diferentes</span> <span class="pre">maneras,</span> <span class="pre">podemos</span> <span class="pre">reducir</span> <span class="pre">la</span> <span class="pre">cantidad</span> <span class="pre">de</span> <span class="pre">sobreajuste</span> <span class="pre">promediando</span> <span class="pre">sus</span> <span class="pre">resultados</span></code>. Esta reducción de overfitting, al tiempo que se mantiene el poder de predicción de los árboles se puede verificar matemáticamente.</p></li>
<li><p>Para poner en práctica esta estrategia, tenemos que construir muchos árboles de decisión. Cada árbol debe hacer un trabajo aceptable de predicción del objetivo, y también debe ser diferente de los otros árboles. Los bosques aleatorios reciben su nombre de la inyección de aleatoriedad en la construcción de árboles para garantizar que cada árbol sea diferente. Hay dos formas de aleatorizar los árboles de un bosque aleatorio: <code class="docutils literal notranslate"><span class="pre">seleccionando</span> <span class="pre">los</span> <span class="pre">puntos</span> <span class="pre">de</span> <span class="pre">datos</span> <span class="pre">utilizados</span> <span class="pre">para</span> <span class="pre">construir</span> <span class="pre">un</span> <span class="pre">árbol</span> <span class="pre">y</span> <span class="pre">seleccionando</span> <span class="pre">las</span> <span class="pre">características</span> <span class="pre">en</span> <span class="pre">cada</span> <span class="pre">prueba</span> <span class="pre">de</span> <span class="pre">división</span></code>. Veamos este proceso con más detalle.</p></li>
</ul>
<p><strong><code class="docutils literal notranslate"><span class="pre">Construcción</span> <span class="pre">de</span> <span class="pre">bosques</span> <span class="pre">aleatorios</span></code></strong></p>
<ul class="simple">
<li><p>Para construir un modelo de bosque aleatorio (<code class="docutils literal notranslate"><span class="pre">random</span> <span class="pre">forest</span></code>), hay que decidir el número de árboles a construir (el parámetro <code class="docutils literal notranslate"><span class="pre">n_estimators</span></code> de <code class="docutils literal notranslate"><span class="pre">RandomForestRegressor</span></code> o <code class="docutils literal notranslate"><span class="pre">RandomForestClassifier</span></code>). Digamos que queremos construir 10 árboles. Estos árboles se construirán de forma completamente independiente unos de otros, y <code class="docutils literal notranslate"><span class="pre">el</span> <span class="pre">algoritmo</span> <span class="pre">hará</span> <span class="pre">elecciones</span> <span class="pre">aleatorias</span> <span class="pre">diferentes</span> <span class="pre">para</span> <span class="pre">cada</span> <span class="pre">árbol</span> <span class="pre">con</span> <span class="pre">el</span> <span class="pre">fin</span> <span class="pre">de</span> <span class="pre">asegurarse</span> <span class="pre">de</span> <span class="pre">que</span> <span class="pre">los</span> <span class="pre">árboles</span> <span class="pre">son</span> <span class="pre">distintos</span></code>.</p></li>
<li><p>Para construir un árbol, primero tomamos lo que se llama una <code class="docutils literal notranslate"><span class="pre">muestra</span> <span class="pre">bootstrap</span></code> de nuestros datos. Es decir, a partir de nuestras <code class="docutils literal notranslate"><span class="pre">n_samples</span></code> (puntos de datos), extraemos repetidamente un ejemplo al azar con reemplazo (lo que significa que la misma muestra puede ser elegida varias veces), <code class="docutils literal notranslate"><span class="pre">n_samples</span></code> veces. Esto creará un conjunto de datos que es tan grande como el conjunto de datos original, pero en el que faltarán algunos puntos de dato (aproximadamente un tercio), y algunos se repetirán.</p></li>
<li><p>Para ilustrarlo, digamos que queremos crear una <code class="docutils literal notranslate"><span class="pre">muestra</span> <span class="pre">bootstrap</span></code> de la lista <code class="docutils literal notranslate"><span class="pre">['a',</span> <span class="pre">'b',</span> <span class="pre">'c',</span> <span class="pre">'d']</span></code>. Una posible muestra bootstrap sería <code class="docutils literal notranslate"><span class="pre">['b',</span> <span class="pre">'d',</span> <span class="pre">'d',</span> <span class="pre">'c']</span></code>. Otra muestra posible sería <code class="docutils literal notranslate"><span class="pre">['d',</span> <span class="pre">'a',</span> <span class="pre">'d',</span> <span class="pre">'a']</span></code>. A continuación, <code class="docutils literal notranslate"><span class="pre">se</span> <span class="pre">construye</span> <span class="pre">un</span> <span class="pre">árbol</span> <span class="pre">de</span> <span class="pre">decisión</span> <span class="pre">basado</span> <span class="pre">en</span> <span class="pre">este</span> <span class="pre">conjunto</span> <span class="pre">de</span> <span class="pre">datos</span> <span class="pre">(muestra</span> <span class="pre">bootstrap)</span> <span class="pre">recién</span> <span class="pre">creado</span></code>. Sin embargo, el algoritmo que hemos descrito para el árbol de decisión se ha modificado ligeramente. En lugar de buscar la mejor prueba para cada nodo, el algoritmo <code class="docutils literal notranslate"><span class="pre">selecciona</span> <span class="pre">aleatoriamente</span> <span class="pre">un</span> <span class="pre">subconjunto</span> <span class="pre">de</span> <span class="pre">características</span> <span class="pre">y</span> <span class="pre">busca</span> <span class="pre">la</span> <span class="pre">mejor</span> <span class="pre">prueba</span> <span class="pre">posible</span> <span class="pre">que</span> <span class="pre">incluya</span> <span class="pre">una</span> <span class="pre">de</span> <span class="pre">estas</span> <span class="pre">características</span></code>.</p></li>
</ul>
<ul class="simple">
<li><p>El número de características que se seleccionan se controla con el parámetro <code class="docutils literal notranslate"><span class="pre">max_features</span></code>. La selección de un subconjunto de características se repite por separado en cada nodo, de modo que <code class="docutils literal notranslate"><span class="pre">cada</span> <span class="pre">nodo</span> <span class="pre">de</span> <span class="pre">un</span> <span class="pre">árbol</span> <span class="pre">puede</span> <span class="pre">tomar</span> <span class="pre">una</span> <span class="pre">decisión</span> <span class="pre">utilizando</span> <span class="pre">un</span> <span class="pre">subconjunto</span> <span class="pre">diferente</span> <span class="pre">de</span> <span class="pre">las</span> <span class="pre">características</span></code>. <code class="docutils literal notranslate"><span class="pre">El</span> <span class="pre">muestreo</span> <span class="pre">bootstrap</span> <span class="pre">hace</span> <span class="pre">que</span> <span class="pre">cada</span> <span class="pre">árbol</span> <span class="pre">de</span> <span class="pre">decisión</span> <span class="pre">del</span> <span class="pre">bosque</span> <span class="pre">aleatorio</span> <span class="pre">se</span> <span class="pre">construya</span> <span class="pre">en</span> <span class="pre">un</span> <span class="pre">conjunto</span> <span class="pre">de</span> <span class="pre">datos</span> <span class="pre">ligeramente</span> <span class="pre">diferente</span></code>. Debido a la selección de características en cada nodo, cada división de cada árbol opera con un subconjunto diferente de características. Juntos, estos dos mecanismos aseguran que todos los árboles del bosque aleatorio son diferentes.</p></li>
<li><p>En este proceso el parámetro <code class="docutils literal notranslate"><span class="pre">max_features</span></code> es crítico. Si establecemos <code class="docutils literal notranslate"><span class="pre">max_features</span></code> en <code class="docutils literal notranslate"><span class="pre">n_features</span></code>, <code class="docutils literal notranslate"><span class="pre">significa</span> <span class="pre">que</span> <span class="pre">cada</span> <span class="pre">división</span> <span class="pre">puede</span> <span class="pre">mirar</span> <span class="pre">todas</span> <span class="pre">las</span> <span class="pre">características</span> <span class="pre">del</span> <span class="pre">conjunto</span> <span class="pre">de</span> <span class="pre">datos,</span> <span class="pre">y</span> <span class="pre">no</span> <span class="pre">se</span> <span class="pre">inyectará</span> <span class="pre">aleatoriedad</span> <span class="pre">ninguna</span> <span class="pre">en</span> <span class="pre">la</span> <span class="pre">selección</span> <span class="pre">de</span> <span class="pre">características</span></code> (la aleatoriedad debida al bootstrap permanece, sin embargo). Si establecemos <code class="docutils literal notranslate"><span class="pre">max_features</span> <span class="pre">en</span> <span class="pre">1,</span> <span class="pre">esto</span> <span class="pre">significa</span> <span class="pre">que</span> <span class="pre">las</span> <span class="pre">divisiones</span> <span class="pre">no</span> <span class="pre">tienen</span> <span class="pre">ninguna</span> <span class="pre">opción</span> <span class="pre">sobre</span> <span class="pre">qué</span> <span class="pre">característica</span> <span class="pre">probar</span></code>, y sólo pueden buscar sobre diferentes umbrales para la característica que fue seleccionada  al azar. Por lo tanto, un <code class="docutils literal notranslate"><span class="pre">max_feature</span></code> significa que los árboles del bosque aleatorio serán bastante similares y podrán con facilidad ajustarse a los datos, utilizando las características más distintivas. <code class="docutils literal notranslate"><span class="pre">Un</span> <span class="pre">max_features</span> <span class="pre">bajo</span> <span class="pre">significa</span> <span class="pre">que</span> <span class="pre">los</span> <span class="pre">árboles</span> <span class="pre">del</span> <span class="pre">bosque</span> <span class="pre">aleatorio</span> <span class="pre">serán</span> <span class="pre">bastante</span> <span class="pre">diferentes,</span> <span class="pre">y</span> <span class="pre">que</span> <span class="pre">cada</span> <span class="pre">árbol</span> <span class="pre">puede</span> <span class="pre">necesitar</span> <span class="pre">ser</span> <span class="pre">muy</span> <span class="pre">profundo</span> <span class="pre">para</span> <span class="pre">ajustarse</span> <span class="pre">bien</span> <span class="pre">a</span> <span class="pre">los</span> <span class="pre">datos</span></code>.</p></li>
<li><p>Para hacer una predicción utilizando el bosque aleatorio, el algoritmo realiza primero una predicción para cada árbol del bosque. <code class="docutils literal notranslate"><span class="pre">Para</span> <span class="pre">la</span> <span class="pre">regresión,</span> <span class="pre">podemos</span> <span class="pre">promediar</span> <span class="pre">estos</span> <span class="pre">resultados</span> <span class="pre">para</span> <span class="pre">obtener</span> <span class="pre">nuestra</span> <span class="pre">predicción</span> <span class="pre">final</span></code>. Para la clasificación, se utiliza una estrategia de <code class="docutils literal notranslate"><span class="pre">&quot;votación</span> <span class="pre">suave&quot;</span></code>. Esto significa que cada algoritmo hace una predicción <code class="docutils literal notranslate"><span class="pre">&quot;suave&quot;</span></code>, proporcionando una probabilidad para cada posible etiqueta de salida. <code class="docutils literal notranslate"><span class="pre">Las</span> <span class="pre">probabilidades</span> <span class="pre">predichas</span> <span class="pre">por</span> <span class="pre">todos</span> <span class="pre">los</span> <span class="pre">árboles</span> <span class="pre">se</span> <span class="pre">promedian</span> <span class="pre">y</span> <span class="pre">se</span> <span class="pre">predice</span> <span class="pre">la</span> <span class="pre">clase</span> <span class="pre">con</span> <span class="pre">la</span> <span class="pre">mayor</span> <span class="pre">probabilidad</span></code>.</p></li>
</ul>
<p><strong><code class="docutils literal notranslate"><span class="pre">Análisis</span> <span class="pre">de</span> <span class="pre">los</span> <span class="pre">bosques</span> <span class="pre">aleatorios</span></code></strong>. Apliquemos un bosque aleatorio compuesto por cinco árboles al conjunto de datos <code class="docutils literal notranslate"><span class="pre">two_moons</span></code></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">make_moons</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">mglearn</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">make_moons</span><span class="p">(</span><span class="n">n_samples</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">noise</span><span class="o">=</span><span class="mf">0.25</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">stratify</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="n">forest</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">forest</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>RandomForestClassifier(n_estimators=5, random_state=2)
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">Los</span> <span class="pre">árboles</span> <span class="pre">que</span> <span class="pre">se</span> <span class="pre">construyen</span> <span class="pre">como</span> <span class="pre">parte</span> <span class="pre">del</span> <span class="pre">bosque</span> <span class="pre">aleatorio</span> <span class="pre">se</span> <span class="pre">almacenan</span> <span class="pre">en</span> <span class="pre">estimator_attribute</span></code>. Visualicemos los límites de decisión aprendidos por cada árbol, junto con su predicción agregada</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>

<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">ax</span><span class="p">,</span> <span class="n">tree</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">axes</span><span class="o">.</span><span class="n">ravel</span><span class="p">(),</span> <span class="n">forest</span><span class="o">.</span><span class="n">estimators_</span><span class="p">)):</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Tree </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">i</span><span class="p">))</span>
    <span class="n">mglearn</span><span class="o">.</span><span class="n">plots</span><span class="o">.</span><span class="n">plot_tree_partition</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">tree</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">)</span>

<span class="n">mglearn</span><span class="o">.</span><span class="n">plots</span><span class="o">.</span><span class="n">plot_2d_separator</span><span class="p">(</span><span class="n">forest</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">fill</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">axes</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">.4</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Random Forest&quot;</span><span class="p">)</span>
<span class="n">mglearn</span><span class="o">.</span><span class="n">discrete_scatter</span><span class="p">(</span><span class="n">X_train</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X_train</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">y_train</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/supervised_learning_351_0.png" src="_images/supervised_learning_351_0.png" />
</div>
</div>
<ul class="simple">
<li><p>Se puede ver claramente que los límites de decisión aprendidos por los cinco árboles son bastante diferentes. Cada uno de ellos comete algunos errores, ya que algunos de los puntos que se representan aquí no se incluyeron en los conjuntos de entrenamiento de los árboles, debido al muestreo bootstrap. <code class="docutils literal notranslate"><span class="pre">El</span> <span class="pre">bosque</span> <span class="pre">aleatorio</span> <span class="pre">se</span> <span class="pre">ajusta</span> <span class="pre">menos</span> <span class="pre">que</span> <span class="pre">cualquiera</span> <span class="pre">de</span> <span class="pre">los</span> <span class="pre">árboles</span> <span class="pre">por</span> <span class="pre">separado</span> <span class="pre">y</span> <span class="pre">proporciona</span> <span class="pre">un</span> <span class="pre">límite</span> <span class="pre">de</span> <span class="pre">decisión</span> <span class="pre">mucho</span> <span class="pre">más</span> <span class="pre">intuitivo</span></code>. En cualquier aplicación real, utilizaríamos muchos más árboles (a menudo cientos o miles), lo que daría lugar a límites aún más suaves.</p></li>
</ul>
<ul class="simple">
<li><p>Como otro ejemplo, apliquemos un bosque aleatorio compuesto por 100 árboles en el conjunto de datos <code class="docutils literal notranslate"><span class="pre">Breast</span> <span class="pre">Cancer</span></code></p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_breast_cancer</span>
<span class="n">cancer</span> <span class="o">=</span> <span class="n">load_breast_cancer</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">cancer</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">cancer</span><span class="o">.</span><span class="n">target</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">forest</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">forest</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Accuracy on training set: </span><span class="si">{:.3f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">forest</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Accuracy on test set: </span><span class="si">{:.3f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">forest</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Accuracy on training set: 1.000
Accuracy on test set: 0.972
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">El</span> <span class="pre">bosque</span> <span class="pre">aleatorio</span> <span class="pre">nos</span> <span class="pre">da</span> <span class="pre">una</span> <span class="pre">precisión</span> <span class="pre">del</span> <span class="pre">97%,</span> <span class="pre">mejor</span> <span class="pre">que</span> <span class="pre">los</span> <span class="pre">modelos</span> <span class="pre">lineales</span> <span class="pre">o</span> <span class="pre">un</span> <span class="pre">árbol</span> <span class="pre">de</span> <span class="pre">decisión</span> <span class="pre">único,</span> <span class="pre">sin</span> <span class="pre">necesidad</span> <span class="pre">de</span> <span class="pre">ajustar</span> <span class="pre">ningún</span> <span class="pre">parámetro</span></code>. Podríamos ajustar la configuración de <code class="docutils literal notranslate"><span class="pre">max_features</span></code>, o aplicar la pre-selección como hicimos con el árbol de decisión simple. Sin embargo, a menudo los parámetros por defecto del bosque aleatorio ya funcionan bastante bien. <code class="docutils literal notranslate"><span class="pre">Al</span> <span class="pre">igual</span> <span class="pre">que</span> <span class="pre">el</span> <span class="pre">árbol</span> <span class="pre">de</span> <span class="pre">decisión,</span> <span class="pre">el</span> <span class="pre">bosque</span> <span class="pre">aleatorio</span> <span class="pre">proporciona</span> <span class="pre">importancias</span> <span class="pre">de</span> <span class="pre">características,</span> <span class="pre">que</span> <span class="pre">se</span> <span class="pre">calculan</span> <span class="pre">agregando</span> <span class="pre">las</span> <span class="pre">importancias</span> <span class="pre">de</span> <span class="pre">las</span> <span class="pre">características</span> <span class="pre">en</span> <span class="pre">los</span> <span class="pre">árboles</span> <span class="pre">del</span> <span class="pre">bosque</span></code>. Normalmente, las <code class="docutils literal notranslate"><span class="pre">importancias</span> <span class="pre">de</span> <span class="pre">las</span> <span class="pre">características</span> <span class="pre">proporcionadas</span> <span class="pre">por</span> <span class="pre">el</span> <span class="pre">bosque</span> <span class="pre">aleatorio</span> <span class="pre">son</span> <span class="pre">más</span> <span class="pre">fiables</span> <span class="pre">que</span> <span class="pre">las</span> <span class="pre">proporcionadas</span> <span class="pre">por</span> <span class="pre">un</span> <span class="pre">solo</span> <span class="pre">árbol</span></code>.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plot_feature_importances_cancer</span><span class="p">(</span><span class="n">forest</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/supervised_learning_357_0.png" src="_images/supervised_learning_357_0.png" />
</div>
</div>
<ul class="simple">
<li><p>Como puede ver, <code class="docutils literal notranslate"><span class="pre">el</span> <span class="pre">bosque</span> <span class="pre">aleatorio</span> <span class="pre">da</span> <span class="pre">una</span> <span class="pre">importancia</span> <span class="pre">no</span> <span class="pre">nula</span> <span class="pre">a</span> <span class="pre">muchas</span> <span class="pre">más</span> <span class="pre">características</span> <span class="pre">que</span> <span class="pre">el</span> <span class="pre">árbol</span> <span class="pre">simple</span></code>. Al igual que el árbol de decisión simple, el bosque aleatorio también da importancia a la característica <code class="docutils literal notranslate"><span class="pre">&quot;worst</span> <span class="pre">radius&quot;</span></code>, pero en realidad elige <code class="docutils literal notranslate"><span class="pre">&quot;worst</span> <span class="pre">perimeter&quot;</span></code> como la <code class="docutils literal notranslate"><span class="pre">característica</span> <span class="pre">más</span> <span class="pre">informativa</span></code>. <code class="docutils literal notranslate"><span class="pre">La</span> <span class="pre">aleatoriedad</span> <span class="pre">en</span> <span class="pre">la</span> <span class="pre">construcción</span> <span class="pre">del</span> <span class="pre">bosque</span> <span class="pre">aleatorio</span> <span class="pre">obliga</span> <span class="pre">al</span> <span class="pre">algoritmo</span> <span class="pre">a</span> <span class="pre">considerar</span> <span class="pre">muchas</span> <span class="pre">explicaciones</span> <span class="pre">posibles</span></code>. El resultado es que el bosque aleatorio capta una imagen mucho más amplia de los datos que un árbol simple.</p></li>
</ul>
<div class="tip admonition">
<p class="admonition-title">Observación</p>
<p>La <code class="docutils literal notranslate"><span class="pre">importancia</span> <span class="pre">de</span> <span class="pre">la</span> <span class="pre">característica</span></code> se calcula como la disminución de la impureza del nodo ponderada por la probabilidad de alcanzar ese nodo. <code class="docutils literal notranslate"><span class="pre">La</span> <span class="pre">probabilidad</span> <span class="pre">del</span> <span class="pre">nodo</span> <span class="pre">puede</span> <span class="pre">calcularse</span> <span class="pre">mediante</span> <span class="pre">el</span> <span class="pre">número</span> <span class="pre">de</span> <span class="pre">muestras</span> <span class="pre">que</span> <span class="pre">llegan</span> <span class="pre">al</span> <span class="pre">nodo,</span> <span class="pre">dividido</span> <span class="pre">por</span> <span class="pre">el</span> <span class="pre">número</span> <span class="pre">total</span> <span class="pre">de</span> <span class="pre">muestras.</span> <span class="pre">Cuanto</span> <span class="pre">mayor</span> <span class="pre">sea</span> <span class="pre">el</span> <span class="pre">valor,</span> <span class="pre">más</span> <span class="pre">importante</span> <span class="pre">será</span> <span class="pre">la</span> <span class="pre">característica</span></code>. Si tenemos <span class="math notranslate nohighlight">\(C\)</span> clases totales y <span class="math notranslate nohighlight">\(p(i)\)</span> es la probabilidad de escoger un punto de datos con la clase <span class="math notranslate nohighlight">\(i\)</span>, entonces la <code class="docutils literal notranslate"><span class="pre">impureza</span> <span class="pre">de</span> <span class="pre">Gini</span></code> se calcula como</p>
<div class="math notranslate nohighlight">
\[
G=\sum_{i=1}^{C}p(i)(1-p(i)).
\]</div>
</div>
<p><strong><code class="docutils literal notranslate"><span class="pre">Puntos</span> <span class="pre">fuertes,</span> <span class="pre">puntos</span> <span class="pre">débiles</span> <span class="pre">y</span> <span class="pre">parámetros</span></code></strong></p>
<ul class="simple">
<li><p>Los bosques aleatorios para la regresión y la clasificación se encuentran actualmente entre los métodos de aprendizaje automático más utilizados. <code class="docutils literal notranslate"><span class="pre">Son</span> <span class="pre">muy</span> <span class="pre">potentes,</span> <span class="pre">suelen</span> <span class="pre">funcionar</span> <span class="pre">bien</span> <span class="pre">sin</span> <span class="pre">necesidad</span> <span class="pre">de</span> <span class="pre">ajustar</span> <span class="pre">mucho</span> <span class="pre">los</span> <span class="pre">parámetros</span> <span class="pre">y</span> <span class="pre">no</span> <span class="pre">requieren</span> <span class="pre">el</span> <span class="pre">escalado</span> <span class="pre">de</span> <span class="pre">los</span> <span class="pre">datos</span></code>. Esencialmente, los bosques aleatorios comparten todos los beneficios de los árboles de decisión, mientras que compensan algunas de sus deficiencias. Una razón para seguir utilizando los árboles de decisión es, <strong><code class="docutils literal notranslate"><span class="pre">si</span> <span class="pre">se</span> <span class="pre">necesita</span> <span class="pre">una</span> <span class="pre">representación</span> <span class="pre">compacta</span> <span class="pre">del</span> <span class="pre">proceso</span> <span class="pre">de</span> <span class="pre">toma</span> <span class="pre">de</span> <span class="pre">decisiones</span></code></strong>. Es básicamente imposible interpretar decenas o cientos de árboles en detalle, y los árboles de los bosques aleatorios tienden a ser más profundos que los árboles de decisión (debido al uso de subconjuntos de características). Por lo tanto, si se necesita resumir las predicciones de forma visual para los no expertos, un único árbol de decisión puede ser la mejor opción.</p></li>
<li><p>Aunque la construcción de bosques aleatorios en grandes conjuntos de datos puede llevar algo de tiempo, <code class="docutils literal notranslate"><span class="pre">se</span> <span class="pre">puede</span> <span class="pre">paralelizar</span> <span class="pre">a</span> <span class="pre">través</span> <span class="pre">de</span> <span class="pre">múltiples</span> <span class="pre">núcleos</span> <span class="pre">de</span> <span class="pre">CPU</span> <span class="pre">dentro</span> <span class="pre">de</span> <span class="pre">un</span> <span class="pre">ordenador</span> <span class="pre">fácilmente</span></code>. Si utiliza un procesador multinúcleo (como casi todos los ordenadores modernos),  puede utilizar el parámetro <code class="docutils literal notranslate"><span class="pre">n_jobs</span></code> para ajustar el número de núcleos a utilizar. El uso de más núcleos de la CPU dará lugar a un aumento lineal de la velocidad (utilizando dos núcleos, el entrenamiento del bosque aleatorio será el doble de rápido), pero especificar <code class="docutils literal notranslate"><span class="pre">n_jobs</span></code> mayor que el número de núcleos no ayudará. <code class="docutils literal notranslate"><span class="pre">Puede</span> <span class="pre">establecer</span> <span class="pre">n_jobs=-1</span> <span class="pre">para</span> <span class="pre">utilizar</span> <span class="pre">todos</span> <span class="pre">los</span> <span class="pre">núcleos</span> <span class="pre">en</span> <span class="pre">su</span> <span class="pre">ordenador</span></code>.</p></li>
<li><p>Debe tener en cuenta que los bosques aleatorios, por su naturaleza, son aleatorios, y establecen diferentes estados aleatorios (o no establecen el <code class="docutils literal notranslate"><span class="pre">random_state</span></code> en absoluto) puede cambiar drásticamente el modelo que se construye. <code class="docutils literal notranslate"><span class="pre">Cuanto</span> <span class="pre">más</span> <span class="pre">árboles</span> <span class="pre">haya</span> <span class="pre">en</span> <span class="pre">el</span> <span class="pre">bosque,</span> <span class="pre">más</span> <span class="pre">robusto</span> <span class="pre">será</span> <span class="pre">frente</span> <span class="pre">a</span> <span class="pre">la</span> <span class="pre">elección</span> <span class="pre">del</span> <span class="pre">estado</span> <span class="pre">aleatorio</span></code>. Si quiere tener resultados reproducibles, es importante fijar el <code class="docutils literal notranslate"><span class="pre">random_state</span></code> a caulquier número entero. <code class="docutils literal notranslate"><span class="pre">Los</span> <span class="pre">bosques</span> <span class="pre">aleatorios</span> <span class="pre">no</span> <span class="pre">tienden</span> <span class="pre">a</span> <span class="pre">funcionar</span> <span class="pre">bien</span> <span class="pre">en</span> <span class="pre">datos</span> <span class="pre">muy</span> <span class="pre">dimensionales</span> <span class="pre">y</span> <span class="pre">escasos,</span> <span class="pre">como</span> <span class="pre">los</span> <span class="pre">datos</span> <span class="pre">de</span> <span class="pre">texto</span></code>. Para este tipo de datos, los modelos lineales pueden ser más apropiados. Los bosques aleatorios suelen funcionar bien incluso en conjuntos de datos muy grandes, y el entrenamiento se puede paralelizar fácilmente en muchos núcleos de la CPU de un ordenador potente.  Sin embargo, <code class="docutils literal notranslate"><span class="pre">los</span> <span class="pre">bosques</span> <span class="pre">aleatorios</span> <span class="pre">requieren</span> <span class="pre">más</span> <span class="pre">memoria</span> <span class="pre">y</span> <span class="pre">son</span> <span class="pre">más</span> <span class="pre">lentos</span> <span class="pre">de</span> <span class="pre">entrenar</span> <span class="pre">y</span> <span class="pre">predecir</span> <span class="pre">que</span> <span class="pre">los</span> <span class="pre">modelos</span> <span class="pre">lineales</span></code>. Si el tiempo y la memoria son importantes en una aplicación, puede tener sentido utilizar un modelo lineal en su lugar.</p></li>
<li><p>Los parámetros importantes a ajustar son <code class="docutils literal notranslate"><span class="pre">n_estimators</span> <span class="pre">,</span> <span class="pre">max_features</span></code>, y posiblemente opciones de pre-poda como <code class="docutils literal notranslate"><span class="pre">max_depth</span></code>. En el caso de <code class="docutils literal notranslate"><span class="pre">n_estimators</span></code>, un número mayor es siempre mejor. <code class="docutils literal notranslate"><span class="pre">Promediar</span> <span class="pre">más</span> <span class="pre">árboles</span> <span class="pre">dará</span> <span class="pre">lugar</span> <span class="pre">a</span> <span class="pre">un</span> <span class="pre">conjunto</span> <span class="pre">más</span> <span class="pre">robusto</span> <span class="pre">al</span> <span class="pre">reducir</span> <span class="pre">el</span> <span class="pre">sobreajuste</span></code>. Sin embargo, hay rendimientos decrecientes, y más árboles necesitan más memoria y más tiempo para entrenar. Una regla común es construir “tantos como tenga tiempo/memoria”.  Como se ha descrito anteriormente, <code class="docutils literal notranslate"><span class="pre">max_features</span></code> determina el grado de aleatoriedad de cada árbol, y un <code class="docutils literal notranslate"><span class="pre">max_features</span> <span class="pre">pequeño</span> <span class="pre">reduce</span> <span class="pre">el</span> <span class="pre">sobreajuste</span></code>. En general, es una buena regla general utilizar los valores por defecto: <code class="docutils literal notranslate"><span class="pre">max_features=sqrt(n_features)</span></code> para la clasificación y <code class="docutils literal notranslate"><span class="pre">max_features=log2(n_features)</span></code> para la regresión. Añadir <code class="docutils literal notranslate"><span class="pre">max_features</span></code> o <code class="docutils literal notranslate"><span class="pre">max_leaf_nodes</span></code> puede mejorar a veces el rendimiento. También puede reducir drásticamente los requisitos de espacio y tiempo para el entrenamiento y la predicción.</p></li>
</ul>
<p><strong><code class="docutils literal notranslate"><span class="pre">Árboles</span> <span class="pre">de</span> <span class="pre">regresión</span> <span class="pre">de</span> <span class="pre">gradiente</span> <span class="pre">reforzado</span> <span class="pre">(máquinas</span> <span class="pre">de</span> <span class="pre">gradiente</span> <span class="pre">reforzado)</span></code></strong></p>
<ul class="simple">
<li><p>El árbol de regresión de gradiente reforzado es otro método de conjunto que combina múltiples árboles de decisión. A pesar de la <code class="docutils literal notranslate"><span class="pre">&quot;regresión&quot;</span></code> en el nombre, estos modelos pueden utilizarse para la regresión y la clasificación. A diferencia del enfoque de bosque aleatorio, <code class="docutils literal notranslate"><span class="pre">el</span> <span class="pre">refuerzo</span> <span class="pre">de</span> <span class="pre">gradiente</span> <span class="pre">funciona</span> <span class="pre">construyendo</span> <span class="pre">árboles</span> <span class="pre">en</span> <span class="pre">forma</span> <span class="pre">de</span> <span class="pre">serie,</span> <span class="pre">en</span> <span class="pre">el</span> <span class="pre">que</span> <span class="pre">cada</span> <span class="pre">árbol</span> <span class="pre">trata</span> <span class="pre">de</span> <span class="pre">corregir</span> <span class="pre">los</span> <span class="pre">errores</span> <span class="pre">del</span> <span class="pre">anterior</span></code>. Por defecto, no hay aleatoriedad en los árboles de regresión de gradiente; en su lugar, <code class="docutils literal notranslate"><span class="pre">se</span> <span class="pre">utiliza</span> <span class="pre">una</span> <span class="pre">fuerte</span> <span class="pre">pre-poda</span></code>. Los árboles de impulso por gradiente suelen utilizar árboles muy poco profundos, de una a cinco profundidades, lo que hace que el modelo sea más pequeño en términos de memoria y que las predicciones sean más rápidas.</p></li>
<li><p>La idea principal del <code class="docutils literal notranslate"><span class="pre">gradient</span> <span class="pre">boosting</span></code> es combinar muchos modelos simples (en este contexto conocidos como aprendices débiles), como árboles poco profundos. Cada árbol sólo puede proporcionar buenas predicciones sobre una parte de los datos, por lo que se añaden más y más árboles para mejorar el rendimiento. <code class="docutils literal notranslate"><span class="pre">Los</span> <span class="pre">árboles</span> <span class="pre">con</span> <span class="pre">refuerzo</span> <span class="pre">de</span> <span class="pre">gradiente</span> <span class="pre">suelen</span> <span class="pre">ser</span> <span class="pre">los</span> <span class="pre">ganadores</span> <span class="pre">de</span> <span class="pre">los</span> <span class="pre">concursos</span> <span class="pre">de</span> <span class="pre">aprendizaje</span> <span class="pre">automático</span> <span class="pre">y</span> <span class="pre">se</span> <span class="pre">utilizan</span> <span class="pre">mucho</span> <span class="pre">en</span> <span class="pre">la</span> <span class="pre">industria</span></code>. Suelen ser un poco más sensibles a los ajustes de los parámetros que los bosques aleatorios, pero pueden proporcionar una mayor precisión si los parámetros se ajustan correctamente.</p></li>
<li><p>Aparte de la pre-poda y el número de árboles en el conjunto, otro parámetro importante del gradient boosting es la <code class="docutils literal notranslate"><span class="pre">tasa</span> <span class="pre">de</span> <span class="pre">aprendizaje,</span> <span class="pre">que</span> <span class="pre">controla</span> <span class="pre">la</span> <span class="pre">intensidad</span> <span class="pre">con</span> <span class="pre">la</span> <span class="pre">que</span> <span class="pre">cada</span> <span class="pre">árbol</span> <span class="pre">trata</span> <span class="pre">de</span> <span class="pre">corregir</span> <span class="pre">los</span> <span class="pre">errores</span> <span class="pre">de</span> <span class="pre">los</span> <span class="pre">árboles</span> <span class="pre">anteriores</span></code>. Una tasa de aprendizaje alta significa que cada árbol puede hacer correcciones más fuertes, lo que permite modelos más complejos. Si se añaden más árboles al conjunto, lo que puede conseguirse aumentando <code class="docutils literal notranslate"><span class="pre">n_estimators</span></code>, también aumenta la complejidad del modelo, ya que éste tiene más oportunidades de corregir errores en el conjunto de entrenamiento.</p></li>
</ul>
<ul class="simple">
<li><p>Este es un ejemplo del uso del clasificador <code class="docutils literal notranslate"><span class="pre">GradientBoosting</span></code> en el conjunto de datos del <code class="docutils literal notranslate"><span class="pre">Breast</span> <span class="pre">Cancer</span></code>. Por defecto, se utilizan 100 árboles de profundidad máxima 3 y una tasa de aprendizaje de 0.1</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">GradientBoostingClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_breast_cancer</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="n">cancer</span> <span class="o">=</span> <span class="n">load_breast_cancer</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">cancer</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">cancer</span><span class="o">.</span><span class="n">target</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">gbrt</span> <span class="o">=</span> <span class="n">GradientBoostingClassifier</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">gbrt</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Accuracy on training set: </span><span class="si">{:.3f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">gbrt</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Accuracy on test set: </span><span class="si">{:.3f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">gbrt</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Accuracy on training set: 1.000
Accuracy on test set: 0.965
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Como la <code class="docutils literal notranslate"><span class="pre">precisión</span> <span class="pre">del</span> <span class="pre">conjunto</span> <span class="pre">de</span> <span class="pre">entrenamiento</span> <span class="pre">es</span> <span class="pre">del</span> <span class="pre">100%,</span> <span class="pre">es</span> <span class="pre">probable</span> <span class="pre">que</span> <span class="pre">estemos</span> <span class="pre">sobreajustando.</span> <span class="pre">Para</span> <span class="pre">reducir</span> <span class="pre">el</span> <span class="pre">sobreajuste,</span> <span class="pre">podemos</span> <span class="pre">aplicar</span> <span class="pre">una</span> <span class="pre">pre-poda</span> <span class="pre">más</span> <span class="pre">fuerte</span> <span class="pre">limitando</span> <span class="pre">la</span> <span class="pre">profundidad</span> <span class="pre">máxima</span> <span class="pre">o</span> <span class="pre">reducir</span> <span class="pre">la</span> <span class="pre">tasa</span> <span class="pre">de</span> <span class="pre">aprendizaje</span></code></p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">gbrt</span> <span class="o">=</span> <span class="n">GradientBoostingClassifier</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">max_depth</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">gbrt</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Accuracy on training set: </span><span class="si">{:.3f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">gbrt</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Accuracy on test set: </span><span class="si">{:.3f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">gbrt</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Accuracy on training set: 0.991
Accuracy on test set: 0.972
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">gbrt</span> <span class="o">=</span> <span class="n">GradientBoostingClassifier</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>
<span class="n">gbrt</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Accuracy on training set: </span><span class="si">{:.3f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">gbrt</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Accuracy on test set: </span><span class="si">{:.3f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">gbrt</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Accuracy on training set: 0.988
Accuracy on test set: 0.965
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Ambos métodos para disminuir la complejidad del modelo <code class="docutils literal notranslate"><span class="pre">redujeron</span> <span class="pre">la</span> <span class="pre">precisión</span> <span class="pre">del</span> <span class="pre">conjunto</span> <span class="pre">de</span> <span class="pre">entrenamiento,</span> <span class="pre">como</span> <span class="pre">era</span> <span class="pre">de</span> <span class="pre">esperar</span></code>. En este caso, <code class="docutils literal notranslate"><span class="pre">la</span> <span class="pre">reducción</span> <span class="pre">de</span> <span class="pre">la</span> <span class="pre">profundidad</span> <span class="pre">máxima</span> <span class="pre">de</span> <span class="pre">los</span> <span class="pre">árboles</span> <span class="pre">proporcionó</span> <span class="pre">una</span> <span class="pre">mejora</span> <span class="pre">significativa</span> <span class="pre">del</span> <span class="pre">modelo,</span> <span class="pre">mientras</span> <span class="pre">que</span> <span class="pre">la</span> <span class="pre">reducción</span> <span class="pre">de</span> <span class="pre">la</span> <span class="pre">tasa</span> <span class="pre">de</span> <span class="pre">aprendizaje</span> <span class="pre">sólo</span> <span class="pre">aumentó</span> <span class="pre">la</span> <span class="pre">precisión</span> <span class="pre">del</span> <span class="pre">conjunto</span> <span class="pre">de</span> <span class="pre">entrenamiento</span> <span class="pre">ligeramente</span></code>. En cuanto a los otros modelos basados en árboles de decisión, podemos volver a visualizar las características para obtener más información sobre nuestro modelo. Como utilizamos 100 árboles, es poco práctico inspeccionarlos todos, aunque todos tengan una profundidad de 1.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">gbrt</span> <span class="o">=</span> <span class="n">GradientBoostingClassifier</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">max_depth</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">gbrt</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">plot_feature_importances_cancer</span><span class="p">(</span><span class="n">gbrt</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/supervised_learning_371_0.png" src="_images/supervised_learning_371_0.png" />
</div>
</div>
<ul class="simple">
<li><p>Podemos ver que las importancias de las características de los árboles <code class="docutils literal notranslate"><span class="pre">gradient-boost</span></code> son algo similares a las de los bosques aleatorios, aunque el refuerzo del gradiente ignora por completo algunas de las características. Como tanto el refuerzo de gradiente como los bosques aleatorios funcionan bien en tipos de datos similares, <code class="docutils literal notranslate"><span class="pre">un</span> <span class="pre">enfoque</span> <span class="pre">común</span> <span class="pre">es</span> <span class="pre">probar</span> <span class="pre">primero</span> <span class="pre">los</span> <span class="pre">bosques</span> <span class="pre">aleatorios,</span> <span class="pre">que</span> <span class="pre">funcionan</span> <span class="pre">con</span> <span class="pre">bastante</span> <span class="pre">solidez.</span> <span class="pre">Si</span> <span class="pre">los</span> <span class="pre">bosques</span> <span class="pre">aleatorios</span> <span class="pre">funcionan</span> <span class="pre">bien,</span> <span class="pre">pero</span> <span class="pre">el</span> <span class="pre">tiempo</span> <span class="pre">de</span> <span class="pre">predicción</span> <span class="pre">es</span> <span class="pre">un</span> <span class="pre">problema,</span> <span class="pre">o</span> <span class="pre">si</span> <span class="pre">es</span> <span class="pre">importante</span> <span class="pre">exprimir</span> <span class="pre">el</span> <span class="pre">último</span> <span class="pre">porcentaje</span> <span class="pre">de</span> <span class="pre">precisión</span> <span class="pre">del</span> <span class="pre">modelo</span> <span class="pre">de</span> <span class="pre">aprendizaje</span> <span class="pre">automático,</span> <span class="pre">pasar</span> <span class="pre">a</span> <span class="pre">la</span> <span class="pre">refuerzo</span> <span class="pre">por</span> <span class="pre">gradiente</span> <span class="pre">suele</span> <span class="pre">ser</span> <span class="pre">útil</span></code>.</p></li>
<li><p><strong><code class="docutils literal notranslate"><span class="pre">Si</span> <span class="pre">quiere</span> <span class="pre">aplicar</span> <span class="pre">el</span> <span class="pre">refuerzo</span> <span class="pre">de</span> <span class="pre">gradiente</span> <span class="pre">a</span> <span class="pre">un</span> <span class="pre">problema</span> <span class="pre">a</span> <span class="pre">gran</span> <span class="pre">escala,</span> <span class="pre">puede</span> <span class="pre">que</span> <span class="pre">merezca</span> <span class="pre">la</span> <span class="pre">pena</span> <span class="pre">investigar</span> <span class="pre">el</span> <span class="pre">paquete</span> <span class="pre">xgboost</span> <span class="pre">y</span> <span class="pre">su</span> <span class="pre">interfaz</span> <span class="pre">de</span> <span class="pre">Python,</span> <span class="pre">que</span> <span class="pre">hasta</span> <span class="pre">el</span> <span class="pre">momento</span> <span class="pre">es</span> <span class="pre">más</span> <span class="pre">rápido</span> <span class="pre">(y</span> <span class="pre">a</span> <span class="pre">veces</span> <span class="pre">más</span> <span class="pre">fácil</span> <span class="pre">de</span> <span class="pre">usar)</span> <span class="pre">que</span> <span class="pre">la</span> <span class="pre">implementación</span> <span class="pre">de</span> <span class="pre">scikit-learn</span> <span class="pre">en</span> <span class="pre">muchos</span> <span class="pre">conjuntos</span> <span class="pre">de</span> <span class="pre">datos</span></code></strong>.</p></li>
</ul>
<p><strong><code class="docutils literal notranslate"><span class="pre">Puntos</span> <span class="pre">fuertes,</span> <span class="pre">puntos</span> <span class="pre">débiles</span> <span class="pre">y</span> <span class="pre">parámetros</span></code></strong></p>
<ul class="simple">
<li><p>Los árboles de decisión con refuerzo de gradiente se encuentran entre los modelos más potentes y utilizados para el aprendizaje supervisado. <code class="docutils literal notranslate"><span class="pre">Su</span> <span class="pre">principal</span> <span class="pre">inconveniente</span> <span class="pre">es</span> <span class="pre">que</span> <span class="pre">requieren</span> <span class="pre">un</span> <span class="pre">ajuste</span> <span class="pre">cuidadoso</span> <span class="pre">de</span> <span class="pre">los</span> <span class="pre">parámetros</span> <span class="pre">y</span> <span class="pre">pueden</span> <span class="pre">tardar</span> <span class="pre">mucho</span> <span class="pre">tiempo</span> <span class="pre">de</span> <span class="pre">entrenamiento</span></code>. Al igual que otros modelos basados en árboles, el algoritmo funciona bien sin escalar y con una mezcla de características binarias y continuas. Al igual que otros modelos basados en árboles tampoco suele funcionar bien con datos dispersos de alta dimensión.</p></li>
<li><p>Los principales parámetros de los modelos de árbol de gradiente reforzado son el número de árboles, <code class="docutils literal notranslate"><span class="pre">n_estimators</span></code>, y el <code class="docutils literal notranslate"><span class="pre">learning_rate</span></code> que <code class="docutils literal notranslate"><span class="pre">controla</span> <span class="pre">el</span> <span class="pre">grado</span> <span class="pre">en</span> <span class="pre">que</span> <span class="pre">cada</span> <span class="pre">árbol</span> <span class="pre">puede</span> <span class="pre">corregir</span> <span class="pre">los</span> <span class="pre">errores</span> <span class="pre">de</span> <span class="pre">los</span> <span class="pre">árboles</span> <span class="pre">anteriores</span></code>. Estos dos parámetros están muy interconectados, ya que una tasa de aprendizaje más baja significa que se necesitan más árboles para construir un modelo de complejidad similar. A diferencia de los bosques aleatorios, en los que un valor de <code class="docutils literal notranslate"><span class="pre">n_estimators</span></code> es siempre mejor, el aumento de <code class="docutils literal notranslate"><span class="pre">n_estimators</span></code> en el <code class="docutils literal notranslate"><span class="pre">gradient</span> <span class="pre">boosting</span></code> conduce a un modelo más complejo, lo que puede llevar a un sobreajuste. Una práctica común es ajustar <code class="docutils literal notranslate"><span class="pre">n_estimators</span></code> dependiendo del presupuesto de tiempo y memoria, y luego buscar sobre diferentes tasas de aprendizaje.</p></li>
<li><p>Otro parámetro importante es <code class="docutils literal notranslate"><span class="pre">max_depth</span></code> (o alternativamente <code class="docutils literal notranslate"><span class="pre">max_leaf_nodes</span></code>), para reducir la complejidad de cada árbol. <code class="docutils literal notranslate"><span class="pre">Por</span> <span class="pre">lo</span> <span class="pre">general,</span> <span class="pre">la</span> <span class="pre">profundidad</span> <span class="pre">máxima</span> <span class="pre">es</span> <span class="pre">muy</span> <span class="pre">baja</span> <span class="pre">para</span> <span class="pre">los</span> <span class="pre">modelos</span> <span class="pre">de</span> <span class="pre">gradiente,</span> <span class="pre">a</span> <span class="pre">menudo</span> <span class="pre">no</span> <span class="pre">más</span> <span class="pre">allá</span> <span class="pre">de</span> <span class="pre">cinco</span> <span class="pre">divisiones</span></code>.</p></li>
</ul>
</section>
</section>
<section id="maquinas-de-vectores-de-soporte">
<h2>Máquinas de vectores de soporte<a class="headerlink" href="#maquinas-de-vectores-de-soporte" title="Permalink to this headline">#</a></h2>
<p><strong><code class="docutils literal notranslate"><span class="pre">Introducción</span></code></strong></p>
<ul class="simple">
<li><p>Las <code class="docutils literal notranslate"><span class="pre">máquinas</span> <span class="pre">de</span> <span class="pre">vectores</span> <span class="pre">de</span> <span class="pre">soporte</span> <span class="pre">(SVM)</span></code> propuestas por <code class="docutils literal notranslate"><span class="pre">Vapnik</span> <span class="pre">(1996,</span> <span class="pre">1998)</span></code>, se caracterizan por ser un proceso interno de construcción de reglas de clasificación, bastante diferente al de las de los métodos estadísticos. Las <code class="docutils literal notranslate"><span class="pre">SVM</span></code> suelen ser eficaces en casos en los que los métodos de clasificación tradicionales no lo son, como por ejemplo, los problemas basados en datos con estructura no lineal, además las <code class="docutils literal notranslate"><span class="pre">SVM</span></code> se han adaptado y aplicado en muchos campos de investigación. En esta sección, nos centramos en las <code class="docutils literal notranslate"><span class="pre">SVM</span></code> para la solución de problemas de regresión y clasificación, así como también el proceso de construcción, luego abordaremos los pasos de su extensión, de sistemas lineales a sistemas no lineales.</p></li>
<li><p>El paradigma algorítmico de las <code class="docutils literal notranslate"><span class="pre">SVM</span></code> aborda el reto de la complejidad de la muestra mediante la busqueda de separadores de “mayor margen”. A grandes rasgos, un semiespacio separa un conjunto de entrenamiento con un gran margen si todos los ejemplos no sólo están en el lado correcto del hiperplano de separación, sino también lejos de él. Restringir el algoritmo a la salida de un separador de gran margen puede producir una complejidad de muestra pequeña, incluso si la dimensionalidad del espacio de características es alta (e incluso infinita). Introduciremos el concepto de margen y lo relacionamos con el paradigma de minimización de pérdidas regularizadas.</p></li>
</ul>
<section id="analisis">
<h3>Análisis<a class="headerlink" href="#analisis" title="Permalink to this headline">#</a></h3>
</section>
<section id="espacios-de-hilbert-con-kernel-reproductor">
<h3>Espacios de Hilbert con Kernel reproductor<a class="headerlink" href="#espacios-de-hilbert-con-kernel-reproductor" title="Permalink to this headline">#</a></h3>
<p>Sea <span class="math notranslate nohighlight">\(H\)</span> un espacio lineal de funciones reales definidas sobre <span class="math notranslate nohighlight">\(\mathcal{X}\subseteq\mathcal{R}^{l}\)</span>. Además, suponga que <span class="math notranslate nohighlight">\(H\)</span> es un espacio de Hilbert, con producto interno <span class="math notranslate nohighlight">\(\langle\cdot,\cdot\rangle_{H}\)</span> que induce la norma <span class="math notranslate nohighlight">\(\|\cdot\|_{H}\)</span>, con respecto a la cual <span class="math notranslate nohighlight">\(H\)</span> es completo.</p>
<div class="proof definition admonition" id="def_hilbert_rep">
<p class="admonition-title"><span class="caption-number">Definition 1 </span></p>
<section class="definition-content" id="proof-content">
<p>Un espacio de Hilbert <span class="math notranslate nohighlight">\(H\)</span> es llamado <code class="docutils literal notranslate"><span class="pre">espacio</span> <span class="pre">de</span> <span class="pre">Hilbert</span> <span class="pre">con</span> <span class="pre">kernel</span> <span class="pre">reproductor</span> <span class="pre">(RKHS)</span></code> si existe una función:</p>
<div class="math notranslate nohighlight">
\[
\kappa:\mathcal{X}\times\mathcal{X}\mapsto\mathbb{R}
\]</div>
<p>con las siguientes propiedades:</p>
<ul class="simple">
<li><p>Para cada <span class="math notranslate nohighlight">\(\boldsymbol{x}\in\mathcal{X},~\kappa(\cdot, x)\)</span> pertenece a <span class="math notranslate nohighlight">\(H\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(\kappa(\cdot, \cdot)\)</span> tiene la llamada propiedad de reproducción, esto es:</p></li>
</ul>
<div class="math notranslate nohighlight" id="equation-prop-reproductora">
<span class="eqno">(18)<a class="headerlink" href="#equation-prop-reproductora" title="Permalink to this equation">#</a></span>\[
f(\boldsymbol{x})=\langle f, \kappa(\cdot, \boldsymbol{x})\rangle,\quad\forall f\in H,~\forall \boldsymbol{x}\in\mathcal{X}
\]</div>
</section>
</div><ul class="simple">
<li><p>Una consecuencia directa de la propiedad reproductora es, si definimos <span class="math notranslate nohighlight">\(f(\cdot)=\kappa(\cdot, \boldsymbol{y}),~\boldsymbol{y}\in\mathcal{X}\)</span> entonces</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
\kappa(\boldsymbol{x}, \boldsymbol{y})=\langle\kappa(\cdot, \boldsymbol{y}), \kappa(\cdot, \boldsymbol{x})\rangle=\langle\kappa(\cdot, \boldsymbol{x}), \kappa(\cdot, \boldsymbol{y})\rangle=\kappa(\boldsymbol{y}, \boldsymbol{x})
\]</div>
<div class="proof definition admonition" id="def_features_map">
<p class="admonition-title"><span class="caption-number">Definition 2 </span></p>
<section class="definition-content" id="proof-content">
<p>Sea <span class="math notranslate nohighlight">\(H\)</span> un (RKHS) asociado con una función kernel <span class="math notranslate nohighlight">\(\kappa(\cdot, \cdot)\)</span> y <span class="math notranslate nohighlight">\(\mathcal{X}\)</span> un conjunto de elementos. Entonces el mapeo</p>
<div class="math notranslate nohighlight">
\[
\mathcal{X}\ni\boldsymbol{x}\mapsto\Phi(\boldsymbol{x}):=\kappa(\cdot, \boldsymbol{x})\in H
\]</div>
<p>es conocido como <code class="docutils literal notranslate"><span class="pre">mapeo</span> <span class="pre">de</span> <span class="pre">características</span></code> y el espacio <span class="math notranslate nohighlight">\(H\)</span> es el <code class="docutils literal notranslate"><span class="pre">espacio</span> <span class="pre">de</span> <span class="pre">características</span></code>. Esto es <span class="math notranslate nohighlight">\(\Phi\)</span> mapea cada vector <span class="math notranslate nohighlight">\(\boldsymbol{x}\in\mathcal{X}\)</span> en el (RKHS) <span class="math notranslate nohighlight">\(H\)</span>.</p>
</section>
</div><ul class="simple">
<li><p><span class="math notranslate nohighlight">\(H\)</span> puede ser de dimensión finita o inifinita y sus elementos pueden ser funciones. Esto es, cada punto de entrenamiento es mapeado en un espacio de funciones. Si <span class="math notranslate nohighlight">\(H\)</span> es de dimensión finita, por ejemplo el Espacio Euclidiano <span class="math notranslate nohighlight">\(\mathbb{R}^{k},~\Phi(\boldsymbol{x})\in\mathbb{R}^{k}\)</span>.</p></li>
<li><p>Consideraremos el caso de dimensión infinita cuyas imágenes son funciones de <span class="math notranslate nohighlight">\(\Phi(\cdot)\)</span>. Veamos las ventajas de este mapeo, del espacio original a otro de dimensión infinita (RKHS).</p></li>
</ul>
<div class="proof definition admonition" id="def_kernel_trick">
<p class="admonition-title"><span class="caption-number">Definition 3 </span></p>
<section class="definition-content" id="proof-content">
<p>Sean <span class="math notranslate nohighlight">\(\boldsymbol{x}, \boldsymbol{y}\in\mathcal{X}\subseteq\mathbb{R}^{l}\)</span>, entonces el producto interno del respectivo mapeo de imágenes es escrito como:</p>
<div class="math notranslate nohighlight">
\[
\langle\Phi(\boldsymbol{x}), \Phi(\boldsymbol{y})\rangle_{H}=\langle \kappa(\cdot, \boldsymbol{x}), \kappa(\cdot, \boldsymbol{y})\rangle
\]</div>
<p>o</p>
<div class="math notranslate nohighlight">
\[
\langle\Phi(\boldsymbol{x}), \Phi(\boldsymbol{y})\rangle_{H}=\kappa(\boldsymbol{x}, \boldsymbol{y}),\quad\text{Kernel trick}
\]</div>
</section>
</div><ul class="simple">
<li><p>Empleando este tipo de mapeo a nuestro problema, calculamos operaciones de propucto interno en <span class="math notranslate nohighlight">\(H\)</span> en una manera eficiente, vía evaluación de funciones sobre el espacio de baja dimensión.</p></li>
</ul>
<div class="proof property admonition" id="props_features_map">
<p class="admonition-title"><span class="caption-number">Property 2 </span></p>
<section class="property-content" id="proof-content">
<p>El mapeo <span class="math notranslate nohighlight">\(\Phi(\cdot)\)</span> satisface las siguientes propiedades</p>
<ul class="simple">
<li><p>Mapea implicitamente inputs (datos de entrenamiento) en un espacio RKHS</p></li>
<li><p>Soluciona tareas de estimación lineal en <span class="math notranslate nohighlight">\(H\)</span>, involucrando las imágenes:</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
\Phi(x_{n}),~n=1,2,\dots,N.
\]</div>
<ul class="simple">
<li><p>Proyecta el algoritmo que soluciona problemas de parámetros desconcoidos, en términos del producto interno en la forma:</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
\langle\Phi(x_{i}), \Phi(x_{j})\rangle,\quad i,j=1,2,\dots,N
\]</div>
<ul class="simple">
<li><p>Considera la evaluación kernel como el producto interno:</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
\langle\Phi(x_{i}),\Phi(x_{j})\rangle=\kappa(x_{i}, x_{j}).
\]</div>
</section>
</div><ul class="simple">
<li><p>Nótese que este procedimiento de mapeo explicito es necesario para calcular la operación kernel en el último paso. La forma especifica de <span class="math notranslate nohighlight">\(\kappa(\cdot,\cdot)\)</span> no concierne en el análisis.</p></li>
</ul>
<figure class="align-center" id="fig-kernel-map-ilust">
<a class="reference internal image-reference" href="_images/kernel_map_ilust.png"><img alt="_images/kernel_map_ilust.png" src="_images/kernel_map_ilust.png" style="width: 463.4px; height: 354.2px;" /></a>
</figure>
<div class="proof example admonition" id="ej_feature_map">
<p class="admonition-title"><span class="caption-number">Example 1 </span></p>
<section class="example-content" id="proof-content">
<p>Considere el caso del espacio de 2 dimensiones y el mapeo</p>
<div class="math notranslate nohighlight">
\[
\mathbb{R}^{2}\ni \boldsymbol{x}\mapsto\Phi(x)=(x_{1}^{2}, \sqrt{2}x_{1}x{2}, x_{2}^{2})\in\mathbb{R}^{3}
\]</div>
<p>Entonces, dados los vectores <span class="math notranslate nohighlight">\(\boldsymbol{x}=(x_{1}, x_{2})^{T}\)</span> y <span class="math notranslate nohighlight">\(\boldsymbol{y}=(y_{1}, y_{2})^{T}\)</span>, es facil ver que</p>
<div class="math notranslate nohighlight">
\[
\kappa(\boldsymbol{x}, \boldsymbol{y})=\langle\Phi(\boldsymbol{x}), \Phi(\boldsymbol{y})\rangle_{\mathbb{R}^{3}}=\Phi(\boldsymbol{x})^{T}\Phi(\boldsymbol{y})=(x_{1}y_{1}+x_{2}y_{2})^{2}=(\boldsymbol{x}^{T}\boldsymbol{y})^{2}
\]</div>
<p>Es decir, el producto interior en el espacio tridimensional, después del mapeo, está dado en términos de una función de las variables en el espacio original.</p>
</section>
</div><div class="proof property admonition" id="prop_kcompacto">
<p class="admonition-title"><span class="caption-number">Property 3 </span></p>
<section class="property-content" id="proof-content">
<p>Sea <span class="math notranslate nohighlight">\(\mathcal{X}\)</span> un conjunto de puntos. Tipicamente <span class="math notranslate nohighlight">\(\mathcal{X}\subseteq\mathbb{R}^{l}\)</span> es compacto, esto es, cada sucesión en <span class="math notranslate nohighlight">\(X\)</span> tiene una subsucesión convergente. Sea <span class="math notranslate nohighlight">\(\kappa\)</span> la función</p>
<div class="math notranslate nohighlight">
\[
\kappa:\mathcal{X}\times\mathcal{X}\mapsto\mathbb{R}.
\]</div>
<p>La función <span class="math notranslate nohighlight">\(\kappa\)</span> es llamada kernel definido positvo si satisface</p>
<div class="math notranslate nohighlight">
\[
\sum_{n=1}^{N}\sum_{m=1}^{N}a_{n}a_{m}\kappa(x_{n}, x_{m})\geq0,
\]</div>
<p>para cualquier número real <span class="math notranslate nohighlight">\(a_{n}, a_{m}\)</span> y cualquier punto <span class="math notranslate nohighlight">\(x_{n}, x_{m}\in\mathcal{X}\)</span> y cualquier <span class="math notranslate nohighlight">\(N\in\mathbb{N}\)</span>. O equivalentemente, si definimos la matriz <span class="math notranslate nohighlight">\(K\)</span>, de orden <span class="math notranslate nohighlight">\(N\)</span></p>
<div class="math notranslate nohighlight">
\[\begin{split}
K=
\begin{pmatrix}
k(x_{1}, x_{1}) &amp; \cdots &amp; k(x_{1}, x_{N})\\
\vdots &amp; \vdots &amp; \vdots\\
k(x_{N}, x_{1}) &amp; \cdots &amp; k(x_{N}, x_{N})\\
\end{pmatrix}
\end{split}\]</div>
<p><span class="math notranslate nohighlight">\(a^{T}Ka\geq0\)</span>, donde <span class="math notranslate nohighlight">\(a=(a_{1}, a_{2},\dots, a_{N})^{T}\)</span>.</p>
</section>
</div><div class="proof example admonition" id="ej_kernel_functions">
<p class="admonition-title"><span class="caption-number">Example 2 </span></p>
<section class="example-content" id="proof-content">
<p>Los siguientes son algunos ejemplos típicos de funciones kernel, las cuales son comunmente usadas en varias aplicaciones.</p>
<ul>
<li><p>El <code class="docutils literal notranslate"><span class="pre">kernel</span> <span class="pre">gausiano</span></code> está entre las más populares y está dado por la función</p>
<div class="math notranslate nohighlight">
\[\begin{split}
    \\[1mm]
    \kappa(\boldsymbol{x}, \boldsymbol{y})=\exp\left(-\frac{\|\boldsymbol{x}-\boldsymbol{y}\|}{2\sigma^2}\right),\quad\sigma&gt;0
    \end{split}\]</div>
</li>
<li><p>El <code class="docutils literal notranslate"><span class="pre">kernel</span> <span class="pre">polinomial</span></code> homogéneo tiene la forma</p>
<div class="math notranslate nohighlight">
\[\begin{split}
    \\[1mm]
    \kappa(\boldsymbol{x}, \boldsymbol{y})=(\boldsymbol{x}^{T}\boldsymbol{y})^{r},
    \end{split}\]</div>
<p>donde <span class="math notranslate nohighlight">\(r\)</span> es un parámetro.</p>
</li>
<li><p>El <code class="docutils literal notranslate"><span class="pre">kernel</span> <span class="pre">polinomial</span> <span class="pre">no-homogéneo</span></code> tiene la forma</p>
<div class="math notranslate nohighlight">
\[\begin{split}
    \\[1mm]
    \kappa(\boldsymbol{x}, \boldsymbol{y})=(\boldsymbol{x}^{T}\boldsymbol{y}+c)^{r},
    \end{split}\]</div>
<p>donde <span class="math notranslate nohighlight">\(c\geq0,~r\)</span> son parámetros.</p>
</li>
<li><p>El <code class="docutils literal notranslate"><span class="pre">kernel</span> <span class="pre">laplaciano</span></code> está dado por</p>
<div class="math notranslate nohighlight">
\[\begin{split}
    \\[2mm]
    \kappa(\boldsymbol{x}, \boldsymbol{y})=\exp(-t\|\boldsymbol{x}-\boldsymbol{y}\|),
    \end{split}\]</div>
<p>donde <span class="math notranslate nohighlight">\(t&gt;0\)</span> es un parámetro.</p>
</li>
</ul>
</section>
</div><p><strong><code class="docutils literal notranslate"><span class="pre">Construción</span> <span class="pre">de</span> <span class="pre">kernels</span></code></strong></p>
<p>Además de los ejemplos previos, se pueden construir otros kernels aplicando las siguientes propiedades</p>
<ul>
<li><p>Si</p>
<div class="math notranslate nohighlight">
\[\begin{split}
    \kappa_{1}(\boldsymbol{x}, \boldsymbol{y}):\mathcal{X}\times\mathcal{X}\mapsto\mathbb{R}\\
    \kappa_{1}(\boldsymbol{x}, \boldsymbol{y}):\mathcal{X}\times\mathcal{X}\mapsto\mathbb{R}\end{split}\]</div>
<p>son kernels, entonces</p>
<div class="math notranslate nohighlight">
\[\begin{split}
    \kappa(\boldsymbol{x}, \boldsymbol{y})=\kappa_{1}(\boldsymbol{x}, \boldsymbol{y})+\kappa_{2}(\boldsymbol{x}, \boldsymbol{y})\\
    \kappa(\boldsymbol{x}, \boldsymbol{y})=\alpha\kappa_{1}(\boldsymbol{x}, \boldsymbol{y})\end{split}\]</div>
<p>y</p>
<div class="math notranslate nohighlight">
\[
    \kappa(\boldsymbol{x}, \boldsymbol{y})=\kappa_{1}(\boldsymbol{x}, \boldsymbol{y})\kappa_{2}(\boldsymbol{x}, \boldsymbol{y}),
    \]</div>
<p>son kernels.</p>
</li>
</ul>
<ul>
<li><p>Sea</p>
<div class="math notranslate nohighlight">
\[
    f:\mathcal{X}\mapsto\mathbb{R}
    \]</div>
<p>entonces</p>
<div class="math notranslate nohighlight">
\[
    \kappa(\boldsymbol{x}, \boldsymbol{y})=f(\boldsymbol{x})f(\boldsymbol{y})
    \]</div>
<p>es un kernel</p>
</li>
</ul>
<ul>
<li><p>Sea una función</p>
<div class="math notranslate nohighlight">
\[
    g:\mathcal{X}\mapsto\mathbb{R}^{l}
    \]</div>
<p>y una función kernel</p>
<div class="math notranslate nohighlight">
\[
    \kappa_{1}(\cdot, \cdot):\mathbb{R}^{l}\times\mathbb{R}^{l}\mapsto\mathbb{R}.
    \]</div>
<p>Entonces</p>
<div class="math notranslate nohighlight">
\[
    \kappa(\boldsymbol{x}, \boldsymbol{y})=\kappa_{1}(g(\boldsymbol{x}), g(\boldsymbol{y}))
    \]</div>
<p>es también un kernel.</p>
</li>
</ul>
<ul>
<li><p>Sea <span class="math notranslate nohighlight">\(A\)</span> una matriz definida positiva con dimensión <span class="math notranslate nohighlight">\(l\times l\)</span>. Entonces</p>
<div class="math notranslate nohighlight">
\[\begin{split}
    \\[1mm]
    \kappa(\boldsymbol{x}, \boldsymbol{y})=\boldsymbol{x}^{T}A\boldsymbol{y}
    \end{split}\]</div>
<p>es un kernel.</p>
</li>
</ul>
<ul>
<li><p>Si</p>
<div class="math notranslate nohighlight">
\[
    \kappa_{1}(\boldsymbol{x}, \boldsymbol{y}):\mathcal{X}\times\mathcal{X}\mapsto\mathbb{R},
    \]</div>
<p>entonces</p>
<div class="math notranslate nohighlight">
\[
    \kappa(\boldsymbol{x}, \boldsymbol{y})=\exp(\kappa_{1}(\boldsymbol{x}, \boldsymbol{y}))
    \]</div>
<p>es también un kernel, y si <span class="math notranslate nohighlight">\(p(\cdot)\)</span> es un polinomio con coeficientes no negativos,</p>
<div class="math notranslate nohighlight">
\[\begin{split}
    \\[1mm]
    \kappa(\boldsymbol{x}, \boldsymbol{y})=p(\kappa_{1}(\boldsymbol{x}, \boldsymbol{y}))
    \end{split}\]</div>
<p>también es un kernel.</p>
</li>
</ul>
<p>Para mas información sobre los kernel y su construción (ver <span id="id9">[<a class="reference internal" href="#id30" title="Thomas Hofmann, Bernhard Schölkopf, and Alexander J Smola. Kernel methods in machine learning. The annals of statistics, 36(3):1171–1220, 2008.">Hofmann <em>et al.</em>, 2008</a>, <a class="reference internal" href="#id31" title="John Shawe-Taylor, Nello Cristianini, and others. Kernel methods for pattern analysis. Cambridge university press, 2004.">Shawe-Taylor <em>et al.</em>, 2004</a>, <a class="reference internal" href="#id32" title="Konstantinos Slavakis, Pantelis Bouboulis, and Sergios Theodoridis. Online learning in reproducing kernel hilbert spaces. In Academic Press Library in Signal Processing, volume 1, pages 883–987. Elsevier, 2014.">Slavakis <em>et al.</em>, 2014</a>]</span>).</p>
</section>
<section id="teorema-de-representacion">
<h3>Teorema de representación<a class="headerlink" href="#teorema-de-representacion" title="Permalink to this headline">#</a></h3>
<ul class="simple">
<li><p>El teorema que se presentará en esta sección es de gran importancia desde un punto de vista practico. Este nos permite llevar a cabo,  optimización empirica de funciones de pérdida, basado en un conjunto finito de puntos de entrenamiento, en una manera muy eficiente si la función a estimar pertenece a un espacio de dimensión alta o incluso infinita <span class="math notranslate nohighlight">\(H\)</span>.</p></li>
</ul>
<div class="proof theorem admonition" id="th_representation">
<p class="admonition-title"><span class="caption-number">Theorem 1 </span></p>
<section class="theorem-content" id="proof-content">
<p>Sea</p>
<div class="math notranslate nohighlight">
\[
\Omega: [0, +\infty)\longmapsto\mathbb{R}
\]</div>
<p>una función arbitraria, estrictamente monotona creciente. Sea también</p>
<div class="math notranslate nohighlight">
\[
\mathcal{L}:\mathbb{R}^{2}\longmapsto\mathbb{R}\cup\{\infty\}
\]</div>
<p>una función de pérdida. Entonces, cada minimizador <span class="math notranslate nohighlight">\(f\in H\)</span>, de una tarea de minimización regularizada</p>
<div class="math notranslate nohighlight" id="equation-eq-min-reg">
<span class="eqno">(19)<a class="headerlink" href="#equation-eq-min-reg" title="Permalink to this equation">#</a></span>\[
\min_{f\in H} J(f)=\sum_{n=1}^{N}\mathcal{L}(y_{n}, f(\boldsymbol{x}_{n}))+\lambda\Omega(\|f\|^{2})
\]</div>
<p>admite una representación de la forma</p>
<div class="math notranslate nohighlight">
\[
f(\cdot)=\sum_{n=1}^{N}\theta_{n}\kappa(\cdot, \boldsymbol{x}_{n}),
\]</div>
<p>donde <span class="math notranslate nohighlight">\(\theta_{n}\in\mathbb{R},~n=1,2,\dots,N\)</span>. La regularización de la forma <span class="math notranslate nohighlight">\(\Omega(\|f\|^{2})\)</span> es una función cuadrática, y por lo tanto estrictamente monotona en el intervalo <span class="math notranslate nohighlight">\([0, \infty)\)</span>.</p>
</section>
</div><p><strong><code class="docutils literal notranslate"><span class="pre">Demostración</span></code></strong></p>
<p>Sea</p>
<div class="math notranslate nohighlight">
\[
A=\text{span}\{\kappa(\cdot, \boldsymbol{x}_{1}), \kappa(\cdot, \boldsymbol{x}_{2}),\dots,\kappa(\cdot, \boldsymbol{x}_{N})\}.
\]</div>
<p>Dado que cada <span class="math notranslate nohighlight">\(\kappa(\cdot, \boldsymbol{x}_{i})\in H,~i=1,2,\dots,N,~A\subseteq H\)</span> y <span class="math notranslate nohighlight">\(N&lt;\infty\)</span>, entonces, <span class="math notranslate nohighlight">\(A\)</span> es cerrado.</p>
<p>Por <code class="docutils literal notranslate"><span class="pre">Teorema</span> <span class="pre">de</span> <span class="pre">descomposición</span> <span class="pre">ortogonal</span></code>, como <span class="math notranslate nohighlight">\(A\)</span> es un subespacio cerrado de <span class="math notranslate nohighlight">\(H\)</span>, entonces, <span class="math notranslate nohighlight">\(H=A\oplus A^{T}\)</span>. Esto es, si <span class="math notranslate nohighlight">\(f\in H\)</span> entonces</p>
<div class="math notranslate nohighlight">
\[
f(\cdot)=\sum_{n=1}^{N}\theta_{n}\kappa(\cdot, \boldsymbol{x}_{n})+f_{\perp}
\]</div>
<p>donde <span class="math notranslate nohighlight">\(f_{\perp}\)</span> es la parte de <span class="math notranslate nohighlight">\(f\)</span> que es ortogonal a <span class="math notranslate nohighlight">\(A\)</span>.</p>
<p>Usando la <code class="docutils literal notranslate"><span class="pre">propiedad</span> <span class="pre">reproductora</span></code> <a class="reference internal" href="#equation-prop-reproductora">(18)</a> se tiene que <span class="math notranslate nohighlight">\(\forall f\in H\)</span></p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align}
f(\boldsymbol{x})&amp;=\langle f, \kappa(\cdot, \boldsymbol{x}_{m})\rangle\\
&amp;=\left\langle\sum_{n=1}^{N}\theta_{n}\kappa(\cdot, \boldsymbol{x}_{n})+f_{\perp}, \kappa(\cdot, \boldsymbol{x}_{m})\right\rangle\\
&amp;=\left\langle\sum_{n=1}^{N}\theta_{n}\kappa(\cdot, \boldsymbol{x}_{n}), \kappa(\cdot, \boldsymbol{x}_{m})\right\rangle\\
&amp;=\sum_{n=1}^{N}\theta_{n}\langle\kappa(\cdot, \boldsymbol{x}_{n}), \kappa(\cdot, \boldsymbol{x}_{m})\rangle\\
&amp;=\sum_{n=1}^{N}\theta_{n}\kappa(\boldsymbol{x}_{m}, \boldsymbol{x}_{n}).
\end{align}
\end{split}\]</div>
<p>Nótese que la propiedad de reproducción garantiza que en los puntos de entrenamiento el valor de <span class="math notranslate nohighlight">\(f\)</span> no depende de <span class="math notranslate nohighlight">\(f_{\perp}\)</span>, y por lo tanto tampoco el primer término de <span class="math notranslate nohighlight">\(\min_{f\in H}J(f)\)</span> en <a class="reference internal" href="#equation-eq-min-reg">(19)</a>.</p>
<p>Además, para todo <span class="math notranslate nohighlight">\(f_{\perp}\)</span> tenemos que:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align*}
\Omega(\|f\|^{2})&amp;=\Omega\left(\left\langle\sum_{n=1}^{N}\theta_{n}\kappa(\cdot, \boldsymbol{x}_{n})+f_{\perp}, \sum_{n=1}^{N}\theta_{n}\kappa(\cdot, \boldsymbol{x}_{n})+f_{\perp}\right\rangle\right)\\
&amp;=\Omega\left(\left\langle\sum_{n=1}^{N}\theta_{n}\kappa(\cdot, \boldsymbol{x}_{n}), \sum_{n=1}^{N}\theta_{n}\kappa(\cdot, \boldsymbol{x}_{n})\right\rangle+\langle f_{\perp}, f_{\perp}\rangle\right)\\
&amp;=\Omega\left(\left\|\sum_{n=1}^{N}\theta_{n}\kappa(\cdot, \boldsymbol{x}_{n})\right\|^{2}+\|f_{\perp}\|^{2}\right)\\
&amp;\geq\Omega\left(\left\|\sum_{n=1}^{N}\theta_{n}\kappa(\cdot, \boldsymbol{x}_{n})\right\|^{2}\right)
\end{align*}
\end{split}\]</div>
<p>Por lo tanto para cualquier selección de <span class="math notranslate nohighlight">\(\theta_{n},~n=1,2,\dots,N\)</span>, la función de coste es minimizada por <span class="math notranslate nohighlight">\(f_{\perp}=0\)</span>.</p>
<div class="proof observation admonition" id="obs_th_repr">
<p class="admonition-title"><span class="caption-number">Observation 1 </span></p>
<section class="observation-content" id="proof-content">
<ul>
<li><p>La importancia de este teorema radica en que, para optimizar <span class="math notranslate nohighlight">\(J(f)\)</span> en <a class="reference internal" href="#equation-eq-min-reg">(19)</a> con respecto a <span class="math notranslate nohighlight">\(f\)</span>, usamos la expresión <span class="math notranslate nohighlight">\(f(\cdot)\)</span> en <a class="reference internal" href="#equation-prop-reproductora">(18)</a> y la minimización es llevada a cabo con respecto a los parámetros <span class="math notranslate nohighlight">\(\theta_{n},~n=1,2,\dots,N\)</span>.</p></li>
<li><p>En casos que la regularización no es necesaria, usualmente un término de sesgo es agregado y se supone que la función a minimizar admite la repreentación</p>
<div class="math notranslate nohighlight">
\[
    \tilde{f}=f+b,\quad f(\cdot)=\sum_{n=1}^{N}\theta_{n}\kappa(\cdot, \boldsymbol{x}_{n})
    \]</div>
</li>
<li><p>La esencia del siguiente teorema es expandir la solución en dos partes. Una que pertenece al RKHS, <span class="math notranslate nohighlight">\(H\)</span>, y otra que está dada como una combinación lineal de un conjunto de funciones preseleccionadas.</p></li>
</ul>
</section>
</div><div class="proof theorem admonition" id="th_rep_semipar">
<p class="admonition-title"><span class="caption-number">Theorem 2 </span> (Teorema de representación semiparamétrico)</p>
<section class="theorem-content" id="proof-content">
<p>Supongamos que adicionalmente a los supuestos adoptados en el Teorema <a class="reference internal" href="#th_representation">Theorem 1</a>, es dado el siguiente conjunto de funciones reales</p>
<div class="math notranslate nohighlight">
\[
\varphi_{m}:\mathcal{X}\longmapsto\mathbb{R},\quad m=1,2,\dots,M,
\]</div>
<p>con la propiedad que la matriz de <span class="math notranslate nohighlight">\(N\times M\)</span> con elementos <span class="math notranslate nohighlight">\(\varphi_{m}(\boldsymbol{x}_{n}),~n=1,2,\dots,N,~m=1,2,\dots,M\)</span>, tiene rango <span class="math notranslate nohighlight">\(M\)</span>. Entonces, cualquier</p>
<div class="math notranslate nohighlight">
\[
\tilde{f}=f+h,\quad f\in H,~ h\in\text{span}\{\varphi_{m}, m=1,2,\dots,M\},
\]</div>
<p>soluciona la tarea de minimización</p>
<div class="math notranslate nohighlight">
\[
\min_{\tilde{f}} J(\tilde{f}):=\sum_{n=1}^{N}\mathcal{L}(y_{n}, \tilde{f}(\boldsymbol{x}_{n}))+\Omega(\|f\|^{2}),
\]</div>
<p>admite la representación</p>
<div class="math notranslate nohighlight">
\[
\tilde{f}(\cdot)=\sum_{n=1}^{N}\theta_{n}\kappa(\cdot, \boldsymbol{x}_{n})+\sum_{m=1}^{M}b_{m}\psi_{m}(\cdot).
\]</div>
</section>
</div><div class="proof observation admonition" id="observation-11">
<p class="admonition-title"><span class="caption-number">Observation 2 </span></p>
<section class="observation-content" id="proof-content">
<p>Un ejemplo de aplicación exitosa de este teorema fue demostrada en el contexto de procesamiento de imágenes <span id="id10">[<a class="reference internal" href="#id33" title="Pantelis Bouboulis, Konstantinos Slavakis, and Sergios Theodoridis. Adaptive kernel-based image denoising employing semi-parametric regularization. IEEE Transactions on Image Processing, 19(6):1465–1479, 2010.">Bouboulis <em>et al.</em>, 2010</a>]</span>. Un conjunto de funciones no lineales en lugar de <span class="math notranslate nohighlight">\(\psi_{m}\)</span> fueron usadas para detección de bordes en una imágen con (saltos no suaves). La parte de <span class="math notranslate nohighlight">\(f\)</span> que pertence al espacio RKHS es usada para las partes suaves en la imágen.</p>
</section>
</div></section>
<section id="regresion-ridge-con-kernel">
<h3>Regresión ridge con Kernel<a class="headerlink" href="#regresion-ridge-con-kernel" title="Permalink to this headline">#</a></h3>
<ul class="simple">
<li><p>En esta sección abordaremos la tarea de la <code class="docutils literal notranslate"><span class="pre">regresión</span> <span class="pre">ridge</span></code> en un espacio general RKHS. El camino a seguir es el usado típicamente para extender tecnicas, las cuales han sido desarrolladas para modelos lineales, a espacios más generales RKSH.</p></li>
</ul>
<ul>
<li><p>Sea <span class="math notranslate nohighlight">\((y_{n}, \boldsymbol{x}_{n})\in\mathbb{R}\times\mathbb{R}^{l}\)</span> la representación de un mecanismo de generación de datos, modelados vía, tarea de regresión no lineal</p>
<div class="math notranslate nohighlight">
\[\begin{split}
    \\[1mm]
    y_{n}=g(\boldsymbol{x}_{n})+\eta_{n},\quad n=1,2,\dots,N.
    \end{split}\]</div>
</li>
<li><p>Denotemos por <span class="math notranslate nohighlight">\(f\)</span> el estimador de la función <span class="math notranslate nohighlight">\(g\)</span> desconocida. <span class="math notranslate nohighlight">\(f\)</span> es llamada la hipótesis y <span class="math notranslate nohighlight">\(H\)</span> el espacio de hipótesis, donde <span class="math notranslate nohighlight">\(f\)</span> es buscada. Supongamos que <span class="math notranslate nohighlight">\(f\)</span> está en RKHS y está asociada con el kernel</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
\kappa:\mathbb{R}^{l}\times\mathbb{R}^{l}\longmapsto\mathbb{R}.
\]</div>
<ul class="simple">
<li><p>Por el <code class="docutils literal notranslate"><span class="pre">teorema</span> <span class="pre">de</span> <span class="pre">representación</span></code> se tiene que</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
f(\boldsymbol{x})=\sum_{n=1}^{N}\theta_{n}\kappa(\boldsymbol{x}, \boldsymbol{x}_{n}).
\]</div>
<ul>
<li><p>De acuerdo a la <code class="docutils literal notranslate"><span class="pre">regresión</span> <span class="pre">ridge</span> <span class="pre">con</span> <span class="pre">kernel</span></code>, los coeficientes desconocidos son estimados por medio de la siguiente tarea</p>
<div class="math notranslate nohighlight" id="equation-eq-task-ridge-reg">
<span class="eqno">(20)<a class="headerlink" href="#equation-eq-task-ridge-reg" title="Permalink to this equation">#</a></span>\[
    \hat{\theta}=\text{argmin}_{\theta} J(\theta),\quad J(\theta)=\sum_{n=1}^{N}\left(y_{n}-\sum_{m=1}^{N}\theta_{m}\kappa(\boldsymbol{x}_{n}, \boldsymbol{x}_{m})\right)^{2}+C\langle f, f\rangle,
    \]</div>
<p>donde <span class="math notranslate nohighlight">\(C\)</span> es el parámetro de regularización. La Ecuación <a class="reference internal" href="#equation-eq-task-ridge-reg">(20)</a> puede reescribirse como</p>
<div class="math notranslate nohighlight">
\[\begin{split}
    \\[1mm]
    J(\theta)=(\boldsymbol{y}-K\theta)^{T}(\boldsymbol{y}-K\theta)+C\theta^{T}K\theta,
    \end{split}\]</div>
<p>donde <span class="math notranslate nohighlight">\(\boldsymbol{y}=(y_{1}, y_{2},\dots, y_{N})^{T}\)</span> y <span class="math notranslate nohighlight">\(\theta=(\theta_{1}, \theta_{2}, \dots,\theta_{M})^{T}\)</span>, <span class="math notranslate nohighlight">\(K\)</span> es la matriz kernel tal que <span class="math notranslate nohighlight">\(\langle\kappa(\cdot, \boldsymbol{x}_{m}), \kappa(\cdot, \boldsymbol{x}_{m})\rangle=\kappa(\boldsymbol{x}_{m}, \boldsymbol{x}_{n})\)</span>, y <span class="math notranslate nohighlight">\(y\)</span> es determinada por la función kernel y los valores de entrenamiento.</p>
</li>
<li><p>Minimizando <span class="math notranslate nohighlight">\(J(\theta)\)</span> con respecto a <span class="math notranslate nohighlight">\(\theta\)</span> y suponiendo que <span class="math notranslate nohighlight">\(K^{T}=K\)</span> es invertible, utilizando el mismo procedimiento en la regresión ridge, tenemos que</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
(K^{T}K+CK^{T})\hat{\theta}=K^{T}\boldsymbol{y}\quad\text{o}\quad y = (K+CI)\hat{\theta}.
\]</div>
<ul>
<li><p>Una vez <span class="math notranslate nohighlight">\(\hat{\theta}\)</span> es obtenido, dado un vector <span class="math notranslate nohighlight">\(\boldsymbol{x}\in\mathbb{R}^{l}\)</span> la correspondiente predicción de la variable dependiente está dada por:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
    \\[1mm]
    \hat{\boldsymbol{y}}=\sum_{n=1}^{N}\hat{\theta}_{n}\kappa(\boldsymbol{x}, \boldsymbol{x}_{n})=\theta^{T}\boldsymbol{\kappa}(\boldsymbol{x})=\boldsymbol{y}^{T}(K+CI)^{-1}\boldsymbol{\kappa}(\boldsymbol{x}),
    \end{split}\]</div>
<p>donde <span class="math notranslate nohighlight">\(\boldsymbol{\kappa}(\boldsymbol{x})=(\kappa(\boldsymbol{x},\boldsymbol{x}_{1}),\dots,\boldsymbol{\kappa}(\boldsymbol{x}, \boldsymbol{x}_{N}))^{T}\)</span>.</p>
</li>
</ul>
</section>
<section id="regresion-de-vectores-de-soporte">
<h3>Regresión de vectores de soporte<a class="headerlink" href="#regresion-de-vectores-de-soporte" title="Permalink to this headline">#</a></h3>
<ul>
<li><p>El método de mínimos cuadrados no es siempre el mejor criterio de optimización, debido a que, en presencia de ruido no Gaussiano con colas largas y por lo tanto número creciente de outliers, la dependencia cuadrática de el método se sesga hacia valores asociados con presencia de outliers</p></li>
<li><p>Una manera de darle solución a este problema es escoger una función de pérdida que se ajuste mejor al modelo del ruido (ver Huber 1992, <span id="id11">[<a class="reference internal" href="#id34" title="Peter J Huber. Robust estimation of a location parameter. In Breakthroughs in statistics, pages 492–518. Springer, 1992.">Huber, 1992</a>]</span>). Bajo el supuesto de que el ruido tiene función de densidad de probabilidad (fdp) simétrica, la tarea optima de regresión es obtenida minimizando la función de pérdida</p>
<div class="math notranslate nohighlight">
\[\begin{split}
    \\[2mm]
    \mathcal{L}(y, f(\boldsymbol{x}))=|y-f(\boldsymbol{x})|
    \end{split}\]</div>
<p>la cual es conocida como el <code class="docutils literal notranslate"><span class="pre">método</span> <span class="pre">de</span> <span class="pre">mínimos</span> <span class="pre">módulos</span></code>.</p>
</li>
<li><p>Huber demostró que si el ruido tiene dos componentes: Gaussiana y otra fdp arbitraria (simétrica), entonces la mejor función de pérdida en el sentido minimax está dada por:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
    \\[1mm]
    \mathcal{L}(y, f(\boldsymbol{x}))=
    \begin{cases}
    \displaystyle{\varepsilon|y-f(\boldsymbol{x})|-\frac{\varepsilon^{2}}{2}} &amp; \text{si}~|y-f(\boldsymbol{x})|&gt;\varepsilon,\\[2mm]
    \displaystyle{\frac{1}{2}|y-f(\boldsymbol{x})|-\frac{\varepsilon^{2}}{2}} &amp; \text{si}~|y-f(\boldsymbol{x})|\leq\varepsilon,
    \end{cases}
    \end{split}\]</div>
<p>para algún parámetro <span class="math notranslate nohighlight">\(\varepsilon\)</span>. Esta es conocida como función de pérdidad de Huber.</p>
</li>
<li><p>Una función de pérdida que se aproxima a la de Huber y tiene excelentes propiedades computacionales es llamada <code class="docutils literal notranslate"><span class="pre">función</span> <span class="pre">de</span> <span class="pre">pérdida</span> <span class="pre">lineal</span></code> <span class="math notranslate nohighlight">\(\varepsilon\)</span>-<code class="docutils literal notranslate"><span class="pre">insensibe</span></code> y está dada por</p>
<div class="math notranslate nohighlight" id="equation-eq-lin-ins">
<span class="eqno">(21)<a class="headerlink" href="#equation-eq-lin-ins" title="Permalink to this equation">#</a></span>\[\begin{split}
    \\[1mm]
    \mathcal{L}(y, f(\boldsymbol{x}))=
    \begin{cases}
    |y-f(\boldsymbol{x})|-\varepsilon &amp; \text{si}~|y-f(\boldsymbol{x})|&gt;\varepsilon\\[2mm]
    0 &amp; \text{si}~|y-f(\boldsymbol{x})|\leq\varepsilon
    \end{cases}
    \end{split}\]</div>
<p>y la función de pérdida <code class="docutils literal notranslate"><span class="pre">cuadrática</span></code> <span class="math notranslate nohighlight">\(\epsilon\)</span><code class="docutils literal notranslate"><span class="pre">-insensible</span></code></p>
<div class="math notranslate nohighlight">
\[\begin{split}
    \mathcal{L}(y, f(\boldsymbol{x}))=
    \begin{cases}
    |y-f(\boldsymbol{x})|^{2}-\varepsilon &amp; \text{si}~|y-f(\boldsymbol{x})|&gt;\varepsilon\\[2mm]
    0 &amp; \text{si}~|y-f(\boldsymbol{x})|\leq\varepsilon
    \end{cases}
    \end{split}\]</div>
<p>la cuales coinciden con la  función de pérdida de mínimos módulos para <span class="math notranslate nohighlight">\(\varepsilon=0\)</span> y es cercana a la función de pérdida de Huber para <span class="math notranslate nohighlight">\(\varepsilon&lt;1\)</span>.</p>
</li>
</ul>
<figure class="align-center" id="huber-loss-plot">
<a class="reference internal image-reference" href="_images/huber_loss_plot.png"><img alt="_images/huber_loss_plot.png" src="_images/huber_loss_plot.png" style="width: 319.9px; height: 211.39999999999998px;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 7 </span><span class="caption-text">La función de pérdida de Huber (gris punteado), la función de pérdida lineal <span class="math notranslate nohighlight">\(\varepsilon\)</span>-insensible (gris completo) y la función de pérdida cuadrática <span class="math notranslate nohighlight">\(\varepsilon\)</span>-insensible (rojo) para <span class="math notranslate nohighlight">\(\varepsilon = 0.7\)</span>.</span><a class="headerlink" href="#huber-loss-plot" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
</section>
<section id="regresion-optima-lineal-varepsilon-insensible">
<h3>Regresión óptima lineal <span class="math notranslate nohighlight">\(\varepsilon\)</span>-insensible<a class="headerlink" href="#regresion-optima-lineal-varepsilon-insensible" title="Permalink to this headline">#</a></h3>
<ul>
<li><p>Usaremos la función de pérdida lineal <span class="math notranslate nohighlight">\(\varepsilon\)</span>-insensible <a class="reference internal" href="#equation-eq-lin-ins">(21)</a> para cuantificar el error de desajuste del modelo. Trataremos la tarea de regresión en</p>
<div class="math notranslate nohighlight">
\[\begin{split}
    \\[1mm]
    y=g(\boldsymbol{x})+\eta_{n},
    \end{split}\]</div>
<p>usando un model lineal de la forma:</p>
<div class="math notranslate nohighlight">
\[
    f(\boldsymbol{x})=\boldsymbol{\theta}^{T}\boldsymbol{x}+\theta_{0}.
    \]</div>
</li>
<li><p>La solución mas general en la que <span class="math notranslate nohighlight">\(f\)</span> es una función en RKHS será obtenida vía kernel trick (producto interno reemplazado por evaluación de kernel).</p></li>
<li><p>Introducimos ahora dos conjuntos de variables auxiliares</p>
<div class="math notranslate nohighlight" id="equation-eq-restric-1">
<span class="eqno">(22)<a class="headerlink" href="#equation-eq-restric-1" title="Permalink to this equation">#</a></span>\[\begin{split}
    \\[1mm]
    \text{Si}~ y_{n}-\boldsymbol{\theta}^{T}\boldsymbol{x}_{n}-\theta_{0}\geq\varepsilon,~\text{definimos}~\tilde{\xi}_{n}~\text{tal que},\quad y_{n}-\boldsymbol{\theta}^{T}\boldsymbol{x}_{n}-\theta_{0}\leq\varepsilon+\tilde{\xi}_{n}.
    \end{split}\]</div>
<p>Nótese que idealmente, deseamo seleccionar <span class="math notranslate nohighlight">\(\boldsymbol{\theta}, \theta_{0}\)</span> tales que <span class="math notranslate nohighlight">\(\tilde{\xi}_{n}=0\)</span>, dado que este valor entregaría la contribución del respectivo término en la función de pérdida igual a cero, pues <span class="math notranslate nohighlight">\(\mathcal{L}(y, f(\boldsymbol{x}))=0\)</span> si <span class="math notranslate nohighlight">\(|y-f(\boldsymbol{x})|\leq\varepsilon\)</span>. Análogamente,</p>
<div class="math notranslate nohighlight" id="equation-eq-restric-2">
<span class="eqno">(23)<a class="headerlink" href="#equation-eq-restric-2" title="Permalink to this equation">#</a></span>\[\begin{split}
    \\[1mm]
    \text{Si}~ y_{n}-\boldsymbol{\theta}^{T}\boldsymbol{x}_{n}-\theta_{0}\leq-\varepsilon,~\text{definimos}~\xi_{n}~\text{tal que},\quad\boldsymbol{\theta}^{T}\boldsymbol{x}_{n}+\theta_{0}-y_{n}\leq\varepsilon+\xi_{n}.
    \end{split}\]</div>
</li>
</ul>
<ul class="simple">
<li><p>Estamos ahora listos para formular la tarea de minimización para el correspondiente costo empírico, regularizado por la norma de <span class="math notranslate nohighlight">\(\boldsymbol{\theta}\)</span>, el cual es proyectado en términos de las variables auxiliares como:</p></li>
</ul>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{cases}
\text{minimizar} &amp; J(\boldsymbol{\theta}, \theta_{0}, \xi, \tilde{\xi})=\frac{1}{2}\|\boldsymbol{\theta}\|^{2}+C\left(\displaystyle{\sum_{n=1}^{N}\xi_{n}+\sum_{n=1}^{N}\tilde{\xi}_{n}}\right),\\[2mm]
\text{sujeto a} &amp; y_{n}-\boldsymbol{\theta}^{T}\boldsymbol{x}_{n}-\theta_{0}\leq\varepsilon+\tilde{\xi}_{n},\quad n=1,2,\dots,N,\\[2mm]
 &amp; \boldsymbol{\theta}^{T}\boldsymbol{x}_{n}+\theta_{0}-y_{n}\leq\varepsilon+\xi_{n},\quad n=1,2,\dots,N,\\[2mm]
&amp;\tilde{\xi}_{n}\geq0,\quad\tilde{\xi}_{n}\geq0,~ n=1,2,\dots,N.
\end{cases}
\end{split}\]</div>
<ul class="simple">
<li><p>El término <span class="math notranslate nohighlight">\(\frac{1}{2}\|\boldsymbol{\theta}\|^{2}\)</span>, surge de la necesidad de maximizar el margen asociado al hiperplano que separa dos clases (ver sección <code class="docutils literal notranslate"><span class="pre">Máquinas</span> <span class="pre">de</span> <span class="pre">vectores</span> <span class="pre">de</span> <span class="pre">soporte</span></code>). Dicho margen: <span class="math notranslate nohighlight">\(1/\|\boldsymbol{\theta}\|\)</span>, el cual en problemas de clasificación, se desea máximizar, es equivalente a minimizar la norma <span class="math notranslate nohighlight">\(\|\boldsymbol{\theta}\|^2\)</span> para el caso de modelos regresivos. El factor <span class="math notranslate nohighlight">\(\frac{1}{2}\)</span> es inculido de forma conveniente para cálculos posteriores. A este tipo de problemas se les denomina de <code class="docutils literal notranslate"><span class="pre">programación</span> <span class="pre">cuadratica</span></code>.</p></li>
</ul>
<ul>
<li><p>Las variables auxiliares, <span class="math notranslate nohighlight">\(\tilde{\xi}_{n}\)</span> y <span class="math notranslate nohighlight">\(\xi_{n},~ n=1,2,\dots,N\)</span> que miden el exceso de error con respecto a <span class="math notranslate nohighlight">\(\varepsilon\)</span>, son conocidad como <code class="docutils literal notranslate"><span class="pre">variables</span> <span class="pre">de</span> <span class="pre">relajación</span></code>. Nótese que cualquier contribución de la función de costo, para un error obtenido con un valor absoluto menor o igual que <span class="math notranslate nohighlight">\(\varepsilon\)</span> es cero. La tarea de optimización previa, intenta estimar <span class="math notranslate nohighlight">\(\boldsymbol{\theta}, \theta_{0}\)</span> tal que valores de error mayores que <span class="math notranslate nohighlight">\(\epsilon\)</span> y menores que <span class="math notranslate nohighlight">\(-\epsilon\)</span> sean minimizados.</p></li>
<li><p>Por lo tanto, la tarea de optimización es equivalente a minimizar la función de pérdida empírica</p>
<div class="math notranslate nohighlight">
\[\begin{split}
    \\[1mm]
    \frac{1}{2}\|\boldsymbol{\theta}\|^{2}+C\sum_{n=1}^{N}\mathcal{L}(y_{n}, \boldsymbol{\theta}^{T}\boldsymbol{x}_{n}+\theta_{0}),
    \end{split}\]</div>
<p>donde la función de pérdida es <span class="math notranslate nohighlight">\(\varepsilon\)</span>-insensible.</p>
</li>
<li><p>Nótese que debido a que el problema de optimización con restricción involucra las variables de relajación con valores históricos, empleamos el <code class="docutils literal notranslate"><span class="pre">kernel</span> <span class="pre">trick</span></code>.</p></li>
</ul>
<p><strong><code class="docutils literal notranslate"><span class="pre">Solución</span></code></strong></p>
<ul>
<li><p>La solución de la tarea de optimización es obtenida introduciendo los <code class="docutils literal notranslate"><span class="pre">multiplicadores</span> <span class="pre">de</span> <span class="pre">Lagrange</span></code> y formando el correspondiente Lagrangiano. Habiendo obtenido los multiplicadores, la solución estaría dada por</p>
<div class="math notranslate nohighlight">
\[\begin{split}
    \\[1mm]
    \hat{\boldsymbol{\theta}}=\sum_{n=1}^{N}(\tilde{\lambda}_{n}-\lambda_{n})\boldsymbol{x}_{n},
    \end{split}\]</div>
<p>donde <span class="math notranslate nohighlight">\(\tilde{\lambda}_{n},\lambda_{n},~ n=1,2,\dots,N\)</span>, son los multiplicadores asociados con cada una de las restricciones.</p>
</li>
<li><p>Los multiplicadores de Lagrange son distintos de cero, solo para puntos <span class="math notranslate nohighlight">\(\boldsymbol{x}_{n}\)</span>, que corresponden a valores de error ya sean iguales o mayores que <span class="math notranslate nohighlight">\(\varepsilon\)</span>. Estos son conocidos como <code class="docutils literal notranslate"><span class="pre">vectores</span> <span class="pre">de</span> <span class="pre">soporte</span></code>.</p></li>
<li><p>Puntos para los que el valor del puntaje de error es menor que <span class="math notranslate nohighlight">\(\varepsilon\)</span>, corresponden a multiplicadores de Lagrange ceros y por lo tanto no participan en la formación de la solución</p></li>
<li><p>El término de sesgo <span class="math notranslate nohighlight">\(\hat{\theta}_{0}\)</span> puede ser obtenido a partir de las ecuaciones</p>
<div class="math notranslate nohighlight" id="equation-eq-sistem-bias">
<span class="eqno">(24)<a class="headerlink" href="#equation-eq-sistem-bias" title="Permalink to this equation">#</a></span>\[\begin{split}
    \\[1mm]
    \begin{align}
    y_{n}-\boldsymbol{\theta}^{T}\boldsymbol{x}_{n}-\theta_{0}&amp;=\varepsilon,\\[2mm]
    \boldsymbol{\theta}^{T}\boldsymbol{x}_{n}+\theta_{0}-y_{n}&amp;=\varepsilon,
    \end{align} 
    \end{split}\]</div>
<p>donde <span class="math notranslate nohighlight">\(n\)</span> corre sobre todos los puntos que forman un <code class="docutils literal notranslate"><span class="pre">subconjunto</span> <span class="pre">de</span> <span class="pre">vectores</span> <span class="pre">de</span> <span class="pre">soporte</span></code>, esto es, puntos asociados con:</p>
<div class="math notranslate nohighlight">
\[
    \tilde{\lambda}_{n}&gt;0,~(\lambda_{n}&gt;0)\quad\text{y}\quad\tilde{\xi}_{n}=0,~(\xi_{n}=0).
    \]</div>
<p>En la practica, <span class="math notranslate nohighlight">\(\hat{\theta}_{0}\)</span> es obtenido a partir del promedio de todas las ecuaciones en <a class="reference internal" href="#equation-eq-sistem-bias">(24)</a>.</p>
</li>
</ul>
<ul>
<li><p>Una vez <span class="math notranslate nohighlight">\(\hat{\boldsymbol{\theta}}, \hat{\theta}_{0}\)</span> han sido obtenidos, estamos listos para realizar predicciones. Dado un valor <span class="math notranslate nohighlight">\(\boldsymbol{x}\)</span>, primero desarrollamos el mapeo (implícito) usando el mapeo de características <span class="math notranslate nohighlight">\(\boldsymbol{x}\longmapsto\kappa(\cdot, \boldsymbol{x})\)</span> obtenemos</p>
<div class="math notranslate nohighlight">
\[
    \hat{y}(\boldsymbol{x})=\langle\hat{\boldsymbol{\theta}}, \kappa(\cdot, \boldsymbol{x})\rangle+\hat{\theta}_{0},
    \]</div>
<p>o bien,</p>
<div class="math notranslate nohighlight">
\[
    \hat{y}(\boldsymbol{x})=\sum_{n=1}^{N_{s}}(\tilde{\lambda}_{n}-\tilde{\lambda}_{n})\kappa(\boldsymbol{x}, \boldsymbol{x}_{n})+\hat{\theta}_{0},\quad\text{Prediccion SVR},
    \]</div>
<p>donde <span class="math notranslate nohighlight">\(N_{s}\leq N\)</span>, es el número de multiplicadores de Lagrange distintos de cero. Nótese que esta última es una expansión en términos de funciones kernel no lineales</p>
</li>
</ul>
<p><strong><code class="docutils literal notranslate"><span class="pre">Solución</span> <span class="pre">de</span> <span class="pre">la</span> <span class="pre">tarea</span> <span class="pre">de</span> <span class="pre">optimización</span></code></strong></p>
<ul>
<li><p>La tarea de optimización con desigualdades de restricción, satisface las siguientes condiciones</p>
<div class="math notranslate nohighlight">
\[\begin{split}
    \\[1mm]
    \begin{align*}
    &amp;\frac{\partial L}{\partial\boldsymbol{\theta}}=\boldsymbol{0},~\frac{\partial L}{\partial\theta_{0}}=0,~\frac{\partial L}{\partial\tilde{\xi}_{n}}=0,~\frac{\partial L}{\partial\xi_{n}}=0,\\[2mm]
    &amp;\tilde{\lambda}_{n}(y_{n}-\boldsymbol{\theta}^{T}\boldsymbol{x}_{n}-\theta_{0}-\varepsilon-\tilde{\xi}_{n})=0,\quad n=1,2,\dots,N,\\[2mm]
    &amp;\lambda_{n}(\boldsymbol{\theta}^{T}\boldsymbol{x}_{n}+\theta_{0}-y_{n}-\varepsilon-\xi_{n})=0,\quad n=1,2,\dots,N,\\[2mm]
    &amp;\tilde{\mu}_{n}\tilde{\xi}_{n}=0,\quad n=1,2,\dots,N,\\[2mm]
    &amp;\mu_{n}\xi_{n}=0,\quad n=1,2,\dots,N,\\[2mm]
    &amp;\tilde{\lambda}_{n}\geq0,~\lambda_{n}\geq0,~\tilde{\mu}_{n}\geq0,~\mu_{n}\geq0,\quad n=1,2,\dots,N,
    \end{align*}
    \end{split}\]</div>
<p>con respecto al Lagrangiano</p>
<div class="math notranslate nohighlight" id="equation-eq-lagrangiano-general">
<span class="eqno">(25)<a class="headerlink" href="#equation-eq-lagrangiano-general" title="Permalink to this equation">#</a></span>\[\begin{split}
    \begin{align*}
    L(\boldsymbol{\theta}, \theta_{0}, \tilde{\xi}, \xi, \lambda, \mu)&amp;=\frac{1}{2}\|\boldsymbol{\theta}\|^{2}+C\left(\sum_{n=1}^{N}{\xi}_{n}+\sum_{n=1}^{N}\tilde{\xi}_{n}\right)\\
    &amp;+\sum_{n=1}^{N}\tilde{\lambda}_{n}(y_{n}-\boldsymbol{\theta}^{T}\boldsymbol{x}_{n}-\theta_{0}-\varepsilon-\tilde{\xi}_{n})\\
    &amp;+\sum_{n=1}^{N}\lambda_{n}(\boldsymbol{\theta}^{T}\boldsymbol{x}_{n}+\theta_{0}-y_{n}-\varepsilon-\xi_{n})\\
    &amp;-\sum_{n=1}^{N}\tilde{\mu}_{n}\tilde{\xi}_{n}-\sum_{n=1}^{N}\mu_{n}\xi_{n},
    \end{align*}
    \end{split}\]</div>
<p>donde <span class="math notranslate nohighlight">\(\tilde{\lambda}_{n},~\lambda_{n},~\tilde{\mu}_{n},~\mu_{n}\)</span> son los <code class="docutils literal notranslate"><span class="pre">multiplicadores</span> <span class="pre">de</span> <span class="pre">Lagrange</span></code>.</p>
</li>
</ul>
<ul>
<li><p>Sumando las restricciones tenemos que, multiplicando anteriormente por <span class="math notranslate nohighlight">\(\tilde{\lambda}_{n},\lambda_{n}, \tilde{\xi}_{n}, \xi_{n}\)</span>, se tiene que:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
    \\[1mm]
    \tilde{\lambda}_{n}\lambda_{n}((y_{n}-\boldsymbol{\theta}^{T}\boldsymbol{x}_{n}-\theta_{0}-\varepsilon)(\xi_{n}-\tilde{\xi}_{n})-2\tilde{\xi}_{n}\xi_{n})=0,
    \end{split}\]</div>
<p>dado que los multiplicadores de Lagrange que participan en la solución <span class="math notranslate nohighlight">\(\hat{\theta}\)</span> son aquellos distintos de cero, para puntos <span class="math notranslate nohighlight">\(\boldsymbol{x}_{n}\)</span> correspondientes a valores de erros que sean mayores o iguales que <span class="math notranslate nohighlight">\(\varepsilon\)</span>, esto es <span class="math notranslate nohighlight">\((y_{n}-\boldsymbol{\theta}^{T}\boldsymbol{x}_{n}-\theta_{0})\geq\varepsilon,~\lambda_{n}\neq0\)</span></p>
<p>Si <span class="math notranslate nohighlight">\(y_{n}-\boldsymbol{\theta}^{T}-\theta_{0}=\varepsilon\)</span>, entonces</p>
<div class="math notranslate nohighlight">
\[\begin{split}
    \\[1mm]
    (i)~\tilde{\lambda}_{n}\lambda_{n}=0\quad\text{o}\quad(ii)~(y_{n}-\boldsymbol{\theta}^{T}\boldsymbol{x}_{n}-\theta_{0}-\varepsilon)(\xi_{n}-\tilde{\xi}_{n})-2\tilde{\xi}_{n}\xi_{n}=0
    \end{split}\]</div>
<p>Si <span class="math notranslate nohighlight">\(y_{n}-\boldsymbol{\theta}^{T}-\theta_{0}&gt;\varepsilon\)</span>, entonces <span class="math notranslate nohighlight">\((i)~\tilde{\lambda}_{n}\lambda_{n}=0\)</span>, además, basados en la tarea de optimización, seleccionando <span class="math notranslate nohighlight">\(\boldsymbol{\theta}^{T}, \theta_{0}\)</span> tales que <span class="math notranslate nohighlight">\(y_{n}-\boldsymbol{\theta}^{T}\boldsymbol{x}_{n}-\theta_{0}-\varepsilon\rightarrow0\)</span> se tiene que</p>
<div class="math notranslate nohighlight">
\[\begin{split}
    \\[1mm]
    (ii)~(y_{n}-\boldsymbol{\theta}^{T}\boldsymbol{x}_{n}-\theta_{0}-\varepsilon)(\xi_{n}-\tilde{\xi}_{n})-2\tilde{\xi}_{n}\xi_{n}=0\Rightarrow\tilde{\xi}_{n}\xi_{n}=0.
    \end{split}\]</div>
</li>
</ul>
<ul class="simple">
<li><p>Derivando el Lagrangiano <a class="reference internal" href="#equation-eq-lagrangiano-general">(25)</a> tenemos los resultados</p></li>
</ul>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align*}
\frac{\partial L}{\partial\boldsymbol{\theta}}&amp;=\boldsymbol{0}\Leftrightarrow\hat{\boldsymbol{\theta}}=\sum_{n=1}^{N}(\tilde{\lambda}_{n}-\lambda_{n})\boldsymbol{x}_{n};\quad\frac{\partial}{\partial\boldsymbol{\theta}}(\frac{1}{2}\|\boldsymbol{\theta}\|^{2})=\boldsymbol{\theta},~\frac{\partial}{\partial\boldsymbol{\theta}}(\boldsymbol{\theta}^{T}\boldsymbol{x}_{n})=\boldsymbol{x}_{n}\\
\frac{\partial L}{\partial\theta_{0}}&amp;=0\Leftrightarrow\sum_{n=1}^{N}\tilde{\lambda}_{n}=\sum_{n=1}^{N}\lambda_{n};\quad\frac{\partial}{\partial\theta_{0}}(\theta_{0})=1,\\
\frac{\partial L}{\partial\tilde{\xi}_{n}}&amp;=0\Leftrightarrow C-\tilde{\lambda}_{n}-\tilde{\mu}_{n}=0;\quad
\frac{\partial}{\partial\tilde{\xi}_{n}}\left(\sum_{n=1}^{N}\tilde{\xi}_{n}\right)=1\\
\frac{\partial L}{\partial\xi_{n}}&amp;=0\Leftrightarrow C-\lambda_{n}-\mu_{n}=0.
\end{align*}
\end{split}\]</div>
<ul class="simple">
<li><p>Para proceder a calcular los multiplicadores asociados a la tarea de optimización, consideraremos la <code class="docutils literal notranslate"><span class="pre">Representación</span> <span class="pre">dual</span> <span class="pre">de</span> <span class="pre">Walfe</span></code>. En esta representación es considerado el término de sesgo <span class="math notranslate nohighlight">\(\boldsymbol{\theta}_{0}=0\)</span>. Además, consideraremos solo el uso de vectores de soportes, esto es valores asociados a <span class="math notranslate nohighlight">\(\boldsymbol{\xi}_{n}=\tilde{\boldsymbol{\xi}}_{n}=0\)</span>, para proceder con la representación dual respectiva. Esta representación es obtenida a partir del Lagrangiano <span class="math notranslate nohighlight">\(L(\boldsymbol{\theta}, \theta_{0}, \tilde{\xi}, \xi, \lambda, \mu)\)</span>.</p></li>
</ul>
<div class="proof property admonition" id="walfe_prop">
<p class="admonition-title"><span class="caption-number">Property 4 </span> (Representación dual de Walfe)</p>
<section class="property-content" id="proof-content">
<ul>
<li><p>Un <code class="docutils literal notranslate"><span class="pre">problema</span> <span class="pre">de</span> <span class="pre">programación</span> <span class="pre">convexa</span></code> es equivalente a</p>
<div class="math notranslate nohighlight">
\[\begin{split}
    \\[1mm]
    \max_{\lambda\geq0}&amp;\quad L(\boldsymbol{\theta}, \boldsymbol{\lambda}),\\
    \text{sujeto a}&amp;\quad\frac{\partial}{\partial\boldsymbol{\theta}}L(\boldsymbol{\theta},\boldsymbol{\lambda})=\boldsymbol{0}.
    \end{split}\]</div>
<p>La última ecuación garantiza que <span class="math notranslate nohighlight">\(\boldsymbol{\theta}\)</span> es un mínimo del Lagrangiano.</p>
</li>
<li><p>Considere el siguiente problema cuadratico:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
    \begin{align*}
    \text{minimizar:}&amp;\quad\frac{1}{2}\boldsymbol{\theta}^{T}\boldsymbol{\theta},\\
    \text{sujeto a:}&amp;\quad A\boldsymbol{\theta}\geq b.
    \end{align*}
    \end{split}\]</div>
<p>el cual admite la siguiente <code class="docutils literal notranslate"><span class="pre">representación</span> <span class="pre">de</span> <span class="pre">Wolfe</span></code></p>
<div class="math notranslate nohighlight">
\[\begin{split}
    \begin{align*}
    \text{minimizar:}&amp;\quad\frac{1}{2}\boldsymbol{\theta}^{T}\boldsymbol{\theta}-\lambda^{T}(A\boldsymbol{\theta}-\boldsymbol{b}),\\
    \text{sujeto a:}&amp;\quad\theta-A^{T}\lambda=0.
    \end{align*}
    \end{split}\]</div>
</li>
<li><p>Solucionando la tarea de optimización de Wolfe con respecto a <span class="math notranslate nohighlight">\(\boldsymbol{\theta}\)</span>, podemos escribir el problema dual involucrando solo multiplicadores de Lagrange. De esta forma obtenemos otro problema cuadratico, pero más simple</p>
<div class="math notranslate nohighlight">
\[\begin{split}
    \\[1mm]
    \begin{align*}
    \max_{\lambda}&amp;\left\{\displaystyle{-\frac{1}{2}\boldsymbol{\lambda}^{T}AA^{T}\boldsymbol{\lambda}+\boldsymbol{\lambda}^{T}\boldsymbol{b}}\right\}\\
    \text{sujeto a:}&amp;\quad\lambda\geq0.
    \end{align*}
    \end{split}\]</div>
</li>
</ul>
</section>
</div><ul class="simple">
<li><p>Nótese en la propiedad anterior que, <span class="math notranslate nohighlight">\(\partial_{\boldsymbol{\theta}}(\frac{1}{2}\boldsymbol{\theta}^{T}\boldsymbol{\theta}-\lambda^{T}(A\boldsymbol{\theta}-\boldsymbol{b}))=\boldsymbol{\theta}-A^{T}\lambda\)</span>. Consideremos ahora la <code class="docutils literal notranslate"><span class="pre">representación</span> <span class="pre">dual</span> <span class="pre">de</span> <span class="pre">Wolfe</span></code> asociada a la tarea de optimización <a class="reference internal" href="#equation-eq-lagrangiano-general">(25)</a>. Con este fin, consideremos <span class="math notranslate nohighlight">\(\lambda=\tilde{\lambda}_{n}-\lambda_{n}\)</span> y <span class="math notranslate nohighlight">\(b=A\boldsymbol{\theta}=\boldsymbol{\theta}^{T}\boldsymbol{x}_{n}\)</span>, entonces la tarea de optimzación se convierte en:</p></li>
</ul>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align*}
\text{minimizar respecto a}~\lambda,\tilde{\lambda}:&amp;\quad-\frac{1}{2}\sum_{n=1}^{N}\sum_{m=1}^{N}(\tilde{\lambda}_{n}-\lambda_{n})(\tilde{\lambda}_{n}+\lambda_{n})\boldsymbol{x}_{n}^{T}\boldsymbol{x}_{m}\\
&amp;\quad+\sum_{n=1}^{N}(\tilde{\lambda}_{n}-\lambda_{n})y_{n}-\varepsilon(\tilde{\lambda}_{n}+\lambda_{n})\\
\text{sujeto a:}&amp;\quad 0\leq\tilde{\lambda}_{n}\leq C\quad\text{y}\quad 0\leq\lambda_{n}\leq C,\quad n=1,2,\dots,N.\\
&amp;\quad~\sum_{n=1}^{N}\tilde{\lambda}_{n}=\sum_{n=1}^{N}\lambda_{n}.
\end{align*}
\end{split}\]</div>
<ul class="simple">
<li><p>El primer termino proviene la siguiente igualdad obtenida a partir del Lagrangiano, el segundo resulta de factorizar los términos que incluyen los autovalores. Con <span class="math notranslate nohighlight">\(\theta_{0}=0\)</span> y <span class="math notranslate nohighlight">\(\xi_{n}=\tilde{\xi}_{n}=0\)</span>,</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
-\sum_{n=1}^{N}(\tilde{\lambda}_{n}-\lambda_{n})\boldsymbol{\theta}^{T}\boldsymbol{\theta}\boldsymbol{x}_{n}=-\sum_{m=1}^{N}\sum_{n=1}^{N}(\tilde{\lambda}_{m}-\lambda_{m})(\tilde{\lambda}_{n}-\lambda_{n})\boldsymbol{x}_{m}\boldsymbol{x}_{n}
\]</div>
<ul>
<li><p>Nótese que la primera restricción proviene de la igualdad <span class="math notranslate nohighlight">\(C-\tilde{\lambda}-\tilde{\mu}_{n}=0\)</span>, con la cual se tiene que</p>
<div class="math notranslate nohighlight">
\[
    0\leq\tilde{\lambda}_{n}\leq\tilde{\lambda}_{n}+\tilde{\mu}_{n}\leq C\Rightarrow 0\leq\tilde{\lambda}_{n}\leq C,
    \]</div>
<p>analogamente, <span class="math notranslate nohighlight">\(0\leq\lambda_{n}\leq C,\quad n=1,2,\dots,N.\)</span></p>
</li>
</ul>
</section>
<section id="regresion-kernel-ridge">
<h3>Regresión Kernel Ridge<a class="headerlink" href="#regresion-kernel-ridge" title="Permalink to this headline">#</a></h3>
<ul>
<li><p>En esta sección abordaremos la <code class="docutils literal notranslate"><span class="pre">regresión</span> <span class="pre">kernel</span> <span class="pre">ridge</span></code> vía su representación dual. La regresión ridge en su representación primal puede ser proyectada como:</p>
<div class="math notranslate nohighlight" id="equation-eq-kernel-ridge-reg">
<span class="eqno">(26)<a class="headerlink" href="#equation-eq-kernel-ridge-reg" title="Permalink to this equation">#</a></span>\[\begin{split}
    \begin{align*}
    \text{minimizar con respecto a}\quad\boldsymbol{\theta}, \boldsymbol{\xi}:&amp;\quad J(\boldsymbol{\theta}, \boldsymbol{\xi})=\sum_{n=1}^{N}\xi_{n}^{2}+C\|\boldsymbol{\theta}\|^{2}\\
    \text{sujeto a}:&amp;\quad y_{n}-\boldsymbol{\theta}^{T}\boldsymbol{x}_{n}=\boldsymbol{\xi}_{n},\quad n=1,2,\dots,N,
    \end{align*}
    \end{split}\]</div>
<p>con el siguiente Lagrangiano</p>
<div class="math notranslate nohighlight">
\[
    L(\boldsymbol{\theta}, \boldsymbol{\xi}, \lambda)=\sum_{n=1}^{N}\xi_{n}^{2}+C\|\boldsymbol{\theta}\|^{2}+\sum_{n=1}^{N}\lambda_{n}(y_{n}-\boldsymbol{\theta}^{T}\boldsymbol{x}_{n}-\xi_{n}),\quad n=1,2,\dots,N.
    \]</div>
</li>
</ul>
<ul class="simple">
<li><p>Calculando las derivadas parciales <span class="math notranslate nohighlight">\(\partial_{\boldsymbol{\theta},\xi_{n}}=0,\quad n=1,2,\dots,N\)</span> se tiene que</p></li>
</ul>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align*}
\frac{\partial L}{\partial\boldsymbol{\theta}}&amp;=0\Leftrightarrow 2C\boldsymbol{\theta}-\sum_{n=1}^{N}\lambda_{n}\boldsymbol{x}_{n}=0\Leftrightarrow\boldsymbol{\hat{\theta}}=\frac{1}{2C}\sum_{n=1}^{N}\lambda_{n}\boldsymbol{x}_{n}\\
\frac{\partial L}{\partial\xi_{n}}&amp;=0\Leftrightarrow 2\xi_{n}-\lambda_{n}=0\Leftrightarrow\xi_{n}=\frac{\lambda_{n}}{2},\quad n=1,2,\dots,N.
\end{align*}
\end{split}\]</div>
<ul class="simple">
<li><p>Para obtener los multiplicadores de Lagrange, consideramos la siguiente formulación dual, obtenida al reemplazar el estimador <span class="math notranslate nohighlight">\(\hat{\boldsymbol{\theta}}\)</span> y <span class="math notranslate nohighlight">\(\xi_{n}\)</span> en la tarea de optimización <a class="reference internal" href="#equation-eq-kernel-ridge-reg">(26)</a></p></li>
</ul>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align*}
\sum_{n=1}^{N}\xi_{n}^{2}+C\|\boldsymbol{\theta}\|^{2}&amp;+\sum_{n=1}^{N}\lambda_{n}(y_{n}-\boldsymbol{\theta}^{T}\boldsymbol{x}_{n}-\xi_{n})\\
&amp;=\frac{1}{4}\sum_{n=1}^{N}\lambda_{n}^{2}+C\frac{1}{4C^{2}}\sum_{n=1}^{N}\sum_{m=1}^{N}\lambda_{n}\lambda_{m}\kappa(\boldsymbol{x}_{n}, \boldsymbol{x}_{m})+\sum_{n=1}^{N}\lambda_{n}y_{n}\\
&amp;-\frac{1}{2C}\sum_{n=1}^{N}\lambda_{n}\lambda_{m}\kappa(\boldsymbol{x}_{n}, \boldsymbol{x}_{m})-\frac{1}{2}\sum_{n=1}^{N}\lambda_{n}^{2}\\
&amp;=\sum_{n=1}^{N}\lambda_{n}y_{n}-\frac{1}{4C}\sum_{n=1}^{N}\sum_{m=1}^{N}\lambda_{n}\lambda_{m}\kappa(\boldsymbol{x}_{n}, \boldsymbol{x}_{m})-\frac{1}{4}\sum_{n=1}^{N}\lambda_{n}^{2}
\end{align*}
\end{split}\]</div>
<ul>
<li><p>La representación dual entrega la siguiente formulación</p>
<div class="math notranslate nohighlight">
\[
    \text{minimizar respecto a}~\lambda:\quad\sum_{n=1}^{N}\lambda_{n}y_{n}-\frac{1}{4C}\sum_{n=1}^{N}\sum_{m=1}^{N}\lambda_{n}\lambda_{m}\kappa(\boldsymbol{x}_{n}, \boldsymbol{x}_{m})-\frac{1}{4}\sum_{n=1}^{N}\lambda_{n}^{2},
    \]</div>
<p>aquí <span class="math notranslate nohighlight">\(\boldsymbol{x}_{n}^{T}\boldsymbol{x}_{m}\)</span> fue reemplazado por <span class="math notranslate nohighlight">\(\kappa(\boldsymbol{x}_{n}, \boldsymbol{x}_{m})\)</span>, de acuerdo al kernel trick.</p>
</li>
</ul>
<ul class="simple">
<li><p>Diferenciando con respecto a <span class="math notranslate nohighlight">\(\lambda\)</span> obtenemos:</p></li>
</ul>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align*}
\boldsymbol{y}-\frac{1}{2C}K\boldsymbol{\lambda}-\frac{1}{2}\boldsymbol{\lambda}=0&amp;\Rightarrow\left(\frac{1}{2C}K+\frac{1}{2}I\right)\boldsymbol{\lambda}=\boldsymbol{y}\\
&amp;\Rightarrow(K+CI)\boldsymbol{\lambda}=2C\boldsymbol{y}\\[2mm]
&amp;\Rightarrow\boldsymbol{\lambda}=2C(K+CI)^{-1}\boldsymbol{y}.
\end{align*}
\end{split}\]</div>
<ul>
<li><p>Dado que <span class="math notranslate nohighlight">\(\displaystyle{\boldsymbol{\hat{\theta}}=\frac{1}{2C}\sum_{n=1}^{N}\lambda_{n}\boldsymbol{x}_{n}}\)</span>, usando el kernel trick se tiene que</p>
<div class="math notranslate nohighlight">
\[
    \hat{y}(\boldsymbol{x})=\langle\boldsymbol{\hat{\theta}}, \kappa(\cdot,\boldsymbol{x})\rangle=\left\langle\frac{1}{2C}\sum_{n=1}^{N}2C(\kappa(\cdot, \boldsymbol{x}_{n})+C)^{-1}y_{n}, \kappa(\cdot, \boldsymbol{x}_{n})\right\rangle=\boldsymbol{y}^{T}(K+CI)^{-1}\kappa(\boldsymbol{x}).
    \]</div>
<p>Nótese que en este caso no fue necesario el supesto de invertibilidad para la matriz <span class="math notranslate nohighlight">\(K\)</span>.</p>
</li>
</ul>
<figure class="align-center" id="nonlinear-reg-curve">
<img alt="_images/nonlinear_reg_curve.png" src="_images/nonlinear_reg_curve.png" />
<figcaption>
<p><span class="caption-number">Fig. 8 </span><span class="caption-text">El tubo alrededor de la curva de regresión no lineal. Los puntos fuera del tubo (denotados por estrellas) tienen o bien <span class="math notranslate nohighlight">\(\tilde{\xi} &gt; 0\)</span> y
<span class="math notranslate nohighlight">\(\xi = 0\)</span> o <span class="math notranslate nohighlight">\(\xi &gt; 0\)</span> y <span class="math notranslate nohighlight">\(\tilde{\xi} = 0\)</span>. El resto de los puntos tienen <span class="math notranslate nohighlight">\(\tilde{\xi} = \xi = 0\)</span>. Los puntos que están dentro del tubo corresponden a multiplicadores de Lagrange iguales a cero.</span><a class="headerlink" href="#nonlinear-reg-curve" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
</section>
<section id="id12">
<h3>Máquinas de vectores de soporte<a class="headerlink" href="#id12" title="Permalink to this headline">#</a></h3>
<ul class="simple">
<li><p>Antes de abordar el modelos de clasificación, <code class="docutils literal notranslate"><span class="pre">máquinas</span> <span class="pre">de</span> <span class="pre">vectores</span> <span class="pre">de</span> <span class="pre">soporte</span></code> revisemos la definición de clasificador</p></li>
</ul>
<div class="proof definition admonition" id="def_clasificador_general">
<p class="admonition-title"><span class="caption-number">Definition 4 </span></p>
<section class="definition-content" id="proof-content">
<p>Un clasificador, es una función definida como</p>
<div class="math notranslate nohighlight">
\[
\omega(x):=\text{argmax}_{\omega}f_{\omega}(x)
\]</div>
<p>donde para cada clase <span class="math notranslate nohighlight">\(\omega\)</span>, se define su función discriminante <span class="math notranslate nohighlight">\(f_{\omega}\)</span>. El grado de pertenencia del valor <span class="math notranslate nohighlight">\(x\)</span> a la clase <span class="math notranslate nohighlight">\(\omega\)</span> es <span class="math notranslate nohighlight">\(f_{\omega}(x)\)</span>. Ademas <span class="math notranslate nohighlight">\(\omega(x)\)</span> es la clase a la que el objeto <span class="math notranslate nohighlight">\(x\)</span> pertenece en mayor grado.</p>
</section>
</div><ul class="simple">
<li><p>Cuando en un método de <code class="docutils literal notranslate"><span class="pre">clasificación</span> <span class="pre">Bayesiana</span></code> desconocemos estadísticos subyacentes, una alternativa es usar <code class="docutils literal notranslate"><span class="pre">técnicas</span> <span class="pre">de</span> <span class="pre">aprendizaje</span> <span class="pre">discriminante</span></code>, y adoptar una función discriminante <span class="math notranslate nohighlight">\(f\)</span>, que efectua la clasificación correspondiente y tratar de optimizarla, como se minimiza la función de pérdida empírica</p></li>
</ul>
<div class="math notranslate nohighlight">
\[\begin{split}
J(f)=\sum_{n=1}^{N}\mathcal{L}(y_{n}, f(\boldsymbol{x}_{n})),\quad\text{donde}\quad y_{n}=
\begin{cases}
+1,&amp; \text{si}~\boldsymbol{x}_{n}\in\omega_{1},\\
-1,&amp; \text{si}~\boldsymbol{x}_{n}\in\omega_{2}.
\end{cases}
\end{split}\]</div>
<ul class="simple">
<li><p>Para una tarea de clasificación binaria, la función de pérdida <span class="math notranslate nohighlight">\((0, 1)\)</span>, definida de la siguiente forma, puede ser utilizada en la tarea de optimización</p></li>
</ul>
<div class="math notranslate nohighlight">
\[\begin{split}
\mathcal{L}(y, f(x))=
\begin{cases}
1,&amp; \text{si}~ yf(x)\leq0\\
0,&amp; \text{otro caso}
\end{cases}
\end{split}\]</div>
<ul class="simple">
<li><p>El principal problema de esta función de pérdida es que su optimización resulta ser una tarea compleja, debido a que es discontinua. Se han utlizado alternativas para esta función de pérdida, con el fin de solventar este problema. En esta sección centraremos nuestra atención en la <code class="docutils literal notranslate"><span class="pre">función</span> <span class="pre">de</span> <span class="pre">pérdida</span> <span class="pre">hinge</span></code> definida como</p></li>
</ul>
<div class="math notranslate nohighlight" id="equation-eq-loss-hinge">
<span class="eqno">(27)<a class="headerlink" href="#equation-eq-loss-hinge" title="Permalink to this equation">#</a></span>\[
\mathcal{L}(y, f(x))=\max(0, \rho-yf(x))
\]</div>
<ul class="simple">
<li><p>Esto es, si el signo del producto entre el label real <span class="math notranslate nohighlight">\((y)\)</span> y el predicho por la función discriminante <span class="math notranslate nohighlight">\((f(x))\)</span> es positivo y mayor que un <code class="docutils literal notranslate"><span class="pre">umbral</span> <span class="pre">definido</span> <span class="pre">por</span> <span class="pre">el</span> <span class="pre">usuario</span></code>, <span class="math notranslate nohighlight">\(\rho\geq0\)</span>, la función de pérdida es cero. En caso contrario, la función de pérdida exhibe un crecimiento lineal</p></li>
</ul>
<figure class="align-center" id="fig-hinge-lossfn">
<a class="reference internal image-reference" href="_images/hinge_lossfn.png"><img alt="_images/hinge_lossfn.png" src="_images/hinge_lossfn.png" style="width: 307.20000000000005px; height: 232.0px;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 9 </span><span class="caption-text">Función de pérdida <code class="docutils literal notranslate"><span class="pre">hinge</span></code>, para la tarea de clasificación, <span class="math notranslate nohighlight">\(\tau = y\boldsymbol{\theta}^{T}\boldsymbol{x}\)</span>.</span><a class="headerlink" href="#fig-hinge-lossfn" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<ul>
<li><p>Consideraremos en esta sección, la función discriminante en el espacio RKHS</p>
<div class="math notranslate nohighlight">
\[\begin{split}
    \\[1mm]
    f(\boldsymbol{x})=\theta_{0}+\langle\boldsymbol{\theta}, \phi(\boldsymbol{x})\rangle,
    \end{split}\]</div>
<p>donde <span class="math notranslate nohighlight">\(\phi(\boldsymbol{x})\)</span> es el mapeo de características. <code class="docutils literal notranslate"><span class="pre">Proyectamos</span> <span class="pre">la</span> <span class="pre">tarea</span> <span class="pre">de</span> <span class="pre">optimización</span> <span class="pre">como</span> <span class="pre">un</span> <span class="pre">problema</span> <span class="pre">lineal</span> <span class="pre">en</span> <span class="pre">el</span> <span class="pre">espacio</span> <span class="pre">de</span> <span class="pre">inputs</span></code>, <span class="math notranslate nohighlight">\(\mathbb{R}^{l}\)</span>, y al final la información del kernel será implantada usando el <code class="docutils literal notranslate"><span class="pre">kernel</span> <span class="pre">trick</span></code>.</p>
</li>
<li><p>La tarea de diseñar un clasificador lineal, ahora es equivalente a minimizar la función de costo</p></li>
</ul>
<div class="math notranslate nohighlight" id="equation-eq-cost-linear-class">
<span class="eqno">(28)<a class="headerlink" href="#equation-eq-cost-linear-class" title="Permalink to this equation">#</a></span>\[
J(\boldsymbol{\theta}, \theta_{0})=\frac{1}{2}\|\boldsymbol{\theta}\|^{2}+C\sum_{n=1}^{N}\mathcal{L}_{p}(y_{n}, \boldsymbol{\theta}^{T}\boldsymbol{x}_{n}+\theta_{0})
\]</div>
<ul class="simple">
<li><p>Alternativamente,  empleando <code class="docutils literal notranslate"><span class="pre">variables</span> <span class="pre">de</span> <span class="pre">relajación</span> <span class="pre">(slack)</span></code> y siguiendo un razonamiento similar a la regresión de vectores de soporte, minimizar <a class="reference internal" href="#equation-eq-cost-linear-class">(28)</a> es equivalente a:</p></li>
</ul>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align*}
\text{minimizar con respecto a}~\boldsymbol{\theta}, \theta_{0}, \boldsymbol{\xi}:&amp;\quad J(\boldsymbol{\theta}, \boldsymbol{\xi})=\frac{1}{2}\|\boldsymbol{\theta}\|^{2}+C\sum_{n=1}^{N}\boldsymbol{\xi}_{n}\\
\text{sujeto a:}&amp;\quad y_{n}(\boldsymbol{\theta}^{T}\boldsymbol{x}_{n}+\theta_{0})\geq\rho-\boldsymbol{\xi}_{n},\\[2mm]
&amp;\quad\boldsymbol{\xi}_{n}\geq 0,\quad n=1,2,\dots,N.
\end{align*}
\end{split}\]</div>
<ul class="simple">
<li><p>Adoptaremos de ahora en adelante <span class="math notranslate nohighlight">\(\rho=1\)</span> sin pérdida de generalidad. Nótese que <span class="math notranslate nohighlight">\(y_{n}(\boldsymbol{\theta}^{T}\boldsymbol{x}_{n}+\theta_{0})\geq1\)</span> si <span class="math notranslate nohighlight">\(\xi_{n}=0\)</span>, en este caso el margen de error sería nulo. Por otro lado, un margen de error es cometido si <span class="math notranslate nohighlight">\(y_{n}(\boldsymbol{\theta}^{T}\boldsymbol{x}_{n}+\theta_{0})\leq 1\)</span>, correspondiente a <span class="math notranslate nohighlight">\(\xi_{n}&gt;0\)</span>. Por lo tanto, nuestro objetivo para la tarea de optimización es, encontrar <span class="math notranslate nohighlight">\(\boldsymbol{\theta}, \theta_{0}, \xi_{n}\)</span> óptimos, tales que <span class="math notranslate nohighlight">\(\xi_{n}\)</span> sea tan pequeño como sea posible.</p></li>
</ul>
</section>
<section id="clases-linealmente-separables-clasificador-de-maximo-margen">
<h3>Clases linealmente separables: Clasificador de máximo margen<a class="headerlink" href="#clases-linealmente-separables-clasificador-de-maximo-margen" title="Permalink to this headline">#</a></h3>
<ul>
<li><p>Asumiendo que las clases son linealmente separables, hay un número infinito de clasificadores que solucionan la tarea exactamente, sin error, en el conjunto de entrenamiento. Se puede ver que de estos infinitos hiperplanos que solucionan la tarea, podemos identificar un subconjunto tal que</p>
<div class="math notranslate nohighlight">
\[\begin{split}
    \\[1mm]
    y_{n}(\boldsymbol{\theta}^{T}\boldsymbol{x}_{n}+\theta_{0})\geq 1,\quad n=1,2,\dots,N,
    \end{split}\]</div>
<p>el cual garantiza que <span class="math notranslate nohighlight">\(\xi_{n}=0,~n=1,2,\dots,N\)</span>. Por lo tanto, para clases linealmente separables, la tarea de optimización previa es equvalente a</p>
<div class="math notranslate nohighlight" id="equation-eq-opt-task-linear-class-sep">
<span class="eqno">(29)<a class="headerlink" href="#equation-eq-opt-task-linear-class-sep" title="Permalink to this equation">#</a></span>\[\begin{split}
    \\[1mm]
    \begin{align*}
    \text{minimizar con respecto a}~\theta:&amp;\quad\frac{1}{2}\|\boldsymbol{\theta}\|^{2}\\
    \text{sujeto a:}&amp;\quad y_{n}(\boldsymbol{\theta}^{T}\boldsymbol{x}_{n}+\theta_{0})\geq 1,\quad n=1,2,\dots,N.
    \end{align*}
    \end{split}\]</div>
</li>
</ul>
<ul>
<li><p>En otras palabras, de este conjunto infinito de clasificadores lineales (ver <a class="reference internal" href="#inf-correct-classification"><span class="std std-numref">Fig. 10</span></a>), los cuales soluciona la tarea de optimización, y clasifican correctamente todos los patrones, se selecciona aquel que tiene mínima norma. Veremos mas adelante que, la norma <span class="math notranslate nohighlight">\(\|\boldsymbol{\theta}\|\)</span> está directamente relacionada con el margen formado por el respectivo clasificador. Cada hiperplano en el espacio está descrito por la ecuación</p>
<div class="math notranslate nohighlight">
\[\begin{split}
    \\[1mm]
    f(\boldsymbol{x})=\boldsymbol{\theta}^{T}\boldsymbol{x}+\theta_{0}=0.
    \end{split}\]</div>
</li>
</ul>
<figure class="align-center" id="inf-correct-classification">
<a class="reference internal image-reference" href="_images/inf_correct_classification.png"><img alt="_images/inf_correct_classification.png" src="_images/inf_correct_classification.png" style="width: 433.6px; height: 310.40000000000003px;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 10 </span><span class="caption-text">Número infinito de clasificadores lineales que pueden clasificar correctamente todos los patrones de una clase linealmente separable.</span><a class="headerlink" href="#inf-correct-classification" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<ul class="simple">
<li><p>De la geometria analítica sabemos que la dirección en espacio es controlada por <span class="math notranslate nohighlight">\(\boldsymbol{\theta}\)</span> y su posición por <span class="math notranslate nohighlight">\(\theta_{0}\)</span>. De todos los hiperplanos que solucionan la tarea de optimización y tienen la misma dirección (comparten <span class="math notranslate nohighlight">\(\boldsymbol{\theta}\)</span>), seleccionamos <span class="math notranslate nohighlight">\(\theta_{0}\)</span> tal que, el hiperplano queda dentro de dos clases, de modo que su distancia a los puntos más cercanos es siempre la misma para las dos clases.</p></li>
</ul>
<figure class="align-center" id="fig-svm-class-sep">
<a class="reference internal image-reference" href="_images/svm_class_sep.png"><img alt="_images/svm_class_sep.png" src="_images/svm_class_sep.png" style="width: 463.20000000000005px; height: 320.8px;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 11 </span><span class="caption-text">Las líneas punteadas, <span class="math notranslate nohighlight">\(\boldsymbol{\theta}^{T}\boldsymbol{x} + \theta_{0} =±1\)</span>, que pasan por los puntos más cercanos, son paralelas al clasificador respectivo y definen el margen (ancho de banda) <span class="math notranslate nohighlight">\(2/\|\boldsymbol{\theta}\|\)</span>.</span><a class="headerlink" href="#fig-svm-class-sep" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<ul>
<li><p>De la geometría básica sabemos que la distancia de un punto <span class="math notranslate nohighlight">\(\boldsymbol{x}\)</span> al hiperplano está dada por</p>
<div class="math notranslate nohighlight">
\[\begin{split}
    \\[1mm]
    z=\frac{|\boldsymbol{\theta}^{T}\boldsymbol{x}+\theta_{0}|}{\|\boldsymbol{\theta}\|}
    \end{split}\]</div>
<p>la cual es claramente cero cuando <span class="math notranslate nohighlight">\(\boldsymbol{x}\)</span> está dentro del hiperplano <span class="math notranslate nohighlight">\(\boldsymbol{\theta}^{T}\boldsymbol{x}+\theta_{0}=0\)</span>. Donde los prámetros <span class="math notranslate nohighlight">\(\boldsymbol{\theta}\)</span> y <span class="math notranslate nohighlight">\(\theta_{0}\)</span> pueden ser escalados apropiadamente, de tal forma que <span class="math notranslate nohighlight">\(|\boldsymbol{\theta}^{T}\boldsymbol{x}+\theta_{0}|=1\)</span>, esto es, la distancia de los puntos más cercanos entre las dos clases al hiperplano es igual a <span class="math notranslate nohighlight">\(1/\|\boldsymbol{\theta}\|\)</span>.</p>
</li>
</ul>
<ul class="simple">
<li><p>Equivalentemente, el escalamiento garantiza que: <span class="math notranslate nohighlight">\(f(\boldsymbol{x})=\pm 1\)</span>, si <span class="math notranslate nohighlight">\(\boldsymbol{x}\)</span> es el punto más cercano al hiperplano, y dependiendo de si el punto <span class="math notranslate nohighlight">\(x\)</span> pertence a <span class="math notranslate nohighlight">\(\omega_{1} (+1)\)</span> o <span class="math notranslate nohighlight">\(\omega_{2} (-1)\)</span>. Los dos hiperplanos se pueden visualizar en la <a class="reference internal" href="#fig-svm-class-sep"><span class="std std-numref">Fig. 11</span></a> <span class="math notranslate nohighlight">\((f(\boldsymbol{x})=\pm1)\)</span>. Estos dos hiperplanos definen el margen correspondiente de longitud <span class="math notranslate nohighlight">\(2/\|\boldsymbol{\theta}\|\)</span> para cada iteración.</p></li>
</ul>
<ul>
<li><p>Cualquier clasificador construido de la forma anterior, soluciona la tarea de optimización, y además satisface las siguientes propiedades:</p>
<ul class="simple">
<li><p>Tiene un margen de longitud igual a: <span class="math notranslate nohighlight">\(\displaystyle{1/\|\boldsymbol{\theta}\|+1/\|\boldsymbol{\theta}}\|\)</span></p></li>
<li><p>Además:</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
    \boldsymbol{\theta}^{T}\boldsymbol{x}_{n}+\theta_{0}\geq 1,\quad\boldsymbol{x}_{n}\in\omega_{1}~\text{y}~\boldsymbol{\theta}^{T}\boldsymbol{x}_{n}+\theta_{0}\leq-1,\quad\boldsymbol{x}_{n}\in\omega_{2}
    \]</div>
<p>Por lo tanto la tarea de optimización <a class="reference internal" href="#equation-eq-opt-task-linear-class-sep">(29)</a> <code class="docutils literal notranslate"><span class="pre">calcula</span> <span class="pre">el</span> <span class="pre">clasificador</span> <span class="pre">lineal</span> <span class="pre">que</span> <span class="pre">maximiza</span> <span class="pre">el</span> <span class="pre">margen</span> <span class="pre">sujeto</span> <span class="pre">a</span> <span class="pre">las</span> <span class="pre">respectivas</span> <span class="pre">restricciones</span></code>.</p>
</li>
</ul>
<p><strong><code class="docutils literal notranslate"><span class="pre">Solución</span></code></strong></p>
<ul>
<li><p>Siguiendo pasos similares a <code class="docutils literal notranslate"><span class="pre">SVR</span></code>, la solución esta dada por, combinación lineal de un subconjunto de muestras de entrenamiento, esto es:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
    \\[1mm]
    \hat{\boldsymbol{\theta}}=\sum_{n=1}^{N_{s}}\lambda_{n}y_{n}\boldsymbol{x}_{n},
    \end{split}\]</div>
<p>donde <span class="math notranslate nohighlight">\(N_{s}\)</span> es el número de multiplicadores de Lagrange distintos de cero. <code class="docutils literal notranslate"><span class="pre">Multiplicadores</span> <span class="pre">de</span> <span class="pre">Lagrange</span> <span class="pre">asociados</span> <span class="pre">a</span> <span class="pre">los</span> <span class="pre">puntos</span> <span class="pre">más</span> <span class="pre">cercanos</span> <span class="pre">al</span> <span class="pre">clasificador,</span> <span class="pre">esto</span> <span class="pre">es,</span> <span class="pre">puntos</span> <span class="pre">que</span> <span class="pre">satisfacen</span> <span class="pre">la</span> <span class="pre">restricción</span> <span class="pre">con</span> <span class="pre">igualdad</span></code> <span class="math notranslate nohighlight">\((y_{n}(\boldsymbol{\theta}^{T}\boldsymbol{x}_{n}+\theta_{0})=1)\)</span>, <code class="docutils literal notranslate"><span class="pre">son</span> <span class="pre">distintos</span> <span class="pre">de</span> <span class="pre">cero</span></code>. Estos son conocidos como <code class="docutils literal notranslate"><span class="pre">vectores</span> <span class="pre">de</span> <span class="pre">soporte</span></code>. Multiplicadores de Lagrange correspondientes a puntos tales que <span class="math notranslate nohighlight">\((y_{n}(\boldsymbol{\theta}^{T}\boldsymbol{x}_{n}+\theta_{0})&gt;1)\)</span>, son iguales a cero.</p>
</li>
</ul>
<ul>
<li><p>Para el caso mas general, en el espacio RKHS, tenemos que:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
    \\[1mm]
    \hat{\theta}(\cdot)=\sum_{n=1}^{N_{s}}\lambda_{n}y_{n}\kappa(\cdot, \boldsymbol{x}_{n}),
    \end{split}\]</div>
<p>estimación la cual entrega la siguiente regla de predicción. Dado un valor desconocido <span class="math notranslate nohighlight">\(\boldsymbol{x}\)</span>, su clase es predicha de acuerdo al signo de:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
    \\[1mm]
    \hat{y}(\boldsymbol{x})=\sum_{n=1}^{N_{s}}\lambda_{n}y_{n}\kappa(\boldsymbol{x}, \boldsymbol{x}_{n})+\hat{\theta}_{0}:\quad\textit{Predicción SVM},
    \end{split}\]</div>
<p>donde <span class="math notranslate nohighlight">\(\hat{\theta}_{0}\)</span> es obtenido solucionando todas las restricciones con <span class="math notranslate nohighlight">\(\lambda_{n}\neq0\)</span>, correspondientes a:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
    \\[1mm]
    y_{n}(\hat{\boldsymbol{\theta}}^{T}\boldsymbol{x}_{n}+\hat{\theta}_{0})-1=0,\quad n=1,2,\dots,N_{s},
    \end{split}\]</div>
<p>la cual para el caso RKHS se convierte en:</p>
<div class="math notranslate nohighlight" id="equation-mean-sol-fortheta0">
<span class="eqno">(30)<a class="headerlink" href="#equation-mean-sol-fortheta0" title="Permalink to this equation">#</a></span>\[\begin{split}
    \\[1mm]
    y_{n}\left(\sum_{m=1}^{N_{s}}\lambda_{m}y_{m}\kappa(\boldsymbol{x}_{m}, \boldsymbol{x}_{n})+\hat{\theta}_{0}\right)-1=0,\quad n=1,2,\dots,N_{s},
    \end{split}\]</div>
<p>donde <span class="math notranslate nohighlight">\(\hat{\theta}_{0}\)</span> es obtenido por medio del promedio entre las soluciones de <a class="reference internal" href="#equation-mean-sol-fortheta0">(30)</a>. Aunque la solución es única, los correspondientes multiplicadores <span class="math notranslate nohighlight">\(\lambda_{m}\)</span> pueden no ser únicos. Finalmente el número de vectores de soporte está relacionado con la capacidad de generalización del clasificador. Entre mas pequeño es el número de vectores de soporte, mejor será la generalización esperada (ver <span id="id13">[<a class="reference internal" href="#id36" title="佐土原健. N. cristianini and j. shawe-taylor: an introduction to support vector machines, cambridge university press (2000). 人工知能, 16(2):337–337, 2001.">佐土原健, 2001</a>, <a class="reference internal" href="#id37" title="Konstantinos Koutroumbas and Sergios Theodoridis. Pattern recognition. Academic Press, 2008.">Koutroumbas and Theodoridis, 2008</a>]</span>).</p>
</li>
</ul>
<p><strong><code class="docutils literal notranslate"><span class="pre">Tarea</span> <span class="pre">de</span> <span class="pre">optimización</span></code></strong></p>
<ul class="simple">
<li><p>Procedemos de forma similar a <code class="docutils literal notranslate"><span class="pre">SVR</span></code>. El Lagrangiano asociado a la tarea de clasificación está dado por:</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
L(\boldsymbol{\theta}, \theta_{0}, \lambda)=\frac{1}{2}\|\boldsymbol{\theta}\|^{2}-\sum_{n=1}^{N}\lambda_{n}(y_{n}(\boldsymbol{\theta}^{T}\boldsymbol{x}_{n}+\theta_{0})-1),
\]</div>
<ul class="simple">
<li><p>Calculando las derivadas parciales <span class="math notranslate nohighlight">\(\partial_{\boldsymbol{\theta}}=0\)</span> y <span class="math notranslate nohighlight">\(\partial_{\theta_{0}}=0\)</span>, se tienen las condiciones siguientes</p></li>
</ul>
<div class="math notranslate nohighlight" id="equation-opt-task-svm-class">
<span class="eqno">(31)<a class="headerlink" href="#equation-opt-task-svm-class" title="Permalink to this equation">#</a></span>\[\begin{split}
\begin{align*}
\frac{\partial L}{\partial\boldsymbol{\theta}}&amp;=0\Leftrightarrow\boldsymbol{\theta}-\sum_{n=1}^{N}\lambda_{n}y_{n}\boldsymbol{x}_{n}=0\Rightarrow\hat{\boldsymbol{\theta}}=\sum_{n=1}^{N}\lambda_{n}y_{n}\boldsymbol{x}_{n}\\
\frac{\partial L}{\partial\theta_{0}}&amp;=0\Leftrightarrow-\sum_{n=1}^{N}\lambda_{n}y_{n}=0\Rightarrow\sum_{n=1}^{N}\lambda_{n}y_{n}=0,\\
\lambda_{n}(y_{n}(\boldsymbol{\theta}^{T}\boldsymbol{x}_{n}+\theta_{0})-1)&amp;=0,\quad n=1,2,\dots,N,\\[2mm]
\lambda_{n}&amp;\geq0,\quad n=1,2,\dots,N.
\end{align*}
\end{split}\]</div>
<ul class="simple">
<li><p>Los multiplicadores son obtenidos por medio de la representación dual de <a class="reference internal" href="#equation-opt-task-svm-class">(31)</a> en el Lagrangiano</p></li>
</ul>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align*}
L(\boldsymbol{\theta}, \theta_{0}, \lambda)&amp;=\frac{1}{2}\left\langle\sum_{m=1}^{N}\lambda_{m}y_{m}\boldsymbol{x}_{m},\sum_{n=1}^{N}\lambda_{n}y_{n}\boldsymbol{x}_{n}\right\rangle-\sum_{n=1}^{N}\lambda_{n}(y_{n}(\boldsymbol{\theta}\boldsymbol{x}_{n}+\theta_{0})-1)\\
&amp;=\frac{1}{2}\sum_{n=1}^{N}\sum_{m=1}^{N}\lambda_{n}\lambda_{m}y_{n}y_{m}\boldsymbol{x}_{n}^{T}\boldsymbol{x}_{m}-\sum_{n=1}^{N}\sum_{n=1}^{N}\lambda_{n}\lambda_{m}y_{n}y_{m}\boldsymbol{x}_{n}^{T}\boldsymbol{x}_{m}+\sum_{n=1}^{N}\lambda_{n}\\
&amp;=\sum_{n=1}^{N}\lambda_{n}-\frac{1}{2}\sum_{n=1}^{N}\sum_{m=1}^{N}\lambda_{n}\lambda_{m}y_{n}y_{m}\boldsymbol{x}_{n}^{T}\boldsymbol{x}_{m}
\end{align*}
\end{split}\]</div>
<ul class="simple">
<li><p>En base a lo anterior, la siguiente es la representación dual de la tarea de optimización</p></li>
</ul>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align*}
\text{minimizar con respecto a }~\lambda:&amp;\quad\sum_{n=1}^{N}\lambda_{n}-\frac{1}{2}\sum_{n=1}^{N}\sum_{m=1}^{N}\lambda_{n}\lambda_{m}y_{n}y_{m}\boldsymbol{x}_{n}^{T}\boldsymbol{x}_{m}\\
\text{sujeto a}:&amp;\quad\lambda_{n}\geq0,\quad\sum_{n=1}^{N}\lambda_{n}y_{n}=0.
\end{align*}
\end{split}\]</div>
<ul class="simple">
<li><p>Para el caso en que la tarea de optimización original es mapeada en el espacio RKHS, la función de costo viene dada por</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
\sum_{n=1}^{N}\lambda_{n}-\frac{1}{2}\sum_{n=1}^{N}\sum_{m=1}^{N}\lambda_{n}\lambda_{m}y_{n}y_{m}\kappa(\boldsymbol{x}_{n}, \boldsymbol{x}_{m})
\]</div>
<ul class="simple">
<li><p>De acuerdo con la restricción: <span class="math notranslate nohighlight">\(\lambda_{n}(y_{n}(\boldsymbol{\theta}^{T}\boldsymbol{x}_{n}+\theta_{0})-1)=0,~n=1,2,\dots,N\)</span>, si <span class="math notranslate nohighlight">\(\lambda_{n}\neq0\)</span>, entonces necesariamente <span class="math notranslate nohighlight">\(y_{n}(\boldsymbol{\theta}^{T}\boldsymbol{x}_{n}+\theta_{0})=1\)</span>. Estos son los puntos mas cercanos, desde cada clases al clasificador (distancia <span class="math notranslate nohighlight">\(1/\|\boldsymbol{\theta}\|\)</span>). Estos puntos caen en cualquiera de los hiperplanos formando el borde del margen. Estos puntos se conocen como los <code class="docutils literal notranslate"><span class="pre">vectores</span> <span class="pre">de</span> <span class="pre">soporte</span></code> y las respectivas restricciones son conocidas como <code class="docutils literal notranslate"><span class="pre">restricciones</span> <span class="pre">activas</span></code>. El resto de puntos asociados con <span class="math notranslate nohighlight">\(y_{n}(\boldsymbol{\theta}^{T}\boldsymbol{x}_{n}+\theta_{0})&gt;1\)</span>, los cuales quedan por fuera del margen corresponden a <span class="math notranslate nohighlight">\(\lambda_{n}=0\)</span>, y las restricciones asociadas son conocidas como las <code class="docutils literal notranslate"><span class="pre">restricciones</span> <span class="pre">inactivas</span></code>.</p></li>
</ul>
</section>
<section id="clases-no-separables">
<h3>Clases no separables<a class="headerlink" href="#clases-no-separables" title="Permalink to this headline">#</a></h3>
<ul class="simple">
<li><p>Centraremos ahora nuestra atención en un caso mas realista en el que las clases se superponen. En este caso <code class="docutils literal notranslate"><span class="pre">no</span> <span class="pre">existe</span> <span class="pre">un</span> <span class="pre">clasificador</span> <span class="pre">lineal</span> <span class="pre">que</span> <span class="pre">pueda</span> <span class="pre">clasificar</span> <span class="pre">correctamente</span> <span class="pre">todos</span> <span class="pre">los</span> <span class="pre">puntos</span></code>, algunos errores de clasificación pueden ocurrir. Existen tres tipos de puntos mal clasificados.</p></li>
</ul>
<ol>
<li><p>Puntos que se encuentran en la frontera o fuera del margen y en el lado correcto del clasificador, esto es</p>
<div class="math notranslate nohighlight">
\[
    y_{n}f(\boldsymbol{x}_{n})\geq1.
    \]</div>
<p>Estos puntos no cometen margen de error, esto es:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
    \\[1mm]
    \xi_{n}=0.
    \end{split}\]</div>
</li>
<li><p>Puntos que se encuentran en el lado correcto del clasificador, pero se encuentran dentro del margen, esto es</p>
<div class="math notranslate nohighlight">
\[
    0&lt;y_{n}f(\boldsymbol{x}_{n})&lt;1.
    \]</div>
<p>Estos puntos cometen un margen de error, y se tiene que,</p>
<div class="math notranslate nohighlight">
\[\begin{split}
    \\[1mm]
    0&lt;\xi_{n}&lt;1.
    \end{split}\]</div>
</li>
<li><p>Puntos que se encuentran en el lugar equivocado del clasificador, esto es,</p>
<div class="math notranslate nohighlight">
\[\begin{split}
    \\[1mm]
    y_{n}f(\boldsymbol{x}_{n})\leq0.
    \end{split}\]</div>
<p>Estos puntos cometen un eror, y se tiene que</p>
<div class="math notranslate nohighlight">
\[\begin{split}
    \\[1mm]
    \xi_{n}\geq1.
    \end{split}\]</div>
</li>
</ol>
<figure class="align-center" id="non-separable-classes-svm">
<img alt="_images/non_separable_classes_svm.png" src="_images/non_separable_classes_svm.png" />
<figcaption>
<p><span class="caption-number">Fig. 12 </span><span class="caption-text">Puntos para clases que se solapan: (1) puntos que se encuentran fuera o en los límites del margen y se clasifican correctamente (<span class="math notranslate nohighlight">\(\xi_{n} = 0\)</span>); (2) puntos dentro del margen y clasificados correctamente (<span class="math notranslate nohighlight">\(0 &lt; \xi_{n} &lt; 1\)</span>), denotados por círculos; y (3) puntos mal clasificados, denotados por un cuadrado <span class="math notranslate nohighlight">\((\xi_{n}\geq 1\)</span>).</span><a class="headerlink" href="#non-separable-classes-svm" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<ul class="simple">
<li><p>Nuestro objetivo es <code class="docutils literal notranslate"><span class="pre">estimar</span> <span class="pre">el</span> <span class="pre">hiperplano</span> <span class="pre">clasificador</span> <span class="pre">que</span> <span class="pre">maximiza</span> <span class="pre">el</span> <span class="pre">margen</span> <span class="pre">y</span> <span class="pre">al</span> <span class="pre">mismo</span> <span class="pre">tiempo</span> <span class="pre">mantiene</span> <span class="pre">el</span> <span class="pre">número</span> <span class="pre">de</span> <span class="pre">errores</span> <span class="pre">(incluyendo</span> <span class="pre">el</span> <span class="pre">margen</span> <span class="pre">del</span> <span class="pre">error)</span> <span class="pre">tan</span> <span class="pre">pequeño</span> <span class="pre">como</span> <span class="pre">sea</span> <span class="pre">posible</span></code>.</p></li>
</ul>
<p><strong><code class="docutils literal notranslate"><span class="pre">Solución</span></code></strong></p>
<ul>
<li><p>Una vez mas la solución está dada por una combinación lineal de un subconjunto de puntos de entrenamiento</p>
<div class="math notranslate nohighlight">
\[
    \boldsymbol{\hat{\theta}}=\sum_{n=1}^{N_{s}}\lambda_{n}y_{n}\boldsymbol{x}_{n},
    \]</div>
<p>donde <span class="math notranslate nohighlight">\(\lambda_{n},~n=1,2,\dots,N\)</span>, son los multiplicadores de Lagrange asociados con los vectores de soporte. Los puntos <span class="math notranslate nohighlight">\(\boldsymbol{x}_{n}\)</span> pueden satisfacer cualquiera de los tres casos para tipos de datos de entrenamiento.</p>
</li>
</ul>
<p><strong><code class="docutils literal notranslate"><span class="pre">Tarea</span> <span class="pre">de</span> <span class="pre">optimización</span></code></strong></p>
<ul class="simple">
<li><p>El Lagrangiano asociado con la tarea de optimización está dado por:</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
L(\boldsymbol{\theta}, \theta_{0}, \xi, \lambda)=\frac{1}{2}\|\boldsymbol{\theta}\|^{2}+C\sum_{n=1}^{N}\xi_{n}-\sum_{n=1}^{N}\mu_{n}\xi_{n}-\sum_{n=1}^{N}\lambda_{n}(y_{n}(\boldsymbol{\theta}^{T}\boldsymbol{x}_{n}+\theta_{0})-1+\xi_{n})
\]</div>
<ul class="simple">
<li><p>Entonces</p></li>
</ul>
<div class="math notranslate nohighlight" id="equation-eq-class-svm-nonsep">
<span class="eqno">(32)<a class="headerlink" href="#equation-eq-class-svm-nonsep" title="Permalink to this equation">#</a></span>\[\begin{split}
\begin{align*}
\frac{\partial L}{\partial\boldsymbol{\theta}}&amp;=0\Leftrightarrow\boldsymbol{\theta}-\sum_{n=1}^{N}\lambda_{n}y_{n}\boldsymbol{x}_{n}=0\Rightarrow\hat{\boldsymbol{\theta}}=\sum_{n=1}^{N}\lambda_{n}y_{n}\boldsymbol{x}_{n}\\
\frac{\partial L}{\partial\theta_{0}}&amp;=0\Leftrightarrow-\sum_{n=1}^{N}\lambda_{n}y_{n}=0\Rightarrow\sum_{n=1}^{N}\lambda_{n}y_{n}=0\\
\frac{\partial L}{\partial\xi_{n}}&amp;=0\Leftrightarrow C-\mu_{n}-\lambda_{n}=0,\\[2mm]
\lambda_{n}(y_{n}(\boldsymbol{\theta}^{T}\boldsymbol{x}_{n}+\theta_{0})-1+\xi_{n})&amp;=0,\quad n=1,2,\dots,N,\\[2mm]
\mu_{n}\xi_{n}&amp;=0,\quad n=1,2,\dots,N,\\[2mm]
\mu_{n}\geq,~\lambda_{n}\geq&amp;0,\quad n=1,2,\dots,N.
\end{align*}
\end{split}\]</div>
<ul class="simple">
<li><p>El problema dual entonces es proyectado como:</p></li>
</ul>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align*}
\text{maximizar con respecto a }~\lambda:&amp;\quad\sum_{n=1}^{N}\lambda_{n}-\frac{1}{2}\sum_{n=1}^{N}\sum_{m=1}^{N}\lambda_{n}\lambda_{m}y_{n}y_{m}\boldsymbol{x}_{n}^{T}\boldsymbol{x}_{m}\\
\text{sujeto a}:&amp;\quad0\leq\lambda_{n}\leq C, n=1,2,\dots,N,\quad\sum_{n=1}^{N}\lambda_{n}y_{n}=0.
\end{align*}
\end{split}\]</div>
<ul>
<li><p>Cuando se trabaja en un espacio RKHS, la función de coste se convierte en</p>
<div class="math notranslate nohighlight">
\[\begin{split}
    \\[1mm]
    \sum_{n=1}^{N}\lambda_{n}-\frac{1}{2}\sum_{n=1}^{N}\sum_{m=1}^{N}\lambda_{n}\lambda_{m}y_{n}y_{m}\kappa(\boldsymbol{x}_{n}, \boldsymbol{x}_{m})
    \end{split}\]</div>
<p>Obsérvese que la única diferencia con respecto a su contraparte linealmente separable es la existencia de <span class="math notranslate nohighlight">\(C\)</span> en las restricciones de desigualdad para <span class="math notranslate nohighlight">\(\lambda_{n}\)</span>.</p>
</li>
</ul>
<ul>
<li><p>A partir de <a class="reference internal" href="#equation-eq-class-svm-nonsep">(32)</a> concluimos que para todos los puntos fuera del margen, y en el lado correcto del clasificador, que corresponden a <span class="math notranslate nohighlight">\(\xi_{n} = 0\)</span>, tenemos</p>
<div class="math notranslate nohighlight">
\[\begin{split}
    \\[1mm]
    y_{n}(\boldsymbol{\theta}\boldsymbol{x}_{n}+\theta_{0})&gt;1,
    \end{split}\]</div>
<p>por lo tanto, <span class="math notranslate nohighlight">\(\lambda_{n}=0\)</span>. Esto es, estos puntos no participan en la formación de la solución <span class="math notranslate nohighlight">\(\hat{\boldsymbol{\theta}}\)</span> en <a class="reference internal" href="#equation-eq-class-svm-nonsep">(32)</a>.</p>
</li>
<li><p>Tenemos <span class="math notranslate nohighlight">\(\lambda_{n}\neq0\)</span> sólo para los puntos en los hiperplanos de la frontera, dentro o fuera del margen, pero en el lado equivocado del clasificador. Estos son los <code class="docutils literal notranslate"><span class="pre">vectores</span> <span class="pre">de</span> <span class="pre">soporte</span></code>.</p></li>
<li><p>Para los puntos que se encuentran dentro del margen o fuera pero en el lado equivocado, <span class="math notranslate nohighlight">\(\xi_{n}&gt;0\)</span>; por lo tanto, a partir de <a class="reference internal" href="#equation-eq-class-svm-nonsep">(32)</a> se tiene que <span class="math notranslate nohighlight">\(\mu_{n} = 0\)</span> y además <span class="math notranslate nohighlight">\(\lambda_{n}=C\)</span>.</p></li>
<li><p>Los vectores de soporte que se encuentran en los hiperplanos de la frontera del margen satisfacen <span class="math notranslate nohighlight">\(\xi_{n} = 0\)</span> y, por tanto, <span class="math notranslate nohighlight">\(\mu_{n}\)</span> puede ser distinto de cero, lo que lleva a <span class="math notranslate nohighlight">\(0\leq\lambda_{n}\leq C\)</span>.</p></li>
</ul>
</section>
<section id="aplicacion">
<h3>Aplicación<a class="headerlink" href="#aplicacion" title="Permalink to this headline">#</a></h3>
</section>
<section id="modelos-lineales-y-caracteristicas-no-lineales">
<h3>Modelos lineales y características no lineales<a class="headerlink" href="#modelos-lineales-y-caracteristicas-no-lineales" title="Permalink to this headline">#</a></h3>
<ul class="simple">
<li><p>Como se ha visto antes, los modelos lineales pueden ser bastante limitados en espacios de baja dimensión, ya que las líneas y los hiperplanos tienen una flexibilidad limitada. Una forma de hacer que un modelo lineal sea mas flexible es añadiendo más características, por ejemplo, añadiendo interacciones o polinomios de las características de entrada. Veamos el dataset sintetico utilizado en <code class="docutils literal notranslate"><span class="pre">Feature</span> <span class="pre">importance</span></code></p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">make_blobs</span>
<span class="kn">import</span> <span class="nn">mglearn</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>El vector de <code class="docutils literal notranslate"><span class="pre">labels</span></code> y, está compuesto por las clases <code class="docutils literal notranslate"><span class="pre">0,</span> <span class="pre">1,</span> <span class="pre">2,</span> <span class="pre">3</span></code>. Convertimos el problema, en uno binario, usando la clase residual modulo 2, mediante: <code class="docutils literal notranslate"><span class="pre">y</span> <span class="pre">=</span> <span class="pre">y</span> <span class="pre">%</span> <span class="pre">2</span></code></p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">make_blobs</span><span class="p">(</span><span class="n">centers</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">y</span> <span class="o">%</span> <span class="mi">2</span>
<span class="n">mglearn</span><span class="o">.</span><span class="n">discrete_scatter</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">y</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Feature 0&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Feature 1&quot;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/supervised_learning_491_0.png" src="_images/supervised_learning_491_0.png" />
</div>
</div>
<ul class="simple">
<li><p>Un modelo lineal de clasificación sólo puede separar los puntos mediante una línea, por lo tanto, no podrá hacer un buen trabajo en este conjunto de datos</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.svm</span> <span class="kn">import</span> <span class="n">LinearSVC</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">linear_svm</span> <span class="o">=</span> <span class="n">LinearSVC</span><span class="p">()</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="n">mglearn</span><span class="o">.</span><span class="n">plots</span><span class="o">.</span><span class="n">plot_2d_separator</span><span class="p">(</span><span class="n">linear_svm</span><span class="p">,</span> <span class="n">X</span><span class="p">)</span>
<span class="n">mglearn</span><span class="o">.</span><span class="n">discrete_scatter</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">y</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Feature 0&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Feature 1&quot;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/supervised_learning_494_0.png" src="_images/supervised_learning_494_0.png" />
</div>
</div>
<ul class="simple">
<li><p>Ahora vamos a ampliar el conjunto de características de entrada, digamos que añadiendo también <code class="docutils literal notranslate"><span class="pre">feature1</span> <span class="pre">**</span> <span class="pre">2</span></code>, el cuadrado de la segunda característica, como una nueva característica. En lugar de representar cada punto de datos como un punto bidimensional, (<code class="docutils literal notranslate"><span class="pre">feature0</span></code>, <code class="docutils literal notranslate"><span class="pre">feature1</span></code>), ahora lo representamos como un punto tridimensional, (<code class="docutils literal notranslate"><span class="pre">feature0</span></code>, <code class="docutils literal notranslate"><span class="pre">feature1</span></code>, <code class="docutils literal notranslate"><span class="pre">feature1</span> <span class="pre">**</span> <span class="pre">2</span></code>). Esta nueva representación se ilustra en el siguiente grafico de dispersión tridimensional</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X_new</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">([</span><span class="n">X</span><span class="p">,</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">:]</span> <span class="o">**</span> <span class="mi">2</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Nótese que al nuevo array <code class="docutils literal notranslate"><span class="pre">X_new</span></code> se le agregó una tercera columna utilizando la segunda columna de <code class="docutils literal notranslate"><span class="pre">X</span></code>, <code class="docutils literal notranslate"><span class="pre">X[:,</span> <span class="pre">1:]</span></code></p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X_new</span><span class="p">[:</span><span class="mi">5</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([[-1.72161036, -1.48033142,  2.19138111],
       [-3.6573384 , -9.5482383 , 91.16885455],
       [ 7.0778163 ,  0.99508772,  0.99019957],
       [-1.36579859, -0.3148625 ,  0.09913839],
       [-2.66521206, -3.12591651,  9.77135405]])
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">mpl_toolkits.mplot3d</span> <span class="kn">import</span> <span class="n">Axes3D</span><span class="p">,</span> <span class="n">axes3d</span>
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Visualizar los datos en 3D y trazamos primero todos los puntos con <code class="docutils literal notranslate"><span class="pre">y</span> <span class="pre">==</span> <span class="pre">0</span></code>, luego todos con <code class="docutils literal notranslate"><span class="pre">y</span> <span class="pre">==</span> <span class="pre">1</span></code>. Si está interesado en conocer mas sobre los argumentos que puede utilizar en la función <code class="docutils literal notranslate"><span class="pre">scatter</span></code> (ver <a class="reference external" href="https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.scatter.html">matplotlib.pyplot.scatter</a>)</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">figure</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">Axes3D</span><span class="p">(</span><span class="n">figure</span><span class="p">,</span> <span class="n">elev</span><span class="o">=-</span><span class="mi">152</span><span class="p">,</span> <span class="n">azim</span><span class="o">=-</span><span class="mi">26</span><span class="p">)</span>

<span class="n">mask</span> <span class="o">=</span> <span class="n">y</span> <span class="o">==</span> <span class="mi">0</span> <span class="c1"># Boolean para etiquetado</span>
<span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X_new</span><span class="p">[</span><span class="n">mask</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X_new</span><span class="p">[</span><span class="n">mask</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">X_new</span><span class="p">[</span><span class="n">mask</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;b&#39;</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">mglearn</span><span class="o">.</span><span class="n">cm2</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">60</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X_new</span><span class="p">[</span><span class="o">~</span><span class="n">mask</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X_new</span><span class="p">[</span><span class="o">~</span><span class="n">mask</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">X_new</span><span class="p">[</span><span class="o">~</span><span class="n">mask</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;r&#39;</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;^&#39;</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">mglearn</span><span class="o">.</span><span class="n">cm2</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">60</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;feature0&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;feature1&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_zlabel</span><span class="p">(</span><span class="s2">&quot;feature1 ** 2&quot;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/supervised_learning_501_0.png" src="_images/supervised_learning_501_0.png" />
</div>
</div>
<ul class="simple">
<li><p>En esta nueva representación de los datos, <code class="docutils literal notranslate"><span class="pre">ahora</span> <span class="pre">sí</span> <span class="pre">es</span> <span class="pre">posible</span> <span class="pre">separar</span> <span class="pre">las</span> <span class="pre">dos</span> <span class="pre">clases</span> <span class="pre">mediante</span> <span class="pre">un</span> <span class="pre">modelo</span> <span class="pre">lineal,</span> <span class="pre">un</span> <span class="pre">plano</span> <span class="pre">en</span> <span class="pre">tres</span> <span class="pre">dimensiones</span></code>. Podemos confirmarlo ajustando un modelo lineal a los datos aumentados</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">linear_svm_3d</span> <span class="o">=</span> <span class="n">LinearSVC</span><span class="p">()</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_new</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="n">coef</span><span class="p">,</span> <span class="n">intercept</span> <span class="o">=</span> <span class="n">linear_svm_3d</span><span class="o">.</span><span class="n">coef_</span><span class="o">.</span><span class="n">ravel</span><span class="p">(),</span> <span class="n">linear_svm_3d</span><span class="o">.</span><span class="n">intercept_</span>
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Puede imprimir los coeficientes e intercepto (<code class="docutils literal notranslate"><span class="pre">coef,</span> <span class="pre">intercept</span></code>) del plano de la forma <span class="math notranslate nohighlight">\(\beta_{0}+\beta_{1}x_{1}+\beta_{2}x_{2}+\beta_{3}x_{3}=0\)</span> que separa las dos clases. Nótese que en este caso se está realizando un mapeo de caracterísitcas a un espaciod e Hilbert, de mayor dimensión, donde se linealiza nuestro problema de clasificación. Aquí <code class="docutils literal notranslate"><span class="pre">rstride,</span> <span class="pre">cstride</span></code> son utilizados para realizar dividisiones uniformes en el plano XY, <code class="docutils literal notranslate"><span class="pre">elev</span></code> y <code class="docutils literal notranslate"><span class="pre">azim</span></code> son ángulos de rotación en grados gira la imagen en XY y Z respectivamte, . Para mas información acerca de como usar <code class="docutils literal notranslate"><span class="pre">plot_surface</span></code> (ver <a class="reference external" href="https://matplotlib.org/stable/gallery/mplot3d/surface3d.html">3D surface (colormap)</a>). Es tarea del estudiante profundizar en el uso de cada parámetro.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">figure</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">Axes3D</span><span class="p">(</span><span class="n">figure</span><span class="p">,</span> <span class="n">elev</span><span class="o">=-</span><span class="mi">152</span><span class="p">,</span> <span class="n">azim</span><span class="o">=-</span><span class="mi">26</span><span class="p">)</span>

<span class="n">xx</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">X_new</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">min</span><span class="p">()</span> <span class="o">-</span> <span class="mi">2</span><span class="p">,</span> <span class="n">X_new</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">max</span><span class="p">()</span> <span class="o">+</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">50</span><span class="p">)</span>
<span class="n">yy</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">X_new</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">min</span><span class="p">()</span> <span class="o">-</span> <span class="mi">2</span><span class="p">,</span> <span class="n">X_new</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">max</span><span class="p">()</span> <span class="o">+</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">50</span><span class="p">)</span>
<span class="n">XX</span><span class="p">,</span> <span class="n">YY</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">meshgrid</span><span class="p">(</span><span class="n">xx</span><span class="p">,</span> <span class="n">yy</span><span class="p">)</span>
<span class="n">ZZ</span> <span class="o">=</span> <span class="p">(</span><span class="n">coef</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="n">XX</span> <span class="o">+</span> <span class="n">coef</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="n">YY</span> <span class="o">+</span> <span class="n">intercept</span><span class="p">)</span> <span class="o">/</span> <span class="o">-</span><span class="n">coef</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="c1"># Ecuación del plano</span>

<span class="n">ax</span><span class="o">.</span><span class="n">plot_surface</span><span class="p">(</span><span class="n">XX</span><span class="p">,</span> <span class="n">YY</span><span class="p">,</span> <span class="n">ZZ</span><span class="p">,</span> <span class="n">rstride</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">cstride</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X_new</span><span class="p">[</span><span class="n">mask</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X_new</span><span class="p">[</span><span class="n">mask</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">X_new</span><span class="p">[</span><span class="n">mask</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;b&#39;</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">mglearn</span><span class="o">.</span><span class="n">cm2</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">60</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">X_new</span><span class="p">[</span><span class="o">~</span><span class="n">mask</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X_new</span><span class="p">[</span><span class="o">~</span><span class="n">mask</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">X_new</span><span class="p">[</span><span class="o">~</span><span class="n">mask</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;r&#39;</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="s1">&#39;^&#39;</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="n">mglearn</span><span class="o">.</span><span class="n">cm2</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">60</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;feature0&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;feature1&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_zlabel</span><span class="p">(</span><span class="s2">&quot;feature0 ** 2&quot;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/supervised_learning_505_0.png" src="_images/supervised_learning_505_0.png" />
</div>
</div>
<ul class="simple">
<li><p>Como función de las características originales, el modelo <code class="docutils literal notranslate"><span class="pre">SVM</span></code> lineal ya no es lineal. No es una línea, sino más bien una elipse, como se puede ver en el gráfico creado aquí. Para dibujar la función de decisión utilizamos la clase <code class="docutils literal notranslate"><span class="pre">decision_function</span></code> de <code class="docutils literal notranslate"><span class="pre">LinearSVC()</span></code>. La función <code class="docutils literal notranslate"><span class="pre">ravel()</span></code>, devuelve un array 1-D que contiene los elementos de la entrada. Se hace una copia sólo si se necesita. Para conocer más metodos que pueden ser utilizados a partir de la clase <code class="docutils literal notranslate"><span class="pre">SVC</span></code> (ver <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html">sklearn.svm.SVC</a>). Aquí <code class="docutils literal notranslate"><span class="pre">levels</span></code> indica niveles especificos en los que las curvas de nivel serán dibujadas, los valores deben estar en orden creciente. Para mas información acerca de dibujos de contorno (ver <a class="reference external" href="https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.contourf.html">matplotlib.pyplot.contourf</a>).</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">ZZ</span> <span class="o">=</span> <span class="n">YY</span> <span class="o">**</span> <span class="mi">2</span>
<span class="n">dec</span> <span class="o">=</span> <span class="n">linear_svm_3d</span><span class="o">.</span><span class="n">decision_function</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">c_</span><span class="p">[</span><span class="n">XX</span><span class="o">.</span><span class="n">ravel</span><span class="p">(),</span> <span class="n">YY</span><span class="o">.</span><span class="n">ravel</span><span class="p">(),</span> <span class="n">ZZ</span><span class="o">.</span><span class="n">ravel</span><span class="p">()])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">contourf</span><span class="p">(</span><span class="n">XX</span><span class="p">,</span> <span class="n">YY</span><span class="p">,</span> <span class="n">dec</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">XX</span><span class="o">.</span><span class="n">shape</span><span class="p">),</span> <span class="n">levels</span><span class="o">=</span><span class="p">[</span><span class="n">dec</span><span class="o">.</span><span class="n">min</span><span class="p">(),</span> <span class="mi">0</span><span class="p">,</span> <span class="n">dec</span><span class="o">.</span><span class="n">max</span><span class="p">()],</span> <span class="n">cmap</span><span class="o">=</span><span class="n">mglearn</span><span class="o">.</span><span class="n">cm2</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
<span class="n">mglearn</span><span class="o">.</span><span class="n">discrete_scatter</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">y</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Feature 0&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Feature 1&quot;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/supervised_learning_507_0.png" src="_images/supervised_learning_507_0.png" />
</div>
</div>
</section>
<section id="el-kernel-trick">
<h3>El Kernel Trick<a class="headerlink" href="#el-kernel-trick" title="Permalink to this headline">#</a></h3>
<ul class="simple">
<li><p>Durante el entrenamiento, SVM aprende cuan importante son cada uno de los puntos de datos de entrenamiento para representar el límite de decisión entre las dos clases. Recuerde que, sólo un subconjunto de los puntos de entrenamiento es importante para definir la frontera de decisión, los que se encuentran en la frontera entre las clases (<code class="docutils literal notranslate"><span class="pre">vectores</span> <span class="pre">de</span> <span class="pre">soporte</span></code>).</p></li>
<li><p>Para hacer una predicción de un nuevo punto, se mide la distancia a cada uno de los vectores de soporte. Se toma una decisión de clasificación basada en las distancias a los vectores de soporte y en la importancia de los vectores de soporte, aprendida durante el entrenamiento (almacenado en el atributo <code class="docutils literal notranslate"><span class="pre">dual_coef_</span></code> de <code class="docutils literal notranslate"><span class="pre">SVC</span></code>). La distancia entre los puntos de datos se mide, por ejemplo, mediante el kernel Gaussiano:</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
k_{\text{rbf}}=\exp(\gamma\|x_{1}-x_{2}\|^2).
\]</div>
<ul class="simple">
<li><p>Aquí, <span class="math notranslate nohighlight">\(x_{1}\)</span> y <span class="math notranslate nohighlight">\(x_{2}\)</span> son puntos de datos, <span class="math notranslate nohighlight">\(\|x_{1} - x_{2}\|\)</span> denota la distancia euclidiana, y <span class="math notranslate nohighlight">\(\gamma\)</span> es un parámetro que controla el ancho del kernel gaussiano. <code class="docutils literal notranslate"><span class="pre">gamma</span></code> define un factor de escala general para la noción de distancia entre dos puntos de la <code class="docutils literal notranslate"><span class="pre">SVM</span></code>; esto, a su vez, define cómo un vector de apoyo da forma al límite de decisión en su vecindad cercana. La siguiente figura muestra el resultado del entrenamiento de una máquina de vectores de soporte en un conjunto de datos bidimensional de dos clases. <code class="docutils literal notranslate"><span class="pre">El</span> <span class="pre">límite</span> <span class="pre">de</span> <span class="pre">decisión</span> <span class="pre">se</span> <span class="pre">muestra</span> <span class="pre">en</span> <span class="pre">negro,</span> <span class="pre">y</span> <span class="pre">los</span> <span class="pre">vectores</span> <span class="pre">de</span> <span class="pre">soporte</span> <span class="pre">son</span> <span class="pre">puntos</span> <span class="pre">más</span> <span class="pre">grandes</span> <span class="pre">con</span> <span class="pre">el</span> <span class="pre">contorno</span> <span class="pre">ancho</span></code>. El siguiente código crea este gráfico entrenando una <code class="docutils literal notranslate"><span class="pre">SVM</span></code> en el conjunto de datos <code class="docutils literal notranslate"><span class="pre">forge</span></code></p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">imp</span>
<span class="kn">from</span> <span class="nn">sklearn.svm</span> <span class="kn">import</span> <span class="n">SVC</span>
<span class="kn">import</span> <span class="nn">mglearn</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_breast_cancer</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="n">cancer</span> <span class="o">=</span> <span class="n">load_breast_cancer</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">mglearn</span><span class="o">.</span><span class="n">tools</span><span class="o">.</span><span class="n">make_handcrafted_dataset</span><span class="p">()</span>
<span class="n">svm</span> <span class="o">=</span> <span class="n">SVC</span><span class="p">(</span><span class="n">kernel</span><span class="o">=</span><span class="s1">&#39;rbf&#39;</span><span class="p">,</span> <span class="n">C</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">gamma</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Dibujamos los vectores de soporte. Las etiquetas de clase de los vectores soporte vienen dadas por el signo de los coeficientes duales</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">mglearn</span><span class="o">.</span><span class="n">plots</span><span class="o">.</span><span class="n">plot_2d_separator</span><span class="p">(</span><span class="n">svm</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">eps</span><span class="o">=</span><span class="mf">.5</span><span class="p">)</span>
<span class="n">mglearn</span><span class="o">.</span><span class="n">discrete_scatter</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">y</span><span class="p">)</span>
<span class="n">sv</span> <span class="o">=</span> <span class="n">svm</span><span class="o">.</span><span class="n">support_vectors_</span>
<span class="n">sv_labels</span> <span class="o">=</span> <span class="n">svm</span><span class="o">.</span><span class="n">dual_coef_</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span> <span class="o">&gt;</span> <span class="mi">0</span>
<span class="n">mglearn</span><span class="o">.</span><span class="n">discrete_scatter</span><span class="p">(</span><span class="n">sv</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">sv</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">sv_labels</span><span class="p">,</span> <span class="n">s</span><span class="o">=</span><span class="mi">15</span><span class="p">,</span> <span class="n">markeredgewidth</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Feature 0&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Feature 1&quot;</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/supervised_learning_513_0.png" src="_images/supervised_learning_513_0.png" />
</div>
</div>
<ul class="simple">
<li><p>En este caso, la <code class="docutils literal notranslate"><span class="pre">SVM</span></code> produce un límite muy suave y no lineal. Aquí ajustamos dos parámetros: el parámetro <code class="docutils literal notranslate"><span class="pre">C</span></code> y el parámetro <code class="docutils literal notranslate"><span class="pre">gamma</span></code>, que ahora discutiremos en detalle.</p></li>
</ul>
</section>
<section id="ajuste-de-los-parametros-de-svm">
<h3>Ajuste de los parámetros de SVM<a class="headerlink" href="#ajuste-de-los-parametros-de-svm" title="Permalink to this headline">#</a></h3>
<ul class="simple">
<li><p>El parámetro <code class="docutils literal notranslate"><span class="pre">gamma</span></code> es el que se muestra en la fórmula dada en la sección anterior, que <code class="docutils literal notranslate"><span class="pre">controla</span> <span class="pre">la</span> <span class="pre">anchura</span> <span class="pre">del</span> <span class="pre">kernel</span> <span class="pre">Gaussiano</span></code>. Determina la escala de lo que significa que los puntos estén próximos entre sí. El parámetro <code class="docutils literal notranslate"><span class="pre">C</span></code> es un parámetro de regularización, similar al utilizado en los modelos lineales. Limita la importancia de cada punto (o más precisamente, su <code class="docutils literal notranslate"><span class="pre">dual_coef_</span></code>). Veamos qué ocurre cuando variamos estos parámetros:</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">15</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>

<span class="k">for</span> <span class="n">ax</span><span class="p">,</span> <span class="n">C</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">axes</span><span class="p">,</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">]):</span>
    <span class="k">for</span> <span class="n">a</span><span class="p">,</span> <span class="n">gamma</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">ax</span><span class="p">,</span> <span class="nb">range</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">)):</span>
        <span class="n">mglearn</span><span class="o">.</span><span class="n">plots</span><span class="o">.</span><span class="n">plot_svm</span><span class="p">(</span><span class="n">log_C</span><span class="o">=</span><span class="n">C</span><span class="p">,</span> <span class="n">log_gamma</span><span class="o">=</span><span class="n">gamma</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">a</span><span class="p">)</span>
        <span class="n">axes</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">legend</span><span class="p">([</span><span class="s2">&quot;class 0&quot;</span><span class="p">,</span> <span class="s2">&quot;class 1&quot;</span><span class="p">,</span> <span class="s2">&quot;sv class 0&quot;</span><span class="p">,</span> <span class="s2">&quot;sv class 1&quot;</span><span class="p">],</span> <span class="n">ncol</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">loc</span><span class="o">=</span><span class="p">(</span><span class="mf">.9</span><span class="p">,</span> <span class="mf">1.2</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/supervised_learning_517_0.png" src="_images/supervised_learning_517_0.png" />
</div>
</div>
<ul class="simple">
<li><p>De izquierda a derecha, aumentamos el valor del parámetro <code class="docutils literal notranslate"><span class="pre">gamma</span></code> de 0.1 a 10. <code class="docutils literal notranslate"><span class="pre">Un</span> <span class="pre">gamma</span> <span class="pre">pequeño</span> <span class="pre">significa</span> <span class="pre">un</span> <span class="pre">radio</span> <span class="pre">grande</span> <span class="pre">para</span> <span class="pre">el</span> <span class="pre">núcleo</span> <span class="pre">gaussiano,</span> <span class="pre">lo</span> <span class="pre">que</span> <span class="pre">significa</span> <span class="pre">que</span> <span class="pre">muchos</span> <span class="pre">puntos</span> <span class="pre">se</span> <span class="pre">consideran</span> <span class="pre">cercanos</span></code>. Esto se refleja en unos límites de decisión muy suaves a la izquierda, y límites que se centran más en puntos individuales más a la derecha. Un valor bajo de <code class="docutils literal notranslate"><span class="pre">gamma</span></code> significa que el límite de decisión variará lentamente, lo que produce un modelo de baja complejidad, mientras que un valor alto de <code class="docutils literal notranslate"><span class="pre">gamma</span></code> da lugar a un modelo más complejo.</p></li>
<li><p>De arriba a abajo, aumentamos el parámetro <code class="docutils literal notranslate"><span class="pre">C</span></code> de 0.1 a 1000. Al igual que con los modelos lineales, un valor de <code class="docutils literal notranslate"><span class="pre">C</span></code> pequeño <code class="docutils literal notranslate"><span class="pre">corresponde</span> <span class="pre">a</span> <span class="pre">un</span> <span class="pre">modelo</span> <span class="pre">muy</span> <span class="pre">restringido,</span> <span class="pre">en</span> <span class="pre">el</span> <span class="pre">que</span> <span class="pre">cada</span> <span class="pre">punto</span> <span class="pre">de</span> <span class="pre">datos</span> <span class="pre">sólo</span> <span class="pre">puede</span> <span class="pre">tener</span> <span class="pre">una</span> <span class="pre">influencia</span> <span class="pre">muy</span> <span class="pre">limitada</span></code>. Se puede ver que en la parte superior izquierda el límite de decisión parece casi lineal, y los puntos mal clasificados apenas influyen en la línea. <code class="docutils literal notranslate"><span class="pre">Aumentar</span> <span class="pre">C,</span> <span class="pre">como</span> <span class="pre">se</span> <span class="pre">muestra</span> <span class="pre">en</span> <span class="pre">la</span> <span class="pre">parte</span> <span class="pre">inferior</span> <span class="pre">derecha,</span> <span class="pre">permite</span> <span class="pre">que</span> <span class="pre">estos</span> <span class="pre">puntos</span> <span class="pre">tengan</span> <span class="pre">una</span> <span class="pre">influencia</span> <span class="pre">en</span> <span class="pre">el</span> <span class="pre">modelo</span> <span class="pre">y</span> <span class="pre">hace</span> <span class="pre">que</span> <span class="pre">el</span> <span class="pre">límite</span> <span class="pre">de</span> <span class="pre">decisión</span> <span class="pre">se</span> <span class="pre">doble</span> <span class="pre">para</span> <span class="pre">clasificarlos</span> <span class="pre">correctamente</span></code>. Apliquemos <code class="docutils literal notranslate"><span class="pre">SVM</span></code> de núcleo <code class="docutils literal notranslate"><span class="pre">RBF</span></code> al conjunto de datos <code class="docutils literal notranslate"><span class="pre">Breast</span> <span class="pre">Cancer</span></code>. Por defecto, <code class="docutils literal notranslate"><span class="pre">C=1</span></code> y <code class="docutils literal notranslate"><span class="pre">gamma=1/n_features</span></code>:</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">cancer</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">cancer</span><span class="o">.</span><span class="n">target</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">svc</span> <span class="o">=</span> <span class="n">SVC</span><span class="p">()</span>
<span class="n">svc</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Accuracy on training set: </span><span class="si">{:.2f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">svc</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Accuracy on test set: </span><span class="si">{:.2f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">svc</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Accuracy on training set: 0.90
Accuracy on test set: 0.94
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Aunque las <code class="docutils literal notranslate"><span class="pre">SVM</span></code> suelen funcionar bastante bien, <code class="docutils literal notranslate"><span class="pre">son</span> <span class="pre">muy</span> <span class="pre">sensibles</span> <span class="pre">a</span> <span class="pre">los</span> <span class="pre">ajustes</span> <span class="pre">de</span> <span class="pre">los</span> <span class="pre">parámetros</span> <span class="pre">y</span> <span class="pre">al</span> <span class="pre">escalado</span> <span class="pre">de</span> <span class="pre">los</span> <span class="pre">datos</span></code>. En particular, requieren que todas las características varíen en una escala similar. Veamos los valores mínimos y máximos de cada característica, trazados en escala logarítmica</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X_train</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span> <span class="s1">&#39;o&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;min&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X_train</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">),</span> <span class="s1">&#39;^&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;max&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Feature index&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Feature magnitude&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">yscale</span><span class="p">(</span><span class="s2">&quot;log&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/supervised_learning_521_0.png" src="_images/supervised_learning_521_0.png" />
</div>
</div>
<ul class="simple">
<li><p>A partir de este gráfico podemos determinar que <code class="docutils literal notranslate"><span class="pre">las</span> <span class="pre">características</span> <span class="pre">del</span> <span class="pre">conjunto</span> <span class="pre">de</span> <span class="pre">datos</span> <span class="pre">de</span> <span class="pre">cáncer</span> <span class="pre">de</span> <span class="pre">mama</span> <span class="pre">son</span> <span class="pre">de</span> <span class="pre">órdenes</span> <span class="pre">de</span> <span class="pre">magnitud</span> <span class="pre">completamente</span> <span class="pre">diferentes</span></code>. Esto puede ser un problema para otros modelos (como los modelos lineales), pero <code class="docutils literal notranslate"><span class="pre">tiene</span> <span class="pre">efectos</span> <span class="pre">devastadores</span> <span class="pre">para</span> <span class="pre">SVM</span> <span class="pre">con</span> <span class="pre">kernel</span></code>. Examinemos algunas formas de resolver este problema.</p></li>
</ul>
</section>
<section id="preprocesamiento-de-datos-para-svm">
<h3>Preprocesamiento de datos para SVM<a class="headerlink" href="#preprocesamiento-de-datos-para-svm" title="Permalink to this headline">#</a></h3>
<ul class="simple">
<li><p>Una forma de resolver este problema es reescalar cada característica para que todas estén aproximadamente en la misma escala. Un método común de reescalado para <code class="docutils literal notranslate"><span class="pre">SVMs</span></code> con kernel consiste en <code class="docutils literal notranslate"><span class="pre">escalar</span> <span class="pre">los</span> <span class="pre">datos</span> <span class="pre">de</span> <span class="pre">manera</span> <span class="pre">que</span> <span class="pre">todas</span> <span class="pre">las</span> <span class="pre">características</span> <span class="pre">estén</span> <span class="pre">entre</span> <span class="pre">0</span> <span class="pre">y</span> <span class="pre">1</span></code>. Veremos cómo hacer esto usando el método de preprocesamiento <code class="docutils literal notranslate"><span class="pre">MinMaxScaler</span></code>. Por ahora, con el objetivo de comprender su funcionamiento, vamos a implementar el preprocesamiento “a mano”</p></li>
</ul>
<ul class="simple">
<li><p>Calculamos el valor mínimo por característica en el conjunto de entrenamiento. Dado que <code class="docutils literal notranslate"><span class="pre">X_train</span></code> contiene 30 columnas de características, el resultado va a ser un array de dimensión 30. Para obetenerlo usamos <code class="docutils literal notranslate"><span class="pre">min(axis=0)</span></code>, para que el mínimo sea buscado sobre las filas de cada columna.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">min_on_training</span> <span class="o">=</span> <span class="n">X_train</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">min_on_training</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(30,)
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Calculamos el vector de rangos para cada característica <code class="docutils literal notranslate"><span class="pre">(max</span> <span class="pre">-</span> <span class="pre">min)</span></code> en el conjunto de entrenamiento. El máximo sobre cada columna es calculado usando la función <code class="docutils literal notranslate"><span class="pre">max(axis=0)</span></code>.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">range_on_training</span> <span class="o">=</span> <span class="p">(</span><span class="n">X_train</span> <span class="o">-</span> <span class="n">min_on_training</span><span class="p">)</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">range_on_training</span><span class="o">.</span><span class="n">shape</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(30,)
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Restamos con el mínimo, cada una de las características en <code class="docutils literal notranslate"><span class="pre">X_train</span></code> y despues dividimos por el rango, <code class="docutils literal notranslate"><span class="pre">min=0</span></code> y <code class="docutils literal notranslate"><span class="pre">max=1</span></code> para cada característica resultante</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X_train_scaled</span> <span class="o">=</span> <span class="p">(</span><span class="n">X_train</span> <span class="o">-</span> <span class="n">min_on_training</span><span class="p">)</span> <span class="o">/</span> <span class="n">range_on_training</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Minimum for each feature</span><span class="se">\n</span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">X_train_scaled</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Minimum for each feature
[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0.]
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Maximum for each feature</span><span class="se">\n</span><span class="s2"> </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">X_train_scaled</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Maximum for each feature
 [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1.]
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">Utilizamos</span> <span class="pre">la</span> <span class="pre">misma</span> <span class="pre">transformación</span> <span class="pre">en</span> <span class="pre">el</span> <span class="pre">conjunto</span> <span class="pre">de</span> <span class="pre">prueba</span></code>, utilizando el mínimo y el rango del conjunto de entrenamiento</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X_test_scaled</span> <span class="o">=</span> <span class="p">(</span><span class="n">X_test</span> <span class="o">-</span> <span class="n">min_on_training</span><span class="p">)</span> <span class="o">/</span> <span class="n">range_on_training</span>
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Utilizando ahora los datos transformados, entrenamos el modelo <code class="docutils literal notranslate"><span class="pre">SVC()</span></code> y verificamos valores de <code class="docutils literal notranslate"><span class="pre">accuracy</span></code></p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">svc</span> <span class="o">=</span> <span class="n">SVC</span><span class="p">()</span>
<span class="n">svc</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_scaled</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Accuracy on training set: </span><span class="si">{:.3f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">svc</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_train_scaled</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Accuracy on test set: </span><span class="si">{:.3f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">svc</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test_scaled</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Accuracy on training set: 0.984
Accuracy on test set: 0.972
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Escalar los datos supuso una gran diferencia. Ahora estamos en un régimen de overfitting donde el rendimiento del conjunto de entrenamiento es ligeramente mayor que el de prueba, pero menos cercano al 100% de <code class="docutils literal notranslate"><span class="pre">accuracy</span></code>. A partir de aquí, podemos intentar aumentar <code class="docutils literal notranslate"><span class="pre">C</span></code> o <code class="docutils literal notranslate"><span class="pre">gamma</span></code> para ajustar un modelo regularizado. Por ejemplo:</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">svc_C01</span> <span class="o">=</span> <span class="n">SVC</span><span class="p">(</span><span class="n">C</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
<span class="n">svc_C01</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_scaled</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Accuracy on training set: </span><span class="si">{:.3f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">svc_C01</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_train_scaled</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Accuracy on test set: </span><span class="si">{:.3f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">svc_C01</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test_scaled</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Accuracy on training set: 0.948
Accuracy on test set: 0.958
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Nótese que si usamos parámetro de regularización <code class="docutils literal notranslate"><span class="pre">C</span></code> demasiado extremos, podemos caer nuevamente en un mayor overfitting, o en un modelo demasiado simple, que entrega valores de <code class="docutils literal notranslate"><span class="pre">accuracy</span></code> bastantes bajos para los datos de entrenamiento y prueba, esto es, el modelo no será capaza de generalizarse correctamente, underfitting.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">svc_C001</span> <span class="o">=</span> <span class="n">SVC</span><span class="p">(</span><span class="n">C</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>
<span class="n">svc_C001</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_scaled</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Accuracy on training set: </span><span class="si">{:.3f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">svc_C001</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_train_scaled</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Accuracy on test set: </span><span class="si">{:.3f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">svc_C001</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test_scaled</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Accuracy on training set: 0.643
Accuracy on test set: 0.636
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">svc_C100</span> <span class="o">=</span> <span class="n">SVC</span><span class="p">(</span><span class="n">C</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
<span class="n">svc_C100</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_scaled</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Accuracy on training set: </span><span class="si">{:.3f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">svc_C100</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_train_scaled</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Accuracy on test set: </span><span class="si">{:.3f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">svc_C100</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test_scaled</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Accuracy on training set: 1.000
Accuracy on test set: 0.965
</pre></div>
</div>
</div>
</div>
</section>
<section id="id14">
<h3>Puntos fuertes, puntos débiles y parámetros<a class="headerlink" href="#id14" title="Permalink to this headline">#</a></h3>
<ul class="simple">
<li><p>Las máquinas de vectores de soporte kernelizadas son modelos potentes y funcionan bien en una variedad de conjuntos de datos. <code class="docutils literal notranslate"><span class="pre">Las</span> <span class="pre">SVM</span> <span class="pre">permiten</span> <span class="pre">establecer</span> <span class="pre">límites</span> <span class="pre">de</span> <span class="pre">decisión</span> <span class="pre">complejos,</span> <span class="pre">incluso</span> <span class="pre">si</span> <span class="pre">los</span> <span class="pre">datos</span> <span class="pre">sólo</span> <span class="pre">tienen</span>&#160; <span class="pre">unas</span> <span class="pre">pocas</span> <span class="pre">características</span></code>. Funcionan bien con datos de baja y alta dimensión (es decir, pocas y muchas características), pero no escalan muy bien con el número de muestras. Ejecutar SVM con datos de hasta 10.000 muestras puede funcionar bien, pero <code class="docutils literal notranslate"><span class="pre">trabajar</span> <span class="pre">con</span> <span class="pre">conjuntos</span> <span class="pre">de</span> <span class="pre">datos</span> <span class="pre">de</span> <span class="pre">100.000</span> <span class="pre">o</span> <span class="pre">más</span> <span class="pre">puede</span> <span class="pre">ser</span> <span class="pre">un</span> <span class="pre">reto</span> <span class="pre">en</span> <span class="pre">términos</span> <span class="pre">de</span> <span class="pre">tiempo</span> <span class="pre">de</span> <span class="pre">ejecución</span> <span class="pre">y</span> <span class="pre">uso</span> <span class="pre">de</span> <span class="pre">memoria</span></code>.</p></li>
<li><p>Otra desventaja de SVM es que <code class="docutils literal notranslate"><span class="pre">requieren</span> <span class="pre">un</span> <span class="pre">cuidadoso</span> <span class="pre">preprocesamiento</span> <span class="pre">de</span> <span class="pre">los</span> <span class="pre">datos</span> <span class="pre">y</span> <span class="pre">el</span> <span class="pre">ajuste</span> <span class="pre">de</span> <span class="pre">los</span> <span class="pre">parámetros</span></code>. Por eso, hoy en día, algunos investigadores utilizan modelos basados en árboles, como los bosques aleatorios o el gradient boosting (que requieren poco o ningún preprocesamiento) en muchas aplicaciones. Además, los modelos <code class="docutils literal notranslate"><span class="pre">SVM</span></code> son difíciles de inspeccionar, <code class="docutils literal notranslate"><span class="pre">puede</span> <span class="pre">ser</span> <span class="pre">difícil</span> <span class="pre">entender</span> <span class="pre">por</span> <span class="pre">qué</span> <span class="pre">se</span> <span class="pre">ha</span> <span class="pre">hecho</span> <span class="pre">una</span> <span class="pre">predicción</span> <span class="pre">concreta,</span> <span class="pre">y</span> <span class="pre">puede</span> <span class="pre">ser</span> <span class="pre">difícil</span> <span class="pre">explicar</span> <span class="pre">el</span> <span class="pre">modelo</span> <span class="pre">a</span> <span class="pre">un</span> <span class="pre">inexperto</span></code>. Aun así, puede valer la pena probar las <code class="docutils literal notranslate"><span class="pre">SVM</span></code>, sobre todo si todas las características representan medidas en unidades similares (por ejemplo, todas son intensidades de píxeles) y están en escalas similares.</p></li>
<li><p>Los parámetros importantes en las SVM con kernel son el parámetro de regularización <code class="docutils literal notranslate"><span class="pre">C</span></code>, la elección del kernel, y los parámetros específicos del kernel. Aunque principalmente nos centramos en el núcleo <code class="docutils literal notranslate"><span class="pre">RBF</span></code>, hay otras opciones disponibles en <code class="docutils literal notranslate"><span class="pre">scikit-learn</span></code>. El núcleo <code class="docutils literal notranslate"><span class="pre">RBF</span></code> tiene sólo un parámetro,<code class="docutils literal notranslate"> <span class="pre">gamma</span></code>, que es la inversa de la anchura del kernel de Gaus. <code class="docutils literal notranslate"><span class="pre">gamma</span></code> y <code class="docutils literal notranslate"><span class="pre">C</span></code> controlan la complejidad del modelo, <code class="docutils literal notranslate"><span class="pre">con</span> <span class="pre">valores</span> <span class="pre">grandes</span> <span class="pre">en</span> <span class="pre">cualquiera</span> <span class="pre">de</span> <span class="pre">ellos</span> <span class="pre">obtenemos</span> <span class="pre">un</span> <span class="pre">modelo</span> <span class="pre">más</span> <span class="pre">complejo</span></code>. Por lo tanto, los buenos ajustes para los dos parámetros suelen estar fuertemente correlacionados, y <code class="docutils literal notranslate"><span class="pre">C</span></code> y <code class="docutils literal notranslate"><span class="pre">gamma</span></code> deben ajustarse juntos.</p></li>
</ul>
</section>
</section>
<section id="redes-neuronales-y-deep-learning">
<h2>Redes Neuronales y Deep Learning<a class="headerlink" href="#redes-neuronales-y-deep-learning" title="Permalink to this headline">#</a></h2>
<section id="gradiente-descendiente">
<h3>Gradiente descendiente<a class="headerlink" href="#gradiente-descendiente" title="Permalink to this headline">#</a></h3>
<ul>
<li><p>El <code class="docutils literal notranslate"><span class="pre">método</span> <span class="pre">de</span> <span class="pre">gradiente</span> <span class="pre">descendiente</span></code> es uno de los mas ampliamente usados para la minimización iterativa de una función de costo diferenciable, <span class="math notranslate nohighlight">\(J(\boldsymbol{\theta}),~\boldsymbol{\theta}\in\mathbb{R}^{l}\)</span>. Como cualquier otra técnica iterativa, el método parte de una estimación inicial, <span class="math notranslate nohighlight">\(\boldsymbol{\theta}^{(0)}\)</span>, y genera una sucesión <span class="math notranslate nohighlight">\(\boldsymbol{\theta}^{(i)},\quad i=1,2,\dots,\)</span> tal que:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
    \\[1mm]
    \boldsymbol{\theta}^{(i)}=\boldsymbol{\theta}^{(i-1)}+\mu_{i}\Delta\boldsymbol{\theta}^{(i)},~ i &gt;0,~\mu_{i}&gt;0.
    \end{split}\]</div>
</li>
<li><p>La diferencia entre cada método radica en la forma que <span class="math notranslate nohighlight">\(\mu_{i}\)</span> y <span class="math notranslate nohighlight">\(\Delta\boldsymbol{\theta}^{(i)}\)</span> son seleccionados. <span class="math notranslate nohighlight">\(\Delta\boldsymbol{\theta}^{(i)}\)</span> es conocido como la <code class="docutils literal notranslate"><span class="pre">dirección</span> <span class="pre">de</span> <span class="pre">actualización</span></code> o de busqueda. La sucesión <span class="math notranslate nohighlight">\(\mu_{i}\)</span> es conocida como el tamaño o <code class="docutils literal notranslate"><span class="pre">longitud</span> <span class="pre">de</span> <span class="pre">paso</span></code> en la <span class="math notranslate nohighlight">\(i\)</span>-ésima iteación, estos valores pueden ser constantes o cambiar en cada iteración. En el método de gradiente descendiente, la selección de <span class="math notranslate nohighlight">\(\Delta\boldsymbol{\theta}^{(i)}\)</span> es realizada para garantizar que <span class="math notranslate nohighlight">\(J(\boldsymbol{\theta}^{(i)})&lt;J(\boldsymbol{\theta}^{(i-1)})\)</span>, excepto en el minimizador <span class="math notranslate nohighlight">\(\boldsymbol{\theta}_{\star}\)</span>.</p></li>
</ul>
<figure class="align-center" id="curva-nivel">
<a class="reference internal image-reference" href="_images/curva_nivel.png"><img alt="_images/curva_nivel.png" src="_images/curva_nivel.png" style="width: 504.8px; height: 386.40000000000003px;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 13 </span><span class="caption-text">Función de coste en el espacio de parámetros bidimensional.</span><a class="headerlink" href="#curva-nivel" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<ul class="simple">
<li><p>Suponga que en la iteración <span class="math notranslate nohighlight">\(i-1\)</span> el valor <span class="math notranslate nohighlight">\(\boldsymbol{\theta}^{(i-1)}\)</span> ha sido obtenido</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
J(\boldsymbol{\theta}^{(i)})=J(\boldsymbol{\theta}^{(i-1)}+\mu_{i}\Delta\boldsymbol{\theta}^{(i)})\approx J(\boldsymbol{\theta}^{(i-1)})+\mu_{i}\cdot\nabla^{T}J(\boldsymbol{\theta}^{(i-1)})\Delta\boldsymbol{\theta}^{(i-1)}.
\]</div>
<ul class="simple">
<li><p>Nótese que seleccionando la dirección tal que: <span class="math notranslate nohighlight">\(\nabla^{T}J(\boldsymbol{\theta}^{(i-1)})\Delta\boldsymbol{\theta}^{(i)}&lt;0\)</span>, garantizará que <span class="math notranslate nohighlight">\(J(\boldsymbol{\theta}^{(i-1)}+\mu_{i}\Delta\boldsymbol{\theta}^{(i)})&lt;J(\boldsymbol{\theta}^{(i-1)})\)</span>. Tal selección de <span class="math notranslate nohighlight">\(\Delta\boldsymbol{\theta}^{(i)}\)</span> y <span class="math notranslate nohighlight">\(\nabla J(\boldsymbol{\theta}^{(i-1)})\)</span> debe formar un ángulo obtuso. Las curvas de nivel asociadas a <span class="math notranslate nohighlight">\(J(\boldsymbol{\theta})\)</span> pueden tomar cualquier forma, la cual va a depender de como está definido <span class="math notranslate nohighlight">\(J(\boldsymbol{\theta})\)</span>.</p></li>
<li><p><span class="math notranslate nohighlight">\(J(\boldsymbol{\theta})\)</span> se supone diferenciable, por lo tanto, las curvas de nivel o contornos deben ser suaves y aceptar un plano tangente en cualquier punto. Además, de los cursos de Cálculo sabemos que el vector gradiente <span class="math notranslate nohighlight">\(\nabla J(\boldsymbol{\theta})\)</span> es perpendicular al plano tangente (recta tangente) a la correspondiente curva de nivel en el punto <span class="math notranslate nohighlight">\(\boldsymbol{\theta}\)</span>. Nótese que seleccionando la dirección de busqueda <span class="math notranslate nohighlight">\(\Delta\boldsymbol{\theta}^{(i)}\)</span> que forma un angulo obtuso con el gradiente, se coloca a <span class="math notranslate nohighlight">\(\boldsymbol{\theta}^{(i-1)}+\mu_{i}\Delta\boldsymbol{\theta}^{(i)}\)</span> en un punto sobre el contorno el cual corresponde a un valor menor que <span class="math notranslate nohighlight">\(J(\boldsymbol{\theta})\)</span>.</p></li>
</ul>
<figure class="align-center" id="curva-nivel-cost-function">
<a class="reference internal image-reference" href="_images/curva_nivel_cost_function.png"><img alt="_images/curva_nivel_cost_function.png" src="_images/curva_nivel_cost_function.png" style="width: 484.2px; height: 359.1px;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 14 </span><span class="caption-text">Las correspondientes curvas de nivel para la función de coste, en el plano bidimensional. Nótese que a medida que nos alejamos del valor óptimo, <span class="math notranslate nohighlight">\(\boldsymbol{\theta}_{\star}\)</span>, los valores de <span class="math notranslate nohighlight">\(c\)</span> aumentan.</span><a class="headerlink" href="#curva-nivel-cost-function" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<ul class="simple">
<li><p>Dos problemas surgen ahora:</p>
<ol class="simple">
<li><p>Escoger la mejor dirección de busqueda</p></li>
<li><p>Calcular que tan lejos es aceptable un movimiento a traves de esta dirección</p></li>
</ol>
</li>
<li><p>Nótese que si <span class="math notranslate nohighlight">\(\mu_{i}\|\Delta\boldsymbol{\theta}^{(i)}\|\)</span> es demasiado grande, entonces el nuevo punto puede ser colocado en un contorno correspondiente a un valor mayor al del actual contorno.</p></li>
</ul>
<ul class="simple">
<li><p>Para abordar (1), supongamos que <span class="math notranslate nohighlight">\(\mu_{i}=1\)</span> y buscamos todos los vectores <span class="math notranslate nohighlight">\(\boldsymbol{z}\)</span> con norma Euclidiana unitaria, con inicio (cola) en <span class="math notranslate nohighlight">\(\boldsymbol{\theta}^{(i-1)}\)</span>. Entonces, para todas las posibles direcciones, la que entrega el valor más negativo del producto interno, <span class="math notranslate nohighlight">\(\nabla^{T}J(\boldsymbol{\theta}^{(i-1)})z\)</span>, es aquella de gradiente negativo</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
z=-\frac{\nabla J(\boldsymbol{\theta}^{(i-1)})}{\|\nabla J(\boldsymbol{\theta}^{(i-1)}\|}
\]</div>
<ul class="simple">
<li><p>Centrando <span class="math notranslate nohighlight">\(\boldsymbol{\theta}^{(i-1)}\)</span> en la bola con norma Euclideana uno. De todos los vectores con norma unitaria y origen en <span class="math notranslate nohighlight">\(\boldsymbol{\theta}^{(i-1)}\)</span>, seleccionamos aquel que apunta en la dirección negativa del gradiente. Por lo tanto, para todos los vectores con norma Euclidiana 1, la <code class="docutils literal notranslate"><span class="pre">dirección</span> <span class="pre">de</span> <span class="pre">descenso</span></code> mas pronunciada coincide con la dirección del gradiente descendiente, negativo, y la correspondiente actualización recursiva se convierte en</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
\boldsymbol{\theta}^{(i)}=\boldsymbol{\theta}^{(i-1)}-\mu_{i}\nabla J(\boldsymbol{\theta}^{(i-1)}),\quad\text{Gradiente descendiente}.
\]</div>
<figure class="align-center" id="maximun-dec-cost-function">
<a class="reference internal image-reference" href="_images/maximun_dec_cost_function.png"><img alt="_images/maximun_dec_cost_function.png" src="_images/maximun_dec_cost_function.png" style="width: 495.20000000000005px; height: 365.6px;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 15 </span><span class="caption-text">El vector gradiente en un punto <span class="math notranslate nohighlight">\(\boldsymbol{\theta}\)</span> es perpendicular al plano tangente (línea punteada) en la curva de nivel que cruza <span class="math notranslate nohighlight">\(\boldsymbol{\theta}\)</span>. La dirección de descenso forma un ángulo obtuso, <span class="math notranslate nohighlight">\(\phi\)</span>, con el vector gradiente.</span><a class="headerlink" href="#maximun-dec-cost-function" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<ul class="simple">
<li><p>La selección de <span class="math notranslate nohighlight">\(\mu_{i}\)</span> debe ser realizada de tal forma que garantice convergencia de la secuencia de minimización. Nótese que el algoritmo puede oscilar en torno al mínimo sin converger, si no seleccionamos la dirección correcta. La selección de <span class="math notranslate nohighlight">\(\mu_{i}\)</span> dependerá de la convergencia a cero del error entre <span class="math notranslate nohighlight">\(\boldsymbol{\theta}^{(i)}\)</span> y el mínimo real en forma de serie geométrica. Por ejemplo, para el caso de la función de coste del error cuadrático medio, la longitud de paso está dada por: <span class="math notranslate nohighlight">\(0&lt;\mu&lt;2/\lambda_{\max}\)</span>, donde <span class="math notranslate nohighlight">\(\lambda_{\max}\)</span> el máximo eigenvalor de la matriz de covarianza <span class="math notranslate nohighlight">\(\mathbb{E}[\boldsymbol{x}\boldsymbol{x}^{T}]\)</span> (ver <span id="id15">[<a class="reference internal" href="#id35" title="S. Theodoridis. Machine Learning: A Bayesian and Optimization Perspective. Elsevier Science, 2020. ISBN 9780128188040. URL: https://books.google.com.co/books?id=l-nEDwAAQBAJ.">Theodoridis, 2020</a>]</span>).</p></li>
</ul>
<figure class="align-center" id="fig-desc-gradient">
<a class="reference internal image-reference" href="_images/desc_gradient.png"><img alt="_images/desc_gradient.png" src="_images/desc_gradient.png" style="width: 480.6px; height: 352.8px;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 16 </span><span class="caption-text">Representación del gradiente negativo el cual conduce a la máxima disminución de la función de coste.</span><a class="headerlink" href="#fig-desc-gradient" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<div class="proof definition admonition" id="def_convex_subset">
<p class="admonition-title"><span class="caption-number">Definition 5 </span></p>
<section class="definition-content" id="proof-content">
<p>Un subconjunto no vacio <span class="math notranslate nohighlight">\(C\)</span> de un espacio de Hilbert <span class="math notranslate nohighlight">\(H\)</span>, esto es <span class="math notranslate nohighlight">\(C\subseteq H\)</span>, es llamado <code class="docutils literal notranslate"><span class="pre">convexo</span></code>, si <span class="math notranslate nohighlight">\(\forall~\boldsymbol{x}_{1}, \boldsymbol{x}_{2}\in C\)</span> y <span class="math notranslate nohighlight">\(\forall\lambda\in [0,1]\)</span> se tiene que</p>
<div class="math notranslate nohighlight" id="equation-eq-convex-line">
<span class="eqno">(33)<a class="headerlink" href="#equation-eq-convex-line" title="Permalink to this equation">#</a></span>\[
\boldsymbol{x}:=\lambda\boldsymbol{x}_{1}+(1-\lambda)\boldsymbol{x}_{2}\in C
\]</div>
</section>
</div><ul class="simple">
<li><p>Nótese que si <span class="math notranslate nohighlight">\(\lambda=1\)</span> entonces <span class="math notranslate nohighlight">\(\boldsymbol{x}=\boldsymbol{x}_{1}\)</span>, y si <span class="math notranslate nohighlight">\(\lambda=0\)</span> entonces <span class="math notranslate nohighlight">\(\boldsymbol{x}=\boldsymbol{x}_{2}\)</span>. para cualquier otro <span class="math notranslate nohighlight">\(\lambda\in[0, 1]\)</span> se tiene que <span class="math notranslate nohighlight">\(\boldsymbol{x}\)</span> cae dentro de la línea que conecta <span class="math notranslate nohighlight">\(\boldsymbol{x}_{1}\)</span> con <span class="math notranslate nohighlight">\(\boldsymbol{x}_{2}\)</span>. La ecuación <a class="reference internal" href="#equation-eq-convex-line">(33)</a> puede escribirse como</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
\boldsymbol{x}-\boldsymbol{x}_{2}=\lambda(\boldsymbol{x}_{1}-\boldsymbol{x}_{2}),\quad 0\leq\lambda\leq1.
\]</div>
<ul class="simple">
<li><p>Por ejemplo, la función <span class="math notranslate nohighlight">\(f:\mathbb{R}\longrightarrow\mathbb{R}\)</span> definida por <span class="math notranslate nohighlight">\(f(x)=|x|\)</span> es una función convexa. Observe que <span class="math notranslate nohighlight">\(\forall x_{1}, x_{2}\in\mathbb{R}\)</span> se tiene que</p></li>
</ul>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align*}
f(\lambda x_{1}+(1-\lambda)x_{2})&amp;=|\lambda x_{1}+(1-\lambda)x_{2}|\\[2mm]
&amp;\leq|\lambda x_{1}|+|(1-\lambda)x_{2}|\\[2mm]
&amp;=\lambda|x_{1}|+|1-\lambda||x_{2}|\\[2mm]
&amp;=\lambda f(x_{1})+(1-\lambda)f(x_{2}).
\end{align*}
\end{split}\]</div>
<div class="proof definition admonition" id="def_convex_function">
<p class="admonition-title"><span class="caption-number">Definition 6 </span></p>
<section class="definition-content" id="proof-content">
<p>Una función <span class="math notranslate nohighlight">\(f:\mathcal{X}\subset\mathbb{R}^{l}\longrightarrow\mathbb{R}^{l}\)</span> es llamada convexa si <span class="math notranslate nohighlight">\(\mathcal{X}\)</span> es convexo y si <span class="math notranslate nohighlight">\(\forall~\boldsymbol{x}_{1}, \boldsymbol{x}_{2}\in\mathcal{X}\)</span> se tiene que:</p>
<div class="math notranslate nohighlight">
\[
f(\lambda\boldsymbol{x}_{1}+(1-\lambda)\boldsymbol{x}_{2})\leq\lambda f(\boldsymbol{x}_{1})+(1-\lambda)f(\boldsymbol{x}_{2}),\quad\lambda\in [0, 1].
\]</div>
</section>
</div><ul class="simple">
<li><p>Si la desigualdad se mantiene estrica decimos que <span class="math notranslate nohighlight">\(f\)</span> es estrictamente convexa. Además, en este caso el gráfico de la línea queda por encima de <span class="math notranslate nohighlight">\(f(\boldsymbol{x})\)</span></p></li>
</ul>
<div class="proof theorem admonition" id="th_afin_convex">
<p class="admonition-title"><span class="caption-number">Theorem 3 </span></p>
<section class="theorem-content" id="proof-content">
<p>Sea <span class="math notranslate nohighlight">\(\mathcal{X}\subset\mathbb{R}^{l}\)</span> convexo y <span class="math notranslate nohighlight">\(f:\mathcal{X}\longrightarrow\mathbb{R}\)</span> diferenciable. Entonces <span class="math notranslate nohighlight">\(f(\cdot)\)</span> es convexa si y solo si, <span class="math notranslate nohighlight">\(\forall~\boldsymbol{x}, \boldsymbol{y}\in\mathcal{X}\)</span>,</p>
<div class="math notranslate nohighlight">
\[
f(\boldsymbol{y})\geq f(\boldsymbol{x})+\nabla^{T}f(\boldsymbol{x})(\boldsymbol{y}-\boldsymbol{x}).
\]</div>
</section>
</div><ul>
<li><p>Esto es el grafico de la función convexa está ubicado por encima del gráfico de la función afín</p>
<div class="math notranslate nohighlight">
\[\begin{split}
    \\[1mm]
    g:y\longrightarrow\nabla^{T}f(\boldsymbol{x})(\boldsymbol{y}-\boldsymbol{x})+f(\boldsymbol{x}),
    \end{split}\]</div>
<p>la cual define el hiperplano tangente a la gráfica de <span class="math notranslate nohighlight">\(f\)</span> en <span class="math notranslate nohighlight">\((\boldsymbol{x}, f(\boldsymbol{x}))\)</span>.</p>
</li>
</ul>
<div class="proof theorem admonition" id="th_strict_convex">
<p class="admonition-title"><span class="caption-number">Theorem 4 </span></p>
<section class="theorem-content" id="proof-content">
<p>Sea <span class="math notranslate nohighlight">\(\mathcal{X}\subset\mathbb{R}^{l}\)</span> convexo. Entonces una función doblemente diferenciable <span class="math notranslate nohighlight">\(f:\mathcal{X}\longrightarrow\mathbb{R}\)</span>, es convexa (estrictamente convexa) si y solo si la matriz Hessian es semi definida positiva (definida positiva).</p>
</section>
</div><ul>
<li><p>Por ejemplo considere la función cuadratica</p>
<div class="math notranslate nohighlight">
\[\begin{split}
    \\[1mm]
    f(\boldsymbol{x}):=\frac{1}{2}\boldsymbol{x}^{T}Q\boldsymbol{x}+\boldsymbol{b}^{T}\boldsymbol{x}+c,
    \end{split}\]</div>
<p>donde <span class="math notranslate nohighlight">\(Q\)</span> es una matriz definida positiva. Nótese que el gradiente está dado por</p>
<div class="math notranslate nohighlight">
\[\begin{split}
    \\[1mm]
    \nabla f(\boldsymbol{x})=Q\boldsymbol{x}+\boldsymbol{b},
    \end{split}\]</div>
<p>y la matriz Hessiana es igual a <span class="math notranslate nohighlight">\(Q\)</span>, la que por hipótesis es definida positiva, por lo tanto <span class="math notranslate nohighlight">\(f\)</span> es una función estrictamente convexa.</p>
</li>
</ul>
<figure class="align-center" id="def-convex-function">
<a class="reference internal image-reference" href="_images/convex_function.png"><img alt="_images/convex_function.png" src="_images/convex_function.png" style="width: 518.6999999999999px; height: 278.59999999999997px;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 17 </span><span class="caption-text">Gráfica de una función convexa.</span><a class="headerlink" href="#def-convex-function" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
</section>
<section id="redes-neuronales">
<h3>Redes neuronales<a class="headerlink" href="#redes-neuronales" title="Permalink to this headline">#</a></h3>
<ul class="simple">
<li><p>Las <code class="docutils literal notranslate"><span class="pre">redes</span> <span class="pre">neuronales</span></code> son máquinas de aprendizaje, compuestas por un gran número de neuronas, que se conectan en capas. El aprendizaje se consigue ajustando los pesos sinápticos para minimizar una función de coste preseleccionada. Tras el trabajo pionero de <code class="docutils literal notranslate"><span class="pre">Rosenblatt</span></code>, las redes neuronales tardaron casi 25 años en generalizarse. Este es el periodo de tiempo necesario para que el modelo básico de neurona dado por <code class="docutils literal notranslate"><span class="pre">McCulloch-Pitts</span></code> se generalizara y diera lugar a un algoritmo para el entrenamiento de dichas redes. El algoritmo <code class="docutils literal notranslate"><span class="pre">backpropagation</span></code>, que se desarrolló para entrenar redes neuronales basadas en un conjunto de muestras de entrenamiento <code class="docutils literal notranslate"><span class="pre">input-output</span></code>.</p></li>
</ul>
<ul class="simple">
<li><p>Es interesante observar que las <code class="docutils literal notranslate"><span class="pre">redes</span> <span class="pre">neuronales</span></code> dominaron el campo del <code class="docutils literal notranslate"><span class="pre">aprendizaje</span> <span class="pre">automático</span></code> durante casi una
década, desde 1986 hasta mediados de la década de 1990. Luego, fueron desbancadas, en gran medida, por las <code class="docutils literal notranslate"><span class="pre">máquinas</span> <span class="pre">de</span> <span class="pre">vectores</span> <span class="pre">soporte</span></code>, que establecieron su reinado hasta 2010 aproximadamente. Después, las <code class="docutils literal notranslate"><span class="pre">redes</span> <span class="pre">neuronales</span> <span class="pre">con</span> <span class="pre">muchas</span> <span class="pre">capas</span></code>, conocidas como <code class="docutils literal notranslate"><span class="pre">redes</span> <span class="pre">profundas</span></code>, se han hecho con el “reino” del aprendizaje automático. Los primeros trabajos, asociados a lo que se conoce como <code class="docutils literal notranslate"><span class="pre">redes</span> <span class="pre">convolucionales</span></code> y <code class="docutils literal notranslate"><span class="pre">redes</span> <span class="pre">neuronales</span> <span class="pre">recurrentes</span></code> han inspirado el campo que ahora florece. Sin embargo, este resurgimiento no habría sido posible sin la disponibilidad de potencia de cálculo, gracias a los avances en las arquitecturas informáticas, así como a la acumulación de grandes datos.</p></li>
</ul>
</section>
<section id="el-perceptron">
<h3>El perceptrón<a class="headerlink" href="#el-perceptron" title="Permalink to this headline">#</a></h3>
<ul>
<li><p>Nuestro punto de partida será considerar el problema simple de una tarea de clasifición conformada por dos clases <code class="docutils literal notranslate"><span class="pre">linealmente</span> <span class="pre">separables</span></code>. En otras palabras, dado un conjunto de muestras de entrenamiento, <span class="math notranslate nohighlight">\((y_{n}, \boldsymbol{x}_{n})\)</span>, <span class="math notranslate nohighlight">\(n=1,2,\dots,N\)</span>, con <span class="math notranslate nohighlight">\(y_{n}\in\{-1,+1\},~\boldsymbol{x}_{n}\in\mathbb{R}^{l}\)</span>, suponemos que existe un hiperplano</p>
<div class="math notranslate nohighlight">
\[\begin{split}
    \\[2mm]
    \boldsymbol{\theta}_{\star}^{T}\boldsymbol{x}=0,
    \end{split}\]</div>
<p>tal que,</p>
<div class="math notranslate nohighlight">
\[\begin{split}
    \begin{cases}
    \boldsymbol{\theta}_{\star}^{T}\boldsymbol{x}&amp;&gt;0,\quad\text{si}\quad\boldsymbol{x}\in\omega_{1}\\
    \boldsymbol{\theta}_{\star}^{T}\boldsymbol{x}&amp;&lt;0,\quad\text{si}\quad\boldsymbol{x}\in\omega_{2}
    \end{cases}
    \end{split}\]</div>
<p>En otras palabras, dicho hiperplano clasifica correctamente todos los puntos del conjunto de entrenamiento. Para simplificar, el término de sesgo del hiperplano ha sido absorbido en <span class="math notranslate nohighlight">\(\boldsymbol{\theta}_{\star}\)</span> después de extender la dimensionalidad del espacio de entrada en uno. El objetivo ahora es desarrollar un algoritmo que calcule iterativamente un hiperplano que clasifique correctamente todos los patrones de ambas clases. Para ello, se adopta una función de costo.</p>
</li>
</ul>
<p><strong><code class="docutils literal notranslate"><span class="pre">Costo</span> <span class="pre">perceptrón</span></code></strong>: Sea <span class="math notranslate nohighlight">\(\boldsymbol{\theta}\)</span> la estimación del vector de parámetros desconocidos, disponible en la actual iteración. Entonces hay dos posibilidades. La primera es que todos los puntos estén clasificados correctamente; esto significa que se ha obtenido una solución. La otra alternativa es que <span class="math notranslate nohighlight">\(\boldsymbol{\theta}\)</span> clasifique correctamente algunos de los puntos y el resto estén mal clasificados.</p>
<div class="tip admonition">
<p class="admonition-title">Costo perceptrón</p>
<p>Sea <span class="math notranslate nohighlight">\(\mathcal{Y}\)</span> el conjunto de todas las muestras mal clasificadas. La función de costo, <code class="docutils literal notranslate"><span class="pre">perceptrón</span></code> se define como</p>
<div class="math notranslate nohighlight">
\[
J(\boldsymbol{\theta})=-\sum_{n:\boldsymbol{x}_{n}\in\mathcal{Y}}y_{n}\boldsymbol{\theta}^{T}\boldsymbol{x}_{n}:\quad\textit{Costo perceptrón},
\]</div>
<p>donde</p>
<div class="math notranslate nohighlight">
\[\begin{split}
y_{n}=
\begin{cases}
+1,&amp;\quad\text{si}~\boldsymbol{x}\in\omega_{1}\\
-1,&amp;\quad\text{si}~\boldsymbol{x}\in\omega_{2}.
\end{cases}
\end{split}\]</div>
</div>
<ul class="simple">
<li><p>Nótese que la función la función de costo es no negativa. En efecto, dado que la suma es sobre los puntos mal clasificados, si <span class="math notranslate nohighlight">\(\boldsymbol{x}_{n}\in\omega_{1}~(\omega_{2}),~\)</span> entonces <span class="math notranslate nohighlight">\(\boldsymbol{\theta}^{T}\boldsymbol{x}_{n}\leq (\geq)~0\)</span>, entregando así un producto <span class="math notranslate nohighlight">\(-y_{n}\boldsymbol{\theta}^{T}\boldsymbol{x}_{n}\geq0\)</span>.</p></li>
<li><p>La función de costo es cero, si no existen puntos mal clasificados, esto es, <span class="math notranslate nohighlight">\(\mathcal{Y}=\emptyset\)</span>. La función de costo perceptrón no es diferenciable en todos los puntos, es lineal por tramos. Si reescribimos <span class="math notranslate nohighlight">\(J(\boldsymbol{\theta})\)</span> en una forma ligeramente diferente:</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
J(\boldsymbol{\theta})=\left(-\sum_{n:\boldsymbol{x}_{n}\in\mathcal{Y}}y_{n}\boldsymbol{x}_{n}^{T}\right)\boldsymbol{\theta}.
\]</div>
<ul class="simple">
<li><p>Nótese que esta es una función lineal con respeto a <span class="math notranslate nohighlight">\(\boldsymbol{\theta}\)</span>, siempre que el conjunto de puntos mal clasificados permaneza igual. Además, nótese que ligeros cambios del valor <span class="math notranslate nohighlight">\(\boldsymbol{\theta}\)</span> corresponden a cambios de posición del respectivo hiperplano. Como consecuencia, existirá un punto donde el número de muestras mal clasificadas en <span class="math notranslate nohighlight">\(\mathcal{Y}\)</span>, repentinamente cambia; este es el tiempo donde una muestra en el conjunto de entrenamiento cambia su posición relativa con respecto a el hiperplano en movimiento, y en consecuencia, el conjunto <span class="math notranslate nohighlight">\(\mathcal{Y}\)</span> es modificado. Despues de este cambio, el conjunto, <span class="math notranslate nohighlight">\(J(\boldsymbol{\theta})\)</span>, corresponderá a una nueva  función lineal.</p></li>
</ul>
<div class="tip admonition">
<p class="admonition-title">El algoritmo perceptrón</p>
<p>A partir del <code class="docutils literal notranslate"><span class="pre">método</span> <span class="pre">de</span> <span class="pre">subgradientes</span></code> se puede verificar facilmente que, iniciando desde un punto arbitrario, <span class="math notranslate nohighlight">\(\boldsymbol{\theta}^{(0)}\)</span>, el siguiente método iterativo,</p>
<div class="math notranslate nohighlight">
\[
\boldsymbol{\theta}^{(i)}=\boldsymbol{\theta}^{(i-1)}+\mu_{i}\sum_{n:\boldsymbol{x}_{n}\in\mathcal{Y}}y_{n}\boldsymbol{x}_{n}:\quad\textit{Regla perceptrón}, 
\]</div>
<p>converge despues de un <em>número finito de pasos</em>. La suseción de parámetros <span class="math notranslate nohighlight">\(\mu_{i}\)</span> es seleccionada adecuadamente para garantizar convergencia.</p>
</div>
<ul class="simple">
<li><p>Nótese que usando el método de subgradiente se tiene que</p></li>
</ul>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align*}
\boldsymbol{\theta}^{(i)}&amp;=\boldsymbol{\theta}^{(i-1)}-\mu_{i}J'(\boldsymbol{\theta}^{(i-1)})\\
&amp;=\boldsymbol{\theta}^{(i-1)}-\mu_{i}\left(-\sum_{n:\boldsymbol{x}_{n}\in\mathcal{Y}}y_{n}\boldsymbol{x}_{n}^{T}\right)\\
&amp;=\boldsymbol{\theta}^{(i-1)}+\mu_{i}\sum_{n:\boldsymbol{x}_{n}\in\mathcal{Y}}y_{n}\boldsymbol{x}_{n}.
\end{align*}
\end{split}\]</div>
<ul class="simple">
<li><p>Otra versión del algoritmo considera una muestra por iteración en un esquema cíclico, hasta que el algoritmo converge. Denotemos por <span class="math notranslate nohighlight">\(y_{(i)}\)</span>, <span class="math notranslate nohighlight">\(\boldsymbol{x}_{i},~i\in\{1,2,\dots,N\}\)</span> los pares de entrenamiento presentados al algoritmo en la iteración <span class="math notranslate nohighlight">\(i\)</span>-ésima. Entonces, la iteración de actualización se convierte en:</p></li>
</ul>
<div class="math notranslate nohighlight" id="equation-eq-perceptron-algo2">
<span class="eqno">(34)<a class="headerlink" href="#equation-eq-perceptron-algo2" title="Permalink to this equation">#</a></span>\[\begin{split}
\boldsymbol{\theta}^{(i)}=
\begin{cases}
\boldsymbol{\theta}^{(i-1)}+\mu_{i}y_{(i)}\boldsymbol{x}_{(i)},&amp;\quad\text{si}\,\boldsymbol{x}_{(i)}\,\text{es mal clasificado por}\,\boldsymbol{\theta}^{(i-1)},\\
\boldsymbol{\theta}^{(i-1)},&amp;\quad\text{otro caso}.
\end{cases}
\end{split}\]</div>
<ul class="simple">
<li><p>Esto es, partiendo de una estimación inicial de forma random, inicializando <span class="math notranslate nohighlight">\(\boldsymbol{\theta}^{(0)}\)</span> con algunos valores pequeños, testeamos cada una de las muestras, <span class="math notranslate nohighlight">\(\boldsymbol{x}_{n},~n=1,2,\dots,N\)</span>. Cada vez que una muestra es mal clasificada, se toma acción por medio de la <code class="docutils literal notranslate"><span class="pre">regla</span> <span class="pre">perceptrón</span></code> para una corrección. En otro caso, ninguna acción es requerida. Una vez que todas las muestras han sido consideradas, decimos que una epoca <code class="docutils literal notranslate"><span class="pre">epoch</span></code> ha sido completada. Si no se obtiene convergencia, todas las muestras son reconsideradas en una segunda epoca, y así sucesivamente. La versión de este algoritmo es conocida como esquema <code class="docutils literal notranslate"><span class="pre">pattern-by-pattern</span></code>. Algunas veces también es referido como el algoritmo <code class="docutils literal notranslate"><span class="pre">online</span></code>. Nótese que el número total de datos muestrales es fijo, y que el algoritmo las considera en forma cíclica, época por época (<code class="docutils literal notranslate"><span class="pre">epoch-by-epoch</span></code>).</p></li>
<li><p>Despues de un número finito de épocas, se garantiza que el algoritmo es convergente. Nótese que para obtener dicha convergencia, la suseción <span class="math notranslate nohighlight">\(\mu_{i}\)</span> debe ser seleccionada apropiadamente. Sin embargo para el caso del algoritmo perceptrón, la convergencia es garantizada, aún cuando <span class="math notranslate nohighlight">\(\mu_{i}\)</span> es una constante positiva, <span class="math notranslate nohighlight">\(\mu_{i}=\mu&gt;0\)</span>, usualmente tomado igual a uno. La formulación en <a class="reference internal" href="#equation-eq-perceptron-algo2">(34)</a> es conocida también como la filosofia de aprendizaje <code class="docutils literal notranslate"><span class="pre">reward-punishment</span></code>. Si la actual estimación es exitosa en la predicción de la clase del respectivo patron, ninguna acción es tomada (<code class="docutils literal notranslate"><span class="pre">reward</span></code>), en otro caso, el agoritmo es obligado a realizar una actualización (<code class="docutils literal notranslate"><span class="pre">punishment</span></code>).</p></li>
</ul>
<figure class="align-center" id="perceptron-rule">
<img alt="_images/perceptron_rule.png" src="_images/perceptron_rule.png" />
<figcaption>
<p><span class="caption-number">Fig. 18 </span><span class="caption-text">El punto <span class="math notranslate nohighlight">\(x\)</span> está mal clasificado por la línea roja. La regla perceptrón gira el hiperplano hacia el punto <span class="math notranslate nohighlight">\(x\)</span>, para intentar incluirlo en el lado correcto del nuevo hiperplano y clasificarlo correctamente. El nuevo hiperplano está definido por <span class="math notranslate nohighlight">\(θ^{(i)}\)</span> y se muestra con la línea negra.</span><a class="headerlink" href="#perceptron-rule" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<ul>
<li><p>La <a class="reference internal" href="#perceptron-rule"><span class="std std-numref">Fig. 18</span></a> ofrece una interpretación geométrica de la <code class="docutils literal notranslate"><span class="pre">regla</span> <span class="pre">del</span> <span class="pre">perceptrón</span></code>. Supongamos que la muestra <span class="math notranslate nohighlight">\(\boldsymbol{x}\)</span> está mal clasificada por el hiperplano, <span class="math notranslate nohighlight">\(\boldsymbol{\theta}^{(i-1)}\)</span>. Como sabemos, por geometría analítica, <span class="math notranslate nohighlight">\(\boldsymbol{\theta}^{(i-1)}\)</span> corresponde a un vector que es perpendicular al hiperplano que está definido por este vector. Como <span class="math notranslate nohighlight">\(\boldsymbol{x}\)</span> se encuentra en el lado <span class="math notranslate nohighlight">\((-)\)</span> del hiperplano y está mal clasificado, pertenece a la clase <span class="math notranslate nohighlight">\(\omega_{1}\)</span>; asumiendo <span class="math notranslate nohighlight">\(\mu = 1\)</span>, la corrección aplicada por el algoritmo es</p>
<div class="math notranslate nohighlight">
\[\begin{split}
    \\[1mm]
    \boldsymbol{\theta}^{(i)}=\boldsymbol{\theta}^{(i-1)}+\boldsymbol{x},
    \end{split}\]</div>
<p>y su efecto es girar el hiperplano en dirección a <span class="math notranslate nohighlight">\(\boldsymbol{x}\)</span> para colocarlo en el lado <span class="math notranslate nohighlight">\((+)\)</span> del nuevo hiperplano, que está definido por la estimación actualizada <span class="math notranslate nohighlight">\(\boldsymbol{\theta^{(i)}}\)</span>. El <code class="docutils literal notranslate"><span class="pre">algoritmo</span> <span class="pre">perceptrón</span></code> en su modo de funcionamiento patrón por patrón (<code class="docutils literal notranslate"><span class="pre">pattern-by-pattern</span></code>) se resume en el siguiente algoritmo.</p>
</li>
</ul>
<div class="proof algorithm admonition" id="my_algorithm_pattern_by_pattern">
<p class="admonition-title"><span class="caption-number">Algorithm 1 </span> (Algoritmo perceptrón <em>pattern-by-pattern</em>)</p>
<section class="algorithm-content" id="proof-content">
<p><strong>Inicialización</strong></p>
<ol class="simple">
<li><p>Inicializar <span class="math notranslate nohighlight">\(\boldsymbol{\theta}^{(0)}\)</span>; usualmente, de forma random, un número pequeño</p></li>
<li><p>Seleccionar <span class="math notranslate nohighlight">\(\mu\)</span>; usualmente establecido como uno</p></li>
<li><p><span class="math notranslate nohighlight">\(i=1\)</span></p></li>
</ol>
<p><strong>Repeat</strong> Cada iteración corresponde a un <code class="docutils literal notranslate"><span class="pre">epoch</span></code></p>
<ol>
<li><p><code class="docutils literal notranslate"><span class="pre">counter</span> <span class="pre">=</span> <span class="pre">0</span></code>; Contador del número de actualizaciones por <code class="docutils literal notranslate"><span class="pre">epoch</span></code></p></li>
<li><p><strong>For</strong> <span class="math notranslate nohighlight">\(n=1,2,\dots,N\)</span> <strong>Do</strong> Para cada <code class="docutils literal notranslate"><span class="pre">epoch</span></code>, todas las muestras son presentadas una vez</p>
<p><strong>If</strong>(<span class="math notranslate nohighlight">\(y_{n}\boldsymbol{x}_{n}^{T}\leq0\)</span>) <strong>Then</strong></p>
<ol class="simple">
<li><p><span class="math notranslate nohighlight">\(\boldsymbol{\theta}^{(i)}=\boldsymbol{\theta}^{(i-1)}+\mu y_{n}\boldsymbol{x}_{n}\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(i=i+1\)</span></p></li>
<li><p>counter = counter + 1</p></li>
</ol>
<p><strong>End For</strong></p>
</li>
<li><p><strong>Until</strong> counter = 0</p></li>
</ol>
</section>
</div><ul class="simple">
<li><p>Una vez que el algoritmo perceptrón se ha ejecutado y converge, tenemos los pesos, <span class="math notranslate nohighlight">\(\theta_{i},~i = 1,2,\dots,l\)</span>, de las <code class="docutils literal notranslate"><span class="pre">sinapsis</span> <span class="pre">de</span> <span class="pre">la</span> <span class="pre">neurona/perceptrón</span></code> asociada, así como el término de sesgo <span class="math notranslate nohighlight">\(\theta_{0}\)</span>. Ahora se pueden utilizar para clasificar patrones desconocidos. Las características <span class="math notranslate nohighlight">\(x_{i}, i = 1, 2,\dots,l\)</span>, se aplican a los nodos de entrada. A su vez, cada característica se multiplica por la sinapsis respectiva (peso), y luego se añade el término de sesgo en su combinación lineal. El resultado de esta operación pasa por una función no lineal, <span class="math notranslate nohighlight">\(f\)</span>, conocida como función de activación. Dependiendo de la forma de la no linealidad, se producen diferentes tipos de neuronas. La mas clásica conocida como <code class="docutils literal notranslate"><span class="pre">neurona</span> <span class="pre">McCulloch-Pitts</span></code>, la función de activación es la de Heaviside, es decir,</p></li>
</ul>
<div class="math notranslate nohighlight">
\[\begin{split}
f(z)=
\begin{cases}
1,&amp;\quad\text{si}~z&gt;0,\\
0,&amp;\quad\text{si}~z\leq0.
\end{cases}
\end{split}\]</div>
<figure class="align-center" id="mcculloch-pitts">
<a class="reference internal image-reference" href="_images/mcculloch_pitts.png"><img alt="_images/mcculloch_pitts.png" src="_images/mcculloch_pitts.png" style="width: 532.0px; height: 167.20000000000002px;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 19 </span><span class="caption-text">Arquitectura básica de neuronas/perceptrones.</span><a class="headerlink" href="#mcculloch-pitts" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<ul class="simple">
<li><p>En la arquitectura básica de neuronas/perceptrones, las características de entrada se aplican a los nodos de entrada y se ponderan por los respectivos pesos que definen las sinapsis. A continuación se añade el término de sesgo en su combinación lineal y el resultado es empujado a través de la no linealidad. En la neurona <code class="docutils literal notranslate"><span class="pre">McCulloch-Pitts</span></code>, la salida es un 1 para los patrones de la clase <span class="math notranslate nohighlight">\(\omega_{1}\)</span> o un cero para la clase <span class="math notranslate nohighlight">\(\omega_{2}\)</span>. La suma y la operación no lineal se unen para simplificar el gráfico.</p></li>
</ul>
</section>
<section id="redes-neuronales-multicapa-feed-forward">
<h3>Redes Neuronales Multicapa Feed-Forward<a class="headerlink" href="#redes-neuronales-multicapa-feed-forward" title="Permalink to this headline">#</a></h3>
<ul>
<li><p>Una sola neurona está asociada a un hiperplano</p>
<div class="math notranslate nohighlight">
\[\begin{split}
    \\[1mm]
    H: \theta_{1}x_{1}+\theta_{2}x_{2}+\cdots+\theta_{l}x_{l}+\theta_{0}=0,
    \end{split}\]</div>
<p>en el espacio de entrada (característica). Además, la clasificación se realiza a través de la no linealidad, que entrega un uno o se queda en cero, dependiendo de en qué lado de <span class="math notranslate nohighlight">\(H\)</span> se encuentre un punto. A continuación, mostraremos cómo combinar neuronas, en forma de capas, para construir clasificadores no lineales. Seguiremos una prueba constructiva sencilla, que permitirá abordar ciertos aspectos de las redes neuronales, útiles cuando se trate de con arquitecturas profundas <code class="docutils literal notranslate"><span class="pre">deep</span> <span class="pre">learning</span></code>.</p>
</li>
</ul>
<ul class="simple">
<li><p>Como punto de partida, consideramos el caso en el que las clases del espacio de características están formadas por uniones de regiones poliédricas</p></li>
</ul>
<figure class="align-center" id="regiones-poliedricas">
<a class="reference internal image-reference" href="_images/regiones_poliedricas.png"><img alt="_images/regiones_poliedricas.png" src="_images/regiones_poliedricas.png" style="width: 452.9px; height: 290.5px;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 20 </span><span class="caption-text">Clases formadas por uniones de regiones poliédricas. Las regiones se etiquetan según el lado en el que se encuentran, con respecto a las tres líneas, <span class="math notranslate nohighlight">\(H_{1}, H_{2}\)</span> y <span class="math notranslate nohighlight">\(H_{3}\)</span>.</span><a class="headerlink" href="#regiones-poliedricas" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<ul class="simple">
<li><p>Las regiones poliédricas se forman como intersecciones de semiespacios, cada uno de ellos asociado a un hiperplano. En la <a class="reference internal" href="#regiones-poliedricas"><span class="std std-numref">Fig. 20</span></a>, hay tres hiperplanos (líneas rectas en <span class="math notranslate nohighlight">\(\mathbb{R}^2\)</span>), indicados como <span class="math notranslate nohighlight">\(H_{1}, H_{2}, H_{3}\)</span>, que dan lugar a siete regiones poliédricas. Para cada hiperplano se indican los lados <span class="math notranslate nohighlight">\((+)\)</span> y <span class="math notranslate nohighlight">\((-)\)</span> (semiespacios). Cada una de las regiones se etiqueta con un triplete de números binarios, según el lado que se encuentra con respecto a <span class="math notranslate nohighlight">\(H_{1}, H_{2}, H_{3}\)</span>. Por ejemplo, la región etiquetada como <span class="math notranslate nohighlight">\((101)\)</span> se encuentra en el lado <span class="math notranslate nohighlight">\((+)\)</span> de <span class="math notranslate nohighlight">\(H_{1}\)</span>, el lado <span class="math notranslate nohighlight">\((-)\)</span> de <span class="math notranslate nohighlight">\(H_{2}\)</span> y el lado <span class="math notranslate nohighlight">\((+)\)</span> de <span class="math notranslate nohighlight">\(H_{3}\)</span>.</p></li>
</ul>
<figure class="align-center" id="poliedros-neurons">
<a class="reference internal image-reference" href="_images/poliedros_neurons.png"><img alt="_images/poliedros_neurons.png" src="_images/poliedros_neurons.png" style="width: 613.9px; height: 301.0px;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 21 </span><span class="caption-text">(A) Las neuronas de la primera capa oculta son activadas por los valores de las características aplicadas en los nodos de entrada y forman las regiones poliédricas. (B) Las neuronas de la segunda capa tienen como entradas las salidas de la primera capa, y así
forman las clases.</span><a class="headerlink" href="#poliedros-neurons" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<p>La <a class="reference internal" href="#poliedros-neurons"><span class="std std-numref">Fig. 21</span></a> muestra tres neuronas, correspondientes a los tres hiperplanos, <span class="math notranslate nohighlight">\(H_{1}, H_{2}\)</span> y <span class="math notranslate nohighlight">\(H_{3}\)</span>, de la <a class="reference internal" href="#regiones-poliedricas"><span class="std std-numref">Fig. 20</span></a>, respectivamente. Las salidas asociadas, denotadas como <span class="math notranslate nohighlight">\(y_{1}, y_{2}\)</span>, y <span class="math notranslate nohighlight">\(y_{3}\)</span>, forman la etiqueta de la región a la que el patrón de entrada correspondiente pertenece. De hecho, si los pesos de las sinapsis se han fijado adecuadamente, entonces, si un patrón se origina en la región, digamos, <span class="math notranslate nohighlight">\((010)\)</span>, la primera neurona de la izquierda asigna un cero <span class="math notranslate nohighlight">\((y_{1} = 0)\)</span>, la del medio un uno <span class="math notranslate nohighlight">\((y_{2} = 1)\)</span>, y la de la derecha un cero <span class="math notranslate nohighlight">\((y_{3} = 0)\)</span>. En otras palabras, combinando las de las tres neuronas, hemos logrado un mapeo del espacio de características de entrada en el espacio tridimensional. Más concretamente, el mapeo se realiza en los vértices del cubo unitario en <span class="math notranslate nohighlight">\(\mathbb{R}^{3}\)</span>, como se muestra en la <a class="reference internal" href="#mapping-input-feature"><span class="std std-numref">Fig. 22</span></a></p>
<figure class="align-center" id="mapping-input-feature">
<a class="reference internal image-reference" href="_images/mapping_input_feature.png"><img alt="_images/mapping_input_feature.png" src="_images/mapping_input_feature.png" style="width: 449.4px; height: 411.59999999999997px;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 22 </span><span class="caption-text">Las neuronas de la primera capa oculta realizan un mapeo del espacio de características de entrada a los vértices de un hipercubo unitario. El vértice 110, denotado como un círculo sin sombrear, no corresponde a ninguna región.</span><a class="headerlink" href="#mapping-input-feature" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<ul class="simple">
<li><p>Cada región del espacio de entrada corresponde exclusivamente a un vértice del cubo. En el caso más general, en el que se emplean <span class="math notranslate nohighlight">\(p\)</span> neuronas, el mapeo se hará sobre los vértices del hipercubo unitario en <span class="math notranslate nohighlight">\(\mathbb{R}^{p}\)</span>. Esta capa de neuronas constituye la primera capa oculta de la red, que estamos desarrollando.</p></li>
</ul>
<ul class="simple">
<li><p>Ahora utilizaremos esta nueva representación, proporcionada por las salidas de las neuronas de la primera capa oculta, como entrada que alimenta las neuronas de una segunda capa oculta, la cual se construye de la siguiente forma. Elegimos todas las regiones que pertenecen a una clase. Para nuestro ejemplo de la <a class="reference internal" href="#regiones-poliedricas"><span class="std std-numref">Fig. 20</span></a>, seleccionamos las dos regiones que corresponden a la clase <span class="math notranslate nohighlight">\(\omega_{1}\)</span>, es decir, <span class="math notranslate nohighlight">\((000)\)</span> y <span class="math notranslate nohighlight">\((111)\)</span>. Recordemos que todos los puntos de estas regiones se mapean a los respectivos vértices del cubo unitario en la <span class="math notranslate nohighlight">\(\mathbb{R}^{3}\)</span>. Sin embargo, en este nuevo espacio transformado, cada uno de los vértices es linealmente separable del resto. Esto significa que podemos utilizar una neurona/perceptrón en el espacio transformado, que colocará un solo vértice en el lado <span class="math notranslate nohighlight">\((+)\)</span> y el resto en el <span class="math notranslate nohighlight">\((-)\)</span> del hiperplano asociado. Esto se muestra en la <a class="reference internal" href="#mapping-input-feature"><span class="std std-numref">Fig. 22</span></a>, donde se muestran dos de estos planos, que separan los respectivos vértices del resto. Cada uno de estos planos es obtenido por medio de una neurona que opera en <span class="math notranslate nohighlight">\(\mathbb{R}^{3}\)</span>, como se muestra en la <a class="reference internal" href="#poliedros-neurons"><span class="std std-numref">Fig. 21</span></a>, donde se ha añadido una segunda capa de neuronas ocultas.</p></li>
</ul>
<ul class="simple">
<li><p>Observe que la salida <span class="math notranslate nohighlight">\(z_{1}\)</span> de la neurona izquierda arroja un 1 sólo si el patrón de entrada se origina en la región <span class="math notranslate nohighlight">\(000\)</span> y 0 para todos los demás patrones. Para la neurona de la derecha, la salida <span class="math notranslate nohighlight">\(z_{2}\)</span> será 1 para todos los patrones procedentes de la región <span class="math notranslate nohighlight">\((111)\)</span> y cero para el resto (ver <a class="reference internal" href="#mapping-input-feature"><span class="std std-numref">Fig. 22</span></a>). Nótese que esta segunda capa de neuronas ha realizado un segundo mapeo, esta vez a los vértices del rectángulo unitario en <span class="math notranslate nohighlight">\(\mathbb{R}^{2}\)</span>.</p></li>
</ul>
<figure class="align-center" id="map-layer-intor2">
<a class="reference internal image-reference" href="_images/map_layer_intor2.png"><img alt="_images/map_layer_intor2.png" src="_images/map_layer_intor2.png" style="width: 507.20000000000005px; height: 364.0px;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 23 </span><span class="caption-text">Los patrones de la clase <span class="math notranslate nohighlight">\(\omega_{1}\)</span> se asignan a (01) o a (10) y los patrones de la clase <span class="math notranslate nohighlight">\(\omega_{2}\)</span> se asignan a (00). Clases ahora linealmente separables a través de una línea recta realizada por una neurona.</span><a class="headerlink" href="#map-layer-intor2" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<ul class="simple">
<li><p>Este mapeo proporciona una nueva representación de los patrones de entrada, y esta representación codifica la información relacionada con las clases de las regiones. La <a class="reference internal" href="#map-layer-intor2"><span class="std std-numref">Fig. 23</span></a> muestra el mapeo a los vértices del rectángulo unitario en el espacio <span class="math notranslate nohighlight">\((z_{1}, z_{2})\)</span>. Obsérvese que todos los puntos procedentes de la clase <span class="math notranslate nohighlight">\(\omega_{2}\)</span> están mapeados a <span class="math notranslate nohighlight">\((00)\)</span> y los puntos de la clase <span class="math notranslate nohighlight">\(\omega_{1}\)</span> están asignados a <span class="math notranslate nohighlight">\((10)\)</span> o a <span class="math notranslate nohighlight">\((01)\)</span>. Esto es, mediante mapeos sucesivos, hemos transformado nuestra tarea, originalmente, linealmente no separable a una que es linealmente separable. En efecto, el punto <span class="math notranslate nohighlight">\((00)\)</span> puede separarse linealmente de <span class="math notranslate nohighlight">\((01)\)</span> y <span class="math notranslate nohighlight">\((10)\)</span>, y esto puede realizarse mediante una neurona adicional que opera en el espacio <span class="math notranslate nohighlight">\((z_{1}, z_{2})\)</span>; la cual se conoce como la neurona de salida, porque proporciona la decisión final de clasificación.</p></li>
</ul>
<figure class="align-center" id="final-neural-network">
<a class="reference internal image-reference" href="_images/final_neural_network.png"><img alt="_images/final_neural_network.png" src="_images/final_neural_network.png" style="width: 317.79999999999995px; height: 376.59999999999997px;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 24 </span><span class="caption-text">Red neuronal feed-forward de tres capas. Comprende la capa de entrada (no de procesamiento), dos capas ocultas y una capa de salida de neuronas</span><a class="headerlink" href="#final-neural-network" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<ul class="simple">
<li><p>La red final resultante se muestra en la <a class="reference internal" href="#final-neural-network"><span class="std std-numref">Fig. 24</span></a>. Llamamos a esta red <code class="docutils literal notranslate"><span class="pre">feed-forward</span></code>, porque la información fluye hacia adelante desde la capa de entrada a la de salida. Se compone de la capa de entrada, que es una capa no procesadora, dos capas ocultas, y una capa de salida. Llamamos a esta red neuronal, <code class="docutils literal notranslate"><span class="pre">red</span> <span class="pre">de</span> <span class="pre">tres</span> <span class="pre">capas</span></code>, sin contar la capa de entrada de nodos no procesadores. Esta red neuronal de tres capas puede resolver cualquier tarea de clasificación, en la que las clases están formadas por uniones de regiones poliédricas.</p></li>
</ul>
<ul class="simple">
<li><p>Hemos demostrado constructivamente que una red neuronal feed-forward de tres capas puede, en principio, resolver cualquier tarea de clasificación cuyas clases estén formadas por uniones de regiones poliédricas. Aunque nos hemos centrado en el caso de dos clases, la generalización a casos multiclase es sencilla, empleando más neuronas de salida en función del número de clases. Obsérvese que en algunos casos, una capa oculta de nodos puede ser suficiente. Esto depende de si los vértices en los que se mapean las regiones se asignan a las clases para que sea posible la separabilidad lineal.</p></li>
<li><p>Dicha construcción es importante para demostrar la potencia de la construcción de una red neuronal multicapa, en analogía con lo que ocurre en nuestro cerebro. Sin embargo, desde un punto de vista práctico, dicha construcción no tiene mucho que ofrecer. En la práctica, cuando los datos viven en espacios de alta dimensión, no hay posibilidad de determinar los parámetros que definen las neuronas analíticamente para realizar los hiperplanos, que forman las regiones poliédricas. Además, en la vida real, las clases no están necesariamente formadas por la unión de regiones poliédricas y las clases más importantes se solapan. Por lo tanto, es necesario concebir un <code class="docutils literal notranslate"><span class="pre">procedimiento</span> <span class="pre">de</span> <span class="pre">entrenamiento</span> <span class="pre">basado</span> <span class="pre">en</span> <span class="pre">una</span> <span class="pre">función</span> <span class="pre">de</span> <span class="pre">coste</span></code> y un conjunto de datos de entrenamiento.</p></li>
<li><p>Lo único que tenemos que conservar de nuestra discusión anterior es la estructura de la red multicapa. Nuestro interés se centrará en buscar formas de estimar los pesos desconocidos de las sinapsis y los sesgos de las neuronas. Sin embargo, desde un punto de vista conceptual, debemos recordar que cada capa realiza un mapeo en un nuevo espacio, y cada mapeo proporciona una representación diferente, esperemos que más información de los datos de entrada, hasta la última capa, donde la tarea se ha transformado en una que es fácil de resolver.</p></li>
</ul>
</section>
<section id="redes-totalmente-conectadas">
<h3>Redes Totalmente Conectadas<a class="headerlink" href="#redes-totalmente-conectadas" title="Permalink to this headline">#</a></h3>
<ul class="simple">
<li><p>Las redes <code class="docutils literal notranslate"><span class="pre">feed-forward</span></code> que se han presentado anteriormente también se conocen como redes totalmente conectadas. Este nombre es para destacar que cada una de las neuronas/nodos de cualquier capa está directamente conectada a todos los nodos de la capa anterior. Los nodos de la primera capa oculta están totalmente conectados a los de la capa de entrada. En otras palabras, cada neurona está asociada a un vector de parámetros, cuya dimensión es igual al número de nodos de la capa anterior (de entrada). Las operaciones algebraicas que se realizan son productos internos.</p></li>
</ul>
<ul class="simple">
<li><p>Para resumir de manera más formal el tipo de operaciones que tienen lugar en una red totalmente conectada, centrémonos en, por ejemplo, la capa <span class="math notranslate nohighlight">\(r\)</span> de una red neuronal multicapa y supongamos que está formada por <span class="math notranslate nohighlight">\(k_{r}\)</span> neuronas. El vector de entrada a esta capa está formado por las salidas de los nodos de la capa anterior, que se denomina <span class="math notranslate nohighlight">\(\boldsymbol{y}^{r-1}\)</span>. Sea <span class="math notranslate nohighlight">\(\boldsymbol{\theta}_{j}^{r}\)</span> el vector de los pesos sinápticos, incluido el término de sesgo, asociado a la neurona <span class="math notranslate nohighlight">\(j\)</span> de la capa <span class="math notranslate nohighlight">\(r\)</span>, donde <span class="math notranslate nohighlight">\(j = 1,2,\dots, k_{r}\)</span>. La dimensión respectiva es <span class="math notranslate nohighlight">\(k_{r-1} + 1\)</span>, donde <span class="math notranslate nohighlight">\(k_{r-1}\)</span> es el número de neuronas de la capa anterior, <span class="math notranslate nohighlight">\(r-1\)</span>, y el aumento en 1 representa el término de sesgo. Entonces las operaciones realizadas, antes de la no linealidad, son los productos internos</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
z_{j}^{r}=\boldsymbol{\theta}_{j}^{rT}\boldsymbol{y}^{r-1},\quad j=1,2,\dots,k_{r}.
\]</div>
<ul class="simple">
<li><p>Colocando todos los valores de salida en un vector <span class="math notranslate nohighlight">\(\boldsymbol{z}^{r}=[z_{1}^{r}, z_{2}^{r},\dots,z_{k_{r}}^{r}]^{T}\)</span>, y agrupando todos los vectores sinapticos como filas, una debajo de la otra, en una matriz, podemos escribir colectivamente</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
\boldsymbol{z}^{r}=\Theta\boldsymbol{y}^{r-1},\quad\text{donde}\quad\Theta:=[\boldsymbol{\theta}_{1}^{r}, \boldsymbol{\theta}_{2}^{r},\dots, \boldsymbol{\theta}_{k_{r}}^{r}].
\]</div>
<ul class="simple">
<li><p>El vector de las salidas de la <span class="math notranslate nohighlight">\(r\)</span> th capa oculta, después de empujar cada <span class="math notranslate nohighlight">\(z_{i}^{r}\)</span> a través de la no linealidad <span class="math notranslate nohighlight">\(f\)</span>, está finalmente dado por</p></li>
</ul>
<div class="math notranslate nohighlight">
\[\begin{split}
\boldsymbol{y}^{r}=
\begin{bmatrix}
1\\
f(\boldsymbol{z}^{r})
\end{bmatrix}
\end{split}\]</div>
<ul class="simple">
<li><p>La notación anterior significa que <span class="math notranslate nohighlight">\(f\)</span> actúa sobre cada uno de los respectivos componentes del vector, individualmente, y la extensión del vector en uno es para dar cuenta de los términos de sesgo en la práctica estándar. Para redes grandes, con muchas capas y muchos nodos por capa, este tipo de conectividad resulta ser muy costoso en términos del número de parámetros (pesos), que es del orden de <span class="math notranslate nohighlight">\(k_{r}k_{r-1}\)</span>. Por ejemplo, si <span class="math notranslate nohighlight">\(k_{r-1} = 1000\)</span> y <span class="math notranslate nohighlight">\(k_{r} = 1000\)</span>, esto equivale a un orden de 1 millón de parámetros. Tenga en cuenta que este número es la contribución de los parámetros de una sola de las capas. Sin embargo, un gran número de parámetros hace que una red sea vulnerable al sobreajuste, cuando se trata de entrenamiento</p></li>
<li><p>Se pueden emplear las llamadas técnicas de reparto de pesos, en las que un conjunto de parámetros es compartido entre un número de conexiones, a través de restricciones adecuadamente incorporadas. Las <code class="docutils literal notranslate"><span class="pre">redes</span> <span class="pre">nuronales</span> <span class="pre">recurrentes</span> <span class="pre">y</span> <span class="pre">convolucionales</span></code> que se discutirán en en el curso <code class="docutils literal notranslate"><span class="pre">Time</span> <span class="pre">Series</span> <span class="pre">Forecasting</span></code>, pertenecen a esta familia de redes de peso compartido. Como veremos, en una red convolucional, las convoluciones sustituyen a las operaciones de producto interno, lo que permite un reparto de pesos importante que conduce a una reducción sustancial del número de parámetros.</p></li>
</ul>
</section>
<section id="el-algoritmo-de-backpropagation">
<h3>El Algoritmo De Backpropagation<a class="headerlink" href="#el-algoritmo-de-backpropagation" title="Permalink to this headline">#</a></h3>
<ul class="simple">
<li><p>Una red neuronal <code class="docutils literal notranslate"><span class="pre">feed-forward</span></code> está formada por un número de capas de neuronas, y cada neurona está determinada por el correspondiente conjunto de pesos sinápticos y su término de sesgo. Desde este punto de vista, una red neuronal considera una función paramétrica no lineal, <span class="math notranslate nohighlight">\(\hat{y} = f_{\boldsymbol{\theta}}(\boldsymbol{x})\)</span>, donde <span class="math notranslate nohighlight">\(\boldsymbol{\theta}\)</span> representa todos los pesos/sesgo presentes en la red. Por lo tanto, el entrenamiento de una red neuronal no parece ser diferente del entrenamiento de cualquier otro modelo de predicción paramétrica. Todo lo que se necesita es <code class="docutils literal notranslate"><span class="pre">(a)</span></code> un conjunto de muestras de entrenamiento, <code class="docutils literal notranslate"><span class="pre">(b)</span></code> una función de pérdida <span class="math notranslate nohighlight">\(\mathcal{L}(y, \hat{y})\)</span>, y <code class="docutils literal notranslate"><span class="pre">(c)</span></code> un esquema iterativo, por ejemplo, el <code class="docutils literal notranslate"><span class="pre">gradiente</span> <span class="pre">descendiente</span></code>, para realizar la optimización de la función de coste asociada (<code class="docutils literal notranslate"><span class="pre">pérdida</span> <span class="pre">empírica</span></code>).</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
J(\boldsymbol{\theta})=\sum_{n=1}^{N}\mathcal{L}(y_{n}, f_{\boldsymbol{\theta}}(\boldsymbol{x}_{n})).
\]</div>
<ul class="simple">
<li><p>La dificultad del entrenamiento de las redes neuronales radica en su estructura multicapa que complica el cálculo de los gradientes, que intervienen en la optimización. Además, la neurona <code class="docutils literal notranslate"><span class="pre">McCulloch-Pitts</span></code> se basa en la función de activación discontinua de <code class="docutils literal notranslate"><span class="pre">Heaviside</span></code>, que no es diferenciable. Un primer paso para desarrollar un algoritmo práctico para entrenar una red neuronal es sustituir la función de activación de <code class="docutils literal notranslate"><span class="pre">Heaviside</span></code> por una aproximación diferenciable de la misma.</p></li>
</ul>
<ul class="simple">
<li><p>La <code class="docutils literal notranslate"><span class="pre">neurona</span> <span class="pre">sigmoidea</span> <span class="pre">logística</span></code>: Una posibilidad es adoptar la función <code class="docutils literal notranslate"><span class="pre">sigmoidea</span> <span class="pre">logística</span></code>, es decir,</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
f(z)=\sigma(z):=\frac{1}{1+\exp(-az)}.
\]</div>
<ul class="simple">
<li><p>Obsérvese que cuanto mayor sea el valor del parámetro <span class="math notranslate nohighlight">\(a\)</span>, la gráfica correspondiente se acerca más a la de la función de <code class="docutils literal notranslate"><span class="pre">Heaviside</span></code> (ver <a class="reference internal" href="#sigmoid-act-function"><span class="std std-numref">Fig. 25</span></a>).</p></li>
</ul>
<figure class="align-center" id="sigmoid-act-function">
<a class="reference internal image-reference" href="_images/sigmoid_act_function.png"><img alt="_images/sigmoid_act_function.png" src="_images/sigmoid_act_function.png" style="width: 507.20000000000005px; height: 471.20000000000005px;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 25 </span><span class="caption-text">La función sigmoidea logística para diferentes valores del parámetro <span class="math notranslate nohighlight">\(a\)</span>.</span><a class="headerlink" href="#sigmoid-act-function" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<ul>
<li><p>Otra posibilidad sería utilizar la función,</p>
<div class="math notranslate nohighlight">
\[
    f(z)=a\tanh\left(\frac{cz}{2}\right),
    \]</div>
<p>donde <span class="math notranslate nohighlight">\(c\)</span> y <span class="math notranslate nohighlight">\(a\)</span> son parámetros de control. El gráfico de esta función se muestra en la <a class="reference internal" href="#tanh-act-function"><span class="std std-numref">Fig. 26</span></a>. Nótese que a diferencia de la sigmoidea logística, ésta es una función es antisimétrica, es decir, <span class="math notranslate nohighlight">\(f(-z)=-f(z)\)</span>. Ambas son también conocidas como funciones de reducción o de achicamiento, porque limitan la salida a un rango finito de valores.</p>
</li>
</ul>
<figure class="align-center" id="tanh-act-function">
<a class="reference internal image-reference" href="_images/tanh_act_function.png"><img alt="_images/tanh_act_function.png" src="_images/tanh_act_function.png" style="width: 693.6px; height: 435.20000000000005px;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 26 </span><span class="caption-text">Función de reducción de la tangente hiperbólica para <span class="math notranslate nohighlight">\(a = 1.7\)</span> y <span class="math notranslate nohighlight">\(c = 4/3\)</span>.</span><a class="headerlink" href="#tanh-act-function" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<ul>
<li><p>Cuando se adopta un esquema de <code class="docutils literal notranslate"><span class="pre">gradiente</span> <span class="pre">descendiente</span></code> para minimizar una función de coste no convexa, el algoritmo puede converger a un mínimo local o global. Tomemos, por ejemplo, el caso de la <a class="reference internal" href="#convex-function-saddle-point"><span class="std std-numref">Fig. 27</span></a>. Recordemos que la regla de actualización del algoritmo gradiente descendiente, en su versión unidimensional se convierte en</p>
<div class="math notranslate nohighlight">
\[\begin{split}
    \\[1mm]
    \theta(new)=\theta(old)-\mu\left.\frac{d J}{d\theta}\right|_{\theta(old)},
    \end{split}\]</div>
<p>y las iteraciones parten de un punto inicial arbitrario, <span class="math notranslate nohighlight">\(\theta^{(0)}\)</span>. Si en la iteración actual el algoritmo está digamos, en el punto <span class="math notranslate nohighlight">\(\theta(old) = \theta_{1}\)</span>, entonces se moverá hacia el mínimo local, <span class="math notranslate nohighlight">\(\theta_{l}\)</span>. Esto se debe a que la derivada del coste en <span class="math notranslate nohighlight">\(\theta_{1}\)</span> es igual a la tangente de <span class="math notranslate nohighlight">\(\phi_{1}\)</span>, que es negativa (el ángulo es obtuso) y la actualización, <span class="math notranslate nohighlight">\(\theta(new)\)</span>, se moverá a la derecha, hacia el mínimo local, <span class="math notranslate nohighlight">\(\theta_{l}\)</span>.</p>
</li>
</ul>
<figure class="align-center" id="convex-function-saddle-point">
<a class="reference internal image-reference" href="_images/convex_function_saddle_point.png"><img alt="_images/convex_function_saddle_point.png" src="_images/convex_function_saddle_point.png" style="width: 635.2px; height: 354.40000000000003px;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 27 </span><span class="caption-text">Función no convexa global, con mínimos locales y puntos de silla.</span><a class="headerlink" href="#convex-function-saddle-point" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<ul class="simple">
<li><p>Por el contrario, si el algoritmo se hubiera inicializado desde un punto diferente y el algoritmo estuviera actualmente en, digamos, <span class="math notranslate nohighlight">\(\theta(old) = \theta_{2}\)</span>, la actualización se moverá hacia el mínimo global, <span class="math notranslate nohighlight">\(\theta_{g}\)</span>, ya que la derivada es ahora igual a la tangente de <span class="math notranslate nohighlight">\(\phi_{2}\)</span>, que es positivo (el ángulo es agudo). Como sabemos, la elección del tamaño del paso, <span class="math notranslate nohighlight">\(\mu\)</span>, es crítica para la convergencia del algoritmo. En problemas reales en espacios multidimensionales, el número de mínimos locales puede ser grande, por lo que el algoritmo puede converger a uno local. Sin embargo, esto no es necesariamente una mala noticia. Si este mínimo local es lo suficientemente profundo, es decir, si el valor de la función de coste en este punto, por ejemplo, <span class="math notranslate nohighlight">\(J(\theta_{l})\)</span>, no es mucho mayor que el alcanzado en el mínimo global, es decir, <span class="math notranslate nohighlight">\(J(\theta_{g})\)</span>, la convergencia a dicho mínimo local puede corresponder a una buena solución. En la práctica, hay que tener cuidado con la forma de inicializar un algoritmo cuando se trata de funciones de coste no convexas. Vamos a discutir esta cuestión más adelante, en la seccón de <code class="docutils literal notranslate"><span class="pre">evaluación</span> <span class="pre">de</span> <span class="pre">modelos</span></code>.</p></li>
</ul>
</section>
<section id="el-esquema-de-backpropagation-para-gradiente-descendiente">
<h3>El Esquema De Backpropagation Para Gradiente Descendiente<a class="headerlink" href="#el-esquema-de-backpropagation-para-gradiente-descendiente" title="Permalink to this headline">#</a></h3>
<ul class="simple">
<li><p>Habiendo adoptado una función de activación diferenciable, estamos listos para proceder a desarrollar el esquema iterativo de gradiente descendiente para la minimización de la función de coste. Formularemos la tarea en un marco general.</p></li>
<li><p>Sea <span class="math notranslate nohighlight">\((\boldsymbol{y}_{n}, \boldsymbol{x}_{n}), n = 1, 2,\dots, N\)</span>, es el conjunto de muestras de entrenamiento. Obsérvese que hemos asumido múltiples variables output, como vectores. Suponemos que la red consta de <span class="math notranslate nohighlight">\(L\)</span> capas, <span class="math notranslate nohighlight">\(L-1\)</span> capas ocultas y una capa de salida. Cada capa consta de <span class="math notranslate nohighlight">\(k_{r}, r = 1, 2,\dots, L\)</span>, neuronas. Así, los vectores de salida (objetivo/deseado) son</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
\boldsymbol{y}_{n}=[y_{n1}, y_{n2},\dots, y_{nk_{L}}]^{T}\in\mathbb{R}^{K_{L}},\quad n=1,2,\dots,N.
\]</div>
<ul class="simple">
<li><p>Para ciertas derivaciones matemáticas, también denotamos el número de nodos de entrada como <span class="math notranslate nohighlight">\(k_{0}\)</span>; es decir <span class="math notranslate nohighlight">\(k_{0} = l\)</span>, donde <span class="math notranslate nohighlight">\(l\)</span> es la dimensionalidad del espacio de características de entrada.</p></li>
<li><p>Sea <span class="math notranslate nohighlight">\(\boldsymbol{\theta}_{j}^{r}\)</span> denota el vector de los pesos sinápticos asociados a la <span class="math notranslate nohighlight">\(j\)</span> th neurona de la <span class="math notranslate nohighlight">\(r\)</span> th capa, con <span class="math notranslate nohighlight">\(j = 1, 2,\dots, k_{r}\)</span> y <span class="math notranslate nohighlight">\(r = 1, 2,\dots,L\)</span>, donde el término de sesgo se incluye en <span class="math notranslate nohighlight">\(\boldsymbol{\theta}_{j}^{r}\)</span> , es decir,</p></li>
</ul>
<div class="math notranslate nohighlight" id="equation-parameters-vector-def">
<span class="eqno">(35)<a class="headerlink" href="#equation-parameters-vector-def" title="Permalink to this equation">#</a></span>\[
\boldsymbol{\theta}_{j}^{r}:=[\theta_{j0}^{r}, \theta_{j1}^{r},\dots, \theta_{jk_{r-1}}^{r}]^{T}.
\]</div>
<ul class="simple">
<li><p>Los pesos sinápticos enlazan la neurona respectiva con todas las neuronas de la capa <span class="math notranslate nohighlight">\(k_{r-1}\)</span> (véase la <a class="reference internal" href="#synaptic-weights-link"><span class="std std-numref">Fig. 28</span></a>). El paso iterativo básico para el esquema de gradiente descendiente se escribe como</p></li>
</ul>
<div class="math notranslate nohighlight" id="equation-update-equations-gd">
<span class="eqno">(36)<a class="headerlink" href="#equation-update-equations-gd" title="Permalink to this equation">#</a></span>\[\begin{split}
\begin{align*}
\boldsymbol{\theta}_{j}^{r}(new)&amp;=\boldsymbol{\theta}_{j}^{r}(old)+\Delta\boldsymbol{\theta}_{j}^{r},\\
\Delta\boldsymbol{\theta}_{j}^{r}&amp;:=-\mu\left.\frac{\partial J}{\partial\boldsymbol{\theta}_{j}^{r}}\right|_{\boldsymbol{\theta}_{j}^{r}(old)}.
\end{align*}
\end{split}\]</div>
<ul class="simple">
<li><p>El parámetro <span class="math notranslate nohighlight">\(\mu\)</span> es el tamaño de paso definido por el usuario (también puede depender de la iteración) y <span class="math notranslate nohighlight">\(J\)</span> denota la función de coste.</p></li>
</ul>
<figure class="align-center" id="synaptic-weights-link">
<a class="reference internal image-reference" href="_images/synaptic_weights_link.png"><img alt="_images/synaptic_weights_link.png" src="_images/synaptic_weights_link.png" style="width: 529.6px; height: 355.20000000000005px;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 28 </span><span class="caption-text">Enlaces y las variables asociadas de la <span class="math notranslate nohighlight">\(j\)</span> th neurona en la <span class="math notranslate nohighlight">\(r\)</span> th capa. <span class="math notranslate nohighlight">\(y_{k}^{r-1}\)</span> es la salida de la <span class="math notranslate nohighlight">\(k\)</span> th neurona de la <span class="math notranslate nohighlight">\((r - 1)\)</span> th capa y <span class="math notranslate nohighlight">\(\theta_{jk}^{r}\)</span> es el peso respectivo que conecta estas dos neuronas.</span><a class="headerlink" href="#synaptic-weights-link" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<ul>
<li><p>Las ecuaciones de actualización <a class="reference internal" href="#equation-update-equations-gd">(36)</a> comprenden el par del esquema de gradiente descendiente  para la optimización. Como se ha dicho anteriormente, la dificultad de las redes neuronales <code class="docutils literal notranslate"><span class="pre">feed-forward</span></code> surge de su estructura multicapa. Para calcular los gradientes en la Ecuación <a class="reference internal" href="#equation-update-equations-gd">(36)</a>, para todas las neuronas en todas las capas, se deben seguir dos pasos en su cálculo</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">Forward</span> <span class="pre">computations</span></code>: Para un vector de entrada dado <span class="math notranslate nohighlight">\(\boldsymbol{x}_{n}, n = 1, 2,\dots, N\)</span>, se utilizan las estimaciones actuales de los parámetros (pesos sinápticos) (<span class="math notranslate nohighlight">\(\boldsymbol{\theta}_{j}^{r}(old)\)</span>) y calcula todas las salidas de todas las neuronas en todas las capas, denotadas como <span class="math notranslate nohighlight">\(y_{nj}^{r}\)</span>; en la <a class="reference internal" href="#synaptic-weights-link"><span class="std std-numref">Fig. 28</span></a>, se ha suprimido el índice <span class="math notranslate nohighlight">\(n\)</span> para no afectar la notación.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">Backward</span> <span class="pre">computations</span></code>: Utilizando las salidas neuronales calculadas anteriormente junto con los valores objetivo conocidos, <span class="math notranslate nohighlight">\(y_{nk}\)</span>, de la capa de salida, se calculan los gradientes de la función de coste. Esto implica <span class="math notranslate nohighlight">\(L\)</span> pasos, es decir, tantos como el número de capas. La secuencia de los pasos algorítmicos se indica a continuación:</p>
<ul>
<li><p>Calcular el gradiente de la función de coste con respecto a los parámetros de las neuronas de la última capa, es decir, <span class="math notranslate nohighlight">\(\displaystyle{\frac{\partial J}{\partial\boldsymbol{\theta}_{j}^{L}}, j = 1, 2,\dots, k_{L}}\)</span>.</p></li>
<li><p><strong>For</strong> <span class="math notranslate nohighlight">\(r = L-1\)</span> to <span class="math notranslate nohighlight">\(1\)</span>, <strong>Do</strong></p>
<p>Calcular los gradientes con respecto a los parámetros asociados a las neuronas de la <span class="math notranslate nohighlight">\(r\)</span> th capa, es decir, <span class="math notranslate nohighlight">\(\displaystyle{\frac{\partial J}{\partial\boldsymbol{\theta}_{k}^{r}}, k= 1, 2,\dots, k_{r}}\)</span> basado en todos los gradientes <span class="math notranslate nohighlight">\(\displaystyle{\frac{\partial J}{\partial\boldsymbol{\theta}_{j}^{r+1}}, j= 1, 2,\dots, k_{r+1}}\)</span>, con respecto a los parámetros de la capa <span class="math notranslate nohighlight">\(r + 1\)</span> que se han calculado en el paso anterior.</p>
</li>
<li><p><strong>End For</strong></p></li>
</ul>
</li>
</ul>
</li>
</ul>
<ul>
<li><p>El esquema de cálculo hacia atrás <code class="docutils literal notranslate"><span class="pre">backpropagation</span></code> es una aplicación directa de la <code class="docutils literal notranslate"><span class="pre">regla</span> <span class="pre">de</span> <span class="pre">la</span> <span class="pre">cadena</span> <span class="pre">para</span> <span class="pre">las</span> <span class="pre">derivadas</span></code>, y comienza con el paso inicial de calcular las derivadas asociadas a la última capa (de salida), que resulta ser sencillo. A continuación, el algoritmo “fluye” hacia atrás en la jerarquía de capas. Este se debe a la naturaleza de la red multicapa, donde las salidas, capa tras capa, se forman como funciones de funciones. En efecto, centrémonos en la salida <span class="math notranslate nohighlight">\(y_{k}^{r}\)</span> de la neurona <span class="math notranslate nohighlight">\(k\)</span> en la capa <span class="math notranslate nohighlight">\(r\)</span>. Entonces tenemos</p>
<div class="math notranslate nohighlight">
\[\begin{split}
    \\[1mm]
    y_{k}^{r}=f(\boldsymbol{\theta}_{k}^{r^T}\boldsymbol{y}^{r-1}),\quad k=1,2,\dots, k_{r},
    \end{split}\]</div>
<p>donde <span class="math notranslate nohighlight">\(\boldsymbol{y}^{r-1}\)</span> es el vector (ampliado) que comprende todas las salidas de la capa anterior, <span class="math notranslate nohighlight">\(r-1\)</span>, y <span class="math notranslate nohighlight">\(f\)</span> denota la no-linealidad.</p>
</li>
</ul>
<ul>
<li><p>De acuerdo con lo anterior, la salida de la <span class="math notranslate nohighlight">\(j\)</span> th neurona en la siguiente capa viene dada por</p>
<div class="math notranslate nohighlight">
\[\begin{split}
    \\[1mm]
    y_{j}^{r+1}=f(\boldsymbol{\theta}_{j}^{r+1^T}\boldsymbol{y}^{r})=f\left(\boldsymbol{\theta}_{j}^{r+1^{T}}
    \begin{bmatrix}
    1\\
    f(\Theta^{r}\boldsymbol{y}^{r-1})
    \end{bmatrix}
    \right),
    \end{split}\]</div>
<p>donde <span class="math notranslate nohighlight">\(\Theta^{r}:=[\boldsymbol{\theta}_{1}^{r}, \boldsymbol{\theta}_{2}^{r},\dots,\boldsymbol{\theta}_{k_{r}}]^{T}\)</span> denota la matriz cuyas columnas corresponden al vector de pesos en el layer <span class="math notranslate nohighlight">\(r\)</span>.</p>
</li>
</ul>
<ul class="simple">
<li><p>Nótese que obtuvimos evaluación de “una función interna bajo una función externa”. Claramente, esto continúa a medida que avanzamos en la jerarquía. Esta estructura de evaluación de funciones internas por funciones externas, es el subproducto de la naturaleza multicapa de las redes neuronales, la cual es una operación altamente no lineal, que da lugar a la dificultad de calcular los gradientes, a diferencia de otros modelos, como por ejemplo <code class="docutils literal notranslate"><span class="pre">SVM</span></code>. Sin embargo, se puede observar fácilmente que el <code class="docutils literal notranslate"><span class="pre">cálculo</span> <span class="pre">de</span> <span class="pre">los</span> <span class="pre">gradientes</span> <span class="pre">con</span> <span class="pre">respecto</span> <span class="pre">a</span> <span class="pre">los</span> <span class="pre">parámetros</span> <span class="pre">que</span> <span class="pre">definen</span> <span class="pre">la</span> <span class="pre">capa</span> <span class="pre">de</span> <span class="pre">salida</span> <span class="pre">no</span> <span class="pre">plantea</span> <span class="pre">ninguna</span> <span class="pre">dificultad</span></code>. En efecto, la salida de la <span class="math notranslate nohighlight">\(j\)</span> th neurona de la última capa (que es en realidad la respectiva estimación de salida actual) se escribe como:</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
\hat{y}_{j}:=y_{j}^{L}=f(\boldsymbol{\theta}_{j}^{L^{T}}\boldsymbol{y}^{L-1}).
\]</div>
<ul class="simple">
<li><p>Dado que <span class="math notranslate nohighlight">\(y^{L-1}\)</span> es conocido, después de los cálculos durante el paso adelante, tomando la derivada con respecto a <span class="math notranslate nohighlight">\(\boldsymbol{\theta}_{j}^{L}\)</span> es sencillo; no hay ninguna operación de función sobre función. Por esto es que empezamos por la capa superior y luego nos movemos hacia atrás. Debido a su importancia histórica, se dará la derivación completa del algoritmo <code class="docutils literal notranslate"><span class="pre">backpropagation</span></code>.</p></li>
</ul>
<ul>
<li><p>Para la derivación detallada del algoritmo backpropagation, se adopta como ejemplo la función de pérdida del error cuadratico, es decir</p>
<div class="math notranslate nohighlight" id="equation-gradient-desc-scheme">
<span class="eqno">(37)<a class="headerlink" href="#equation-gradient-desc-scheme" title="Permalink to this equation">#</a></span>\[\begin{split}
    \\[1mm]
    J(\boldsymbol{\theta})=\sum_{n=1}^{N}J_{n}(\boldsymbol{\theta})\quad\text{y}\quad J_{n}(\boldsymbol{\theta})=\frac{1}{2}\sum_{k=1}^{k_{L}}(\hat{y}_{nk}-y_{nk})^{2},
    \end{split}\]</div>
<p>donde <span class="math notranslate nohighlight">\(\hat{y}_{nk},\quad k=1,2,\dots,k_{L}\)</span>, son las estimaciones proporcionadas en los correspondientes nodos de salida de la red. Las consideraremos como los elementos de un vector correspondiente, <span class="math notranslate nohighlight">\(\hat{\boldsymbol{y}}_{n}\)</span>.</p>
</li>
</ul>
<ul>
<li><p><strong><code class="docutils literal notranslate"><span class="pre">Cálculo</span> <span class="pre">de</span> <span class="pre">los</span> <span class="pre">gradientes</span></code></strong> Sea <span class="math notranslate nohighlight">\(z_{nj}^{r}\)</span> la salida del combinador lineal de la <span class="math notranslate nohighlight">\(j\)</span> th neurona en la capa <span class="math notranslate nohighlight">\(r\)</span> en el instante de tiempo <span class="math notranslate nohighlight">\(n\)</span>, cuando se aplica el patrón <span class="math notranslate nohighlight">\(\boldsymbol{x}_{n}\)</span> en los nodos de entrada (véase la <a class="reference internal" href="#synaptic-weights-link"><span class="std std-numref">Fig. 28</span></a>). Entonces podemos escribir</p>
<div class="math notranslate nohighlight" id="equation-eq-znj">
<span class="eqno">(38)<a class="headerlink" href="#equation-eq-znj" title="Permalink to this equation">#</a></span>\[\begin{split}
    \\[1mm]
    z_{nj}^{r}=\sum_{m=1}^{k_{r-1}}\theta_{jm}^{r}y_{nm}^{r-1}+\theta_{j0}^{r}=\sum_{m=0}^{k_{r-1}}\theta_{jm}^{r}y_{nm}^{r-1}=\boldsymbol{\theta}_{j}^{r^{T}}\boldsymbol{y}_{n}^{r-1},
    \end{split}\]</div>
<p>donde por definición</p>
<div class="math notranslate nohighlight">
\[\begin{split}
    \\[1mm]
    \boldsymbol{y}_{n}^{r-1}:=[1, y_{n1}^{r-1},\dots, y_{nk_{r-1}}^{r-1}]^{T},
    \end{split}\]</div>
<p>y <span class="math notranslate nohighlight">\(y_{n0}^{r}\equiv 1,~\forall~r, n\)</span> y <span class="math notranslate nohighlight">\(\theta_{j}^{r}\)</span> ha sido definido en la Ecuación <a class="reference internal" href="#equation-parameters-vector-def">(35)</a>.</p>
</li>
</ul>
<ul class="simple">
<li><p>Para las neuronas de la capa de salida <span class="math notranslate nohighlight">\(r=L,\quad y_{nm}^{L}=\hat{y}_{nm},\quad m=1,2,\dots, k_{L}\)</span>, y para <span class="math notranslate nohighlight">\(r=1\)</span>, tenemos <span class="math notranslate nohighlight">\(y_{nm}^{0}=x_{nm},\quad m=1,2,\dots, k_{0}\)</span>; esto es, <span class="math notranslate nohighlight">\(y_{nm}^{0}\)</span> se fijan iguales a los valores de las características de entrada.</p></li>
</ul>
<ul class="simple">
<li><p>Por lo tanto, podemos escribir ahora</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
\frac{\partial J_{n}}{\partial\boldsymbol{\theta}_{j}^{r}}=\frac{\partial J_{n}}{\partial z_{nj}^{r}}\frac{\partial z_{nj}^{r}}{\partial\boldsymbol{\theta}_{j}^{r}}=\frac{\partial J_{n}}{\partial z_{nj}^{r}}\boldsymbol{y}_{n}^{r-1}.
\]</div>
<ul class="simple">
<li><p>Definamos</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
\delta_{nj}^{r}:=\frac{\partial J_{n}}{\partial z_{nj}^{r}}.
\]</div>
<ul class="simple">
<li><p>Entonces la Ecuación <a class="reference internal" href="#equation-update-equations-gd">(36)</a> puede escribirse como</p></li>
</ul>
<div class="math notranslate nohighlight" id="equation-eq-delta-theta-jr">
<span class="eqno">(39)<a class="headerlink" href="#equation-eq-delta-theta-jr" title="Permalink to this equation">#</a></span>\[
\Delta\boldsymbol{\theta}_{j}^{r}=-\mu\sum_{n=1}^{N}\delta_{nj}^{r}\boldsymbol{y}_{n}^{r-1},\quad r=1,2,\dots,L.
\]</div>
<p><strong><code class="docutils literal notranslate"><span class="pre">Cálculo</span> <span class="pre">de</span> </code><span class="math notranslate nohighlight">\(\delta_{nj}^{r}\)</span></strong>: Este es el cálculo principal del algoritmo de <code class="docutils literal notranslate"><span class="pre">backpropagation</span></code>. Para el cálculo de los gradientes, <span class="math notranslate nohighlight">\(\delta_{nj}^{r}\)</span>, se comienza en la última capa, <span class="math notranslate nohighlight">\(r = L\)</span>, y se procede hacia atrás, hacia <span class="math notranslate nohighlight">\(r = 1\)</span>; esta “filosofía” justifica el nombre dado al algoritmo.</p>
<ol>
<li><p><span class="math notranslate nohighlight">\(r=L\)</span>: Tenemos que</p>
<div class="math notranslate nohighlight">
\[
    \delta_{nj}^{L}:=\frac{\partial J_{n}}{\partial z_{nj}^{L}}.
    \]</div>
<p>Para la función de pérdida del error al cuadrado,</p>
<div class="math notranslate nohighlight">
\[\begin{split}
    \\[1mm]
    J_{n}=\frac{1}{2}\sum_{k=1}^{k_{L}}\left(f(z_{nk}^{L})-y_{nk}\right)^{2}.
    \end{split}\]</div>
<p>Por lo tanto,</p>
<div class="math notranslate nohighlight" id="equation-eq-delta-njl">
<span class="eqno">(40)<a class="headerlink" href="#equation-eq-delta-njl" title="Permalink to this equation">#</a></span>\[
    \delta_{nj}^{L}=(\hat{y}_{nj}-y_{nj})f'(z_{nj}^{L})=e_{nj}f'(z_{nj}^{L}),\quad j=1,2,\dots, k_{L},
    \]</div>
<p>donde <span class="math notranslate nohighlight">\(f'\)</span> denota la derivada de <span class="math notranslate nohighlight">\(f\)</span> y <span class="math notranslate nohighlight">\(e_{nj}\)</span> es el error asociado con el <span class="math notranslate nohighlight">\(j\)</span> th output en el tiempo <span class="math notranslate nohighlight">\(n\)</span>. Nótese que para el último layer, el cálculo del gradiente, <span class="math notranslate nohighlight">\(\delta_{nj}^{L}\)</span> es sencillo.</p>
</li>
</ol>
<ol>
<li><p><span class="math notranslate nohighlight">\(r&lt;L\)</span>: Debido a la dependencia sucesiva entre las capas, el valor de <span class="math notranslate nohighlight">\(z_{nj}^{r-1}\)</span> influye en todos los valores <span class="math notranslate nohighlight">\(z_{nk}^{r},~k = 1, 2,\dots, k_{r}\)</span>, de la capa siguiente. Empleando la regla de la cadena para la diferenciación, obtenemos, para <span class="math notranslate nohighlight">\(r=L, L-1,\dots, 2\)</span>:</p>
<div class="math notranslate nohighlight" id="equation-partial-der-znk1">
<span class="eqno">(41)<a class="headerlink" href="#equation-partial-der-znk1" title="Permalink to this equation">#</a></span>\[\begin{split}
    \\[1mm]
    \delta_{nj}^{r-1}=\frac{\partial J_{n}}{\partial z_{nj}^{r-1}}=\sum_{k=1}^{k_{r}}\frac{\partial J_{n}}{\partial z_{nk}^{r}}\frac{\partial z_{nk}^{r}}{\partial z_{nj}^{r-1}},
    \end{split}\]</div>
<p>o</p>
<div class="math notranslate nohighlight" id="equation-partial-der-znk2">
<span class="eqno">(42)<a class="headerlink" href="#equation-partial-der-znk2" title="Permalink to this equation">#</a></span>\[
    \delta_{nj}^{r-1}=\sum_{k=1}^{k_{r}}\delta_{nk}^{r}\frac{\partial z_{nk}^{r}}{\partial z_{nj}^{r-1}}.
    \]</div>
<p>Además, usando la ecuación <a class="reference internal" href="#equation-eq-znj">(38)</a> se tiene,</p>
<div class="math notranslate nohighlight">
\[\begin{split}
    \\[1mm]
    \frac{\partial z_{nk}^{r}}{\partial z_{nj}^{r-1}}=\frac{\partial\left(\sum_{m=0}^{k_{r-1}}\theta_{km}^{r}y_{nm}^{r-1}\right)}{\partial z_{nj}^{r-1}},
    \end{split}\]</div>
<p>donde</p>
<div class="math notranslate nohighlight">
\[
    y_{nm}^{r-1}=f(z_{nm}^{r-1})=f(\boldsymbol{\theta}_{m}^{r-1^{T}}\boldsymbol{y}_{n}^{r-2})
    \]</div>
<p>que conduce a</p>
<div class="math notranslate nohighlight">
\[
    \frac{\partial z_{nk}^{r}}{\partial z_{nj}^{r-1}}=\theta_{kj}^{r}f'(z_{nj}^{r-1}),
    \]</div>
<p>y combinando las Ecuaciones <a class="reference internal" href="#equation-partial-der-znk1">(41)</a> y <a class="reference internal" href="#equation-partial-der-znk2">(42)</a>, obtenemos la regla recursiva</p>
<div class="math notranslate nohighlight">
\[\begin{split}
    \\[1mm]
    \delta_{nj}^{r-1}=\left(\sum_{k=1}^{k_{r}}\delta_{nk}^{r}\theta_{kj}^{r}\right)f'(z_{nj}^{r-1}).
    \end{split}\]</div>
</li>
</ol>
<ul>
<li><p>Manteniendo la misma notación en la Ecuación <a class="reference internal" href="#equation-eq-delta-njl">(40)</a>, definimos</p>
<div class="math notranslate nohighlight">
\[\begin{split}
    \\[1mm]
    e_{nj}^{r-1}:=\sum_{k=1}^{k_{r}}\delta_{nk}^{r}\theta_{kj}^{r},
    \end{split}\]</div>
<p>y finalmente obtenemos,</p>
<div class="math notranslate nohighlight" id="equation-eq-delta-njr-1">
<span class="eqno">(43)<a class="headerlink" href="#equation-eq-delta-njr-1" title="Permalink to this equation">#</a></span>\[
    \delta_{nj}^{r-1}=e_{nj}^{r-1}f'(z_{nj}^{r-1}).
    \]</div>
</li>
</ul>
<ul class="simple">
<li><p>El único cálculo que queda es la derivada de <span class="math notranslate nohighlight">\(f\)</span>. Para el caso de la <code class="docutils literal notranslate"><span class="pre">función</span> <span class="pre">sigmoidea</span> <span class="pre">logística</span></code> se demuestra fácilmente que es igual a</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
f'(z)=af(z)(1-f(z)).
\]</div>
<ul class="simple">
<li><p>La derivación se ha completado y el esquema <code class="docutils literal notranslate"><span class="pre">backpropagation</span> <span class="pre">neural</span> <span class="pre">network</span></code> se resume en el siguiente algoritmo</p></li>
</ul>
<div class="proof algorithm admonition" id="my_algorithm_backpropagation">
<p class="admonition-title"><span class="caption-number">Algorithm 2 </span> (Algoritmo Backpropagation Gradiente Descendiente )</p>
<section class="algorithm-content" id="proof-content">
<p><strong>Inicialización</strong></p>
<ol class="simple">
<li><p>Inicializar todos los pesos y sesgos sinápticos al azar con valores pequeños, pero no muy pequeños.</p></li>
<li><p>Seleccione el tamaño del paso <span class="math notranslate nohighlight">\(\mu\)</span>.</p></li>
<li><p>Fije <span class="math notranslate nohighlight">\(y_{nj}^{0}=x_{nj},\quad j=1,2,\dots,k_{0}:=l,\quad n=1,2,\dots,N\)</span></p></li>
</ol>
<p><strong>Repeat</strong> Cada repetición completa un <code class="docutils literal notranslate"><span class="pre">epoch</span></code></p>
<ol>
<li><p><strong>For</strong> <span class="math notranslate nohighlight">\(n=1,2,\dots,N\)</span> <strong>Do</strong></p>
<ol>
<li><p><strong>For</strong> <span class="math notranslate nohighlight">\(r=1,2,\dots,L\)</span> <strong>Do</strong> Cálculo <code class="docutils literal notranslate"><span class="pre">Forward</span></code></p>
<ol>
<li><p><strong>For</strong> <span class="math notranslate nohighlight">\(j=1,2,\dots,k_{r}\)</span> <strong>Do</strong></p>
<p>Calcule <span class="math notranslate nohighlight">\(z_{nj}^{r}\)</span> a partir de la Ecuación <a class="reference internal" href="#equation-eq-znj">(38)</a>
Calcule <span class="math notranslate nohighlight">\(y_{nj}^{r}=f(z_{nj}^{r})\)</span></p>
</li>
<li><p><strong>End For</strong></p></li>
</ol>
</li>
<li><p><strong>End For</strong></p></li>
<li><p><strong>For</strong> <span class="math notranslate nohighlight">\(j = 1, 2,\dots, k_{L}\)</span>, <strong>Do</strong>; Cálculo <code class="docutils literal notranslate"><span class="pre">Backward</span></code> (<code class="docutils literal notranslate"><span class="pre">output</span> <span class="pre">layer</span></code>)</p>
<p>Calcule <span class="math notranslate nohighlight">\(\delta_{nj}^{L}\)</span> a partir de la Ecuación <a class="reference internal" href="#equation-eq-delta-njr-1">(43)</a></p>
</li>
<li><p><strong>End For</strong></p></li>
<li><p><strong>For</strong> <span class="math notranslate nohighlight">\(r=L, L-1,\dots, 2\)</span>, <strong>Do</strong>; Cálculo <code class="docutils literal notranslate"><span class="pre">Backward</span></code> (<code class="docutils literal notranslate"><span class="pre">hidden</span> <span class="pre">layers</span></code>)</p>
<ol>
<li><p><strong>For</strong> <span class="math notranslate nohighlight">\(j=1,2,\dots, k_{r}\)</span>, <strong>Do</strong></p>
<p>Calcule <span class="math notranslate nohighlight">\(\delta_{nj}^{r-1}\)</span> a partir de la Ecuación <a class="reference internal" href="#equation-eq-delta-njr-1">(43)</a></p>
</li>
<li><p><strong>End For</strong></p></li>
</ol>
</li>
<li><p><strong>End For</strong></p></li>
</ol>
</li>
<li><p><strong>End For</strong></p></li>
<li><p><strong>For</strong> <span class="math notranslate nohighlight">\(r=1,2,\dots,L\)</span>, <strong>Do</strong>: Actualice los pesos</p>
<ol>
<li><p><strong>For</strong> <span class="math notranslate nohighlight">\(j=1,2,\dots,k_{r}\)</span>, <strong>Do</strong></p>
<p>Calcule <span class="math notranslate nohighlight">\(\Delta\boldsymbol{\theta}_{j}^{r}\)</span> a partir de la Ecuación <a class="reference internal" href="#equation-eq-delta-theta-jr">(39)</a></p>
<p><span class="math notranslate nohighlight">\(\boldsymbol{\theta}_{j}^{r}=\boldsymbol{\theta}_{j}^{r}+\Delta\boldsymbol{\theta}_{j}^{r}\)</span></p>
</li>
<li><p><strong>End For</strong></p></li>
</ol>
</li>
<li><p><strong>End For</strong></p></li>
<li><p><strong>Until</strong> Un criterio de parada se cumpla.</p></li>
</ol>
</section>
</div><ul class="simple">
<li><p>El algoritmo de <code class="docutils literal notranslate"><span class="pre">backpropagation</span></code> puede reivindicar una serie de padres. La popularización del algoritmo se asocia con el artículo clásico <span id="id16">[<a class="reference internal" href="#id39" title="David E Rumelhart, Geoffrey E Hinton, and Ronald J Williams. Learning representations by back-propagating errors. nature, 323(6088):533–536, 1986.">Rumelhart <em>et al.</em>, 1986</a>]</span>, donde se proporciona la derivación del algoritmo. La idea de <code class="docutils literal notranslate"><span class="pre">backpropagation</span></code> también aparece en <span id="id17">[<a class="reference internal" href="#id40" title="Arthur E Bryson Jr, Walter F Denham, and Stewart E Dreyfus. Optimal programming problems with inequality constraints. AIAA journal, 1(11):2544–2550, 1963.">Bryson Jr <em>et al.</em>, 1963</a>]</span> en el contexto del control óptimo.</p></li>
<li><p>Existen diferentes variaciones del algoritmo <code class="docutils literal notranslate"><span class="pre">backpropagation</span></code>, tales como: <code class="docutils literal notranslate"><span class="pre">Gradiende</span> <span class="pre">descendiente</span> <span class="pre">con</span> <span class="pre">término</span> <span class="pre">de</span> <span class="pre">momento,</span> <span class="pre">Algoritmo</span> <span class="pre">de</span> <span class="pre">momentos</span> <span class="pre">de</span> <span class="pre">Nesterov's,</span> <span class="pre">Algoritmo</span> <span class="pre">AdaGrad,</span> <span class="pre">RMSProp</span> <span class="pre">con</span> <span class="pre">momento</span> <span class="pre">de</span> <span class="pre">Nesterov,</span> <span class="pre">Algortimo</span> <span class="pre">de</span> <span class="pre">estimación</span> <span class="pre">de</span> <span class="pre">momentos</span> <span class="pre">adaptativo</span></code> los cuales pueden ser utlizados para resolver la tarea de optimización (ver <span id="id18">[<a class="reference internal" href="#id35" title="S. Theodoridis. Machine Learning: A Bayesian and Optimization Perspective. Elsevier Science, 2020. ISBN 9780128188040. URL: https://books.google.com.co/books?id=l-nEDwAAQBAJ.">Theodoridis, 2020</a>]</span>).</p></li>
</ul>
</section>
</section>
<section id="apendice">
<h2>Apéndice<a class="headerlink" href="#apendice" title="Permalink to this headline">#</a></h2>
<ul class="simple">
<li><p>En este apéndice, resumimos algunas definiciones y teoremas básicos sobre los <code class="docutils literal notranslate"><span class="pre">espacios</span> <span class="pre">de</span> <span class="pre">Hilbert</span></code> y el <code class="docutils literal notranslate"><span class="pre">análisis</span> <span class="pre">convexo</span></code>. No se proporcionan pruebas, el lector interesado puede consultar libros más especializados, que se indican en las referencias.</p></li>
</ul>
<div class="proof definition admonition" id="def_linear_spaces">
<p class="admonition-title"><span class="caption-number">Definition 7 </span> (Espacios lineales)</p>
<section class="definition-content" id="proof-content">
<p>Un conjunto no vacío de elementos, <span class="math notranslate nohighlight">\(V\)</span>, se llama espacio lineal si hay definidas dos operaciones, adición y multiplicación escalar, de modo que se cumplen las siguientes propiedades:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\boldsymbol{x}+\boldsymbol{y}=\boldsymbol{y}+\boldsymbol{x},\quad\forall\,\boldsymbol{x},\boldsymbol{y}\in V\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\((\boldsymbol{x}+\boldsymbol{y})+\boldsymbol{z}=\boldsymbol{x}+(\boldsymbol{y}+\boldsymbol{z}),\quad\forall~\boldsymbol{x}, \boldsymbol{y}, \boldsymbol{z}\in V\)</span></p></li>
<li><p>Existe un elemento <span class="math notranslate nohighlight">\(\boldsymbol{0}\in V\)</span>, conocido como el vector cero, tal que, <span class="math notranslate nohighlight">\(\forall\boldsymbol{x}\in V,~\boldsymbol{x}+\boldsymbol{0}=\boldsymbol{x}\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(\forall~x\in V\)</span>, existe un <span class="math notranslate nohighlight">\(\boldsymbol{y}\in V\)</span> tal que <span class="math notranslate nohighlight">\(\boldsymbol{x}+\boldsymbol{y}=0\)</span>.</p></li>
<li><p>Para cada par de escalares <span class="math notranslate nohighlight">\(\alpha, \beta\in\mathbb{C}\)</span> y <span class="math notranslate nohighlight">\(\forall~\boldsymbol{x},\boldsymbol{y}\in V\)</span>,</p></li>
</ul>
<div class="math notranslate nohighlight">
\[(\alpha\beta)\boldsymbol{x}=\alpha(\beta\boldsymbol{x})\quad\text{y}\quad\alpha(\boldsymbol{x}+\boldsymbol{y})=\alpha\boldsymbol{x}+\alpha\boldsymbol{y}.\]</div>
<ul class="simple">
<li><p>Para cada par de escalares <span class="math notranslate nohighlight">\(\alpha,\beta\in\mathbb{C},~\forall~\boldsymbol{x}\in V,\quad (\alpha+\beta)\boldsymbol{x}=\alpha\boldsymbol{x}+\beta\boldsymbol{x}\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(\forall\boldsymbol{x}\in V\)</span>, y el escalar <span class="math notranslate nohighlight">\(1\in\mathbb{C},\quad 1\boldsymbol{x}=\boldsymbol{x}\)</span></p></li>
</ul>
</section>
</div><ul class="simple">
<li><p>Los espacios lineales se denominan a veces espacios vectoriales y los elementos de <span class="math notranslate nohighlight">\(V\)</span> vectores. Si los escalares <span class="math notranslate nohighlight">\(\alpha, \beta\)</span> están restringidos en <span class="math notranslate nohighlight">\(\mathbb{R}\)</span>, entonces el espacio lineal se conoce como espacio lineal real; de lo contrario, si <span class="math notranslate nohighlight">\(\alpha, \beta \in\mathbb{C}\)</span>, el espacio lineal se conoce como espacio lineal complejo.</p></li>
</ul>
<div class="proof example admonition" id="ej_vector_space">
<p class="admonition-title"><span class="caption-number">Example 3 </span> (El espacio vectorial <span class="math notranslate nohighlight">\(\mathbb{R}^{l}\)</span>)</p>
<section class="example-content" id="proof-content">
<p>El conjunto de <span class="math notranslate nohighlight">\(l-\)</span>tuplas <span class="math notranslate nohighlight">\(\boldsymbol{x}:=(x_{1}, x_{2},\dots, x_{l}),~x_{i}\in\mathbb{R},~i=1,2,\dots,l\)</span>, es un espacio vectorial real, donde la adición y la multiplicación están definidas como</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{align}
\boldsymbol{x}+\boldsymbol{y}&amp;=(x_{1}+y_{1}, x_{2}+y_{2},\dots,x_{l}+y_{l})\\
a\boldsymbol{x}&amp;=(ax_{1}, ax_{2},\dots, ax_{l}),\quad a\in\mathbb{R}.
\end{align}\end{split}\]</div>
</section>
</div><div class="proof example admonition" id="ej_real_functions">
<p class="admonition-title"><span class="caption-number">Example 4 </span></p>
<section class="example-content" id="proof-content">
<p>Sea el conjunto de todas las funciones reales</p>
<div class="math notranslate nohighlight">
\[\mathcal{F}=\{\boldsymbol{f}:=f(x) | f:\mathbb{R}\longrightarrow\mathbb{R}\},\]</div>
<p>donde <span class="math notranslate nohighlight">\(\boldsymbol{f}\)</span> denota la función general, en vez de la evaluación en un punto especifico <span class="math notranslate nohighlight">\(x\in\mathbb{R}\)</span>. Entonces <span class="math notranslate nohighlight">\(\mathcal{F}(\mathbb{R})\)</span> es un espacio lineal real con respecto a las siguientes operaciones</p>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{align}
(\boldsymbol{f}+\boldsymbol{h})(x)&amp;=f(x)+h(x),\quad\forall~\boldsymbol{f},\boldsymbol{g}\in\mathcal{F}(\mathbb{R}),\\
(a\boldsymbol{f})(x)&amp;=af(x),\quad\forall~\boldsymbol{f}\in\mathcal{F}(\mathbb{R}),~a\in\mathbb{R}.
\end{align}\end{split}\]</div>
</section>
</div><div class="proof definition admonition" id="def_subspace">
<p class="admonition-title"><span class="caption-number">Definition 8 </span></p>
<section class="definition-content" id="proof-content">
<p>Sea <span class="math notranslate nohighlight">\(V\)</span> un espacio lineal y <span class="math notranslate nohighlight">\(S\)</span> un conjunto no vacio, <span class="math notranslate nohighlight">\(S\subseteq V\)</span>. Entonces <span class="math notranslate nohighlight">\(S\)</span> es llamado un subespacio de <span class="math notranslate nohighlight">\(V\)</span> si</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\forall\boldsymbol{x}, \boldsymbol{y}\in S,\quad \boldsymbol{x}+\boldsymbol{y}\in S\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(\forall a\in\mathbb{C}\)</span>, y <span class="math notranslate nohighlight">\(\boldsymbol{x}\in S,~a\boldsymbol{x}\in S\)</span></p></li>
</ul>
</section>
</div><div class="proof definition admonition" id="def_linear_ind">
<p class="admonition-title"><span class="caption-number">Definition 9 </span> (Independencia Lineal)</p>
<section class="definition-content" id="proof-content">
<p>Sea <span class="math notranslate nohighlight">\(V\)</span> un subespacio lineal y <span class="math notranslate nohighlight">\(S\subseteq V\)</span>. Decimo que <span class="math notranslate nohighlight">\(S\)</span> es <strong>linealmente independiente</strong> si existe un número finito de elementos distintos, <span class="math notranslate nohighlight">\(x_{k}\in S,~i=1,2,\dots,K\)</span>, tal que</p>
<div class="math notranslate nohighlight">
\[\sum_{k=1}^{K}a_{k}\boldsymbol{x}_{k}=\boldsymbol{0}\]</div>
<p>para alguna combinación de escalares <span class="math notranslate nohighlight">\(a_{k}\in\mathbb{C},~k=1,2,\dots,K\)</span>, los cuales no son todos ceros. Si este no es el caso, el conjunto <span class="math notranslate nohighlight">\(S\)</span> es <strong>linealmente independiente</strong></p>
</section>
</div><div class="proof definition admonition" id="def_generado">
<p class="admonition-title"><span class="caption-number">Definition 10 </span> (Subespacio generado)</p>
<section class="definition-content" id="proof-content">
<p>Sea <span class="math notranslate nohighlight">\(S\)</span> un subconjunto no vacio <span class="math notranslate nohighlight">\(S\subseteq V\)</span>. El conjunto de todas las combinaciones lineales posibles, denotado como <span class="math notranslate nohighlight">\(\text{span}\{S\}\)</span>,</p>
<div class="math notranslate nohighlight">
\[
\text{span}\{S\}=\left\{\boldsymbol{x}:~\boldsymbol{x}=\sum_{i=1}^{K}a_{k}\boldsymbol{x}_{k}|x_{k}\in S,~K\in\mathbb{N}\right\}
\]</div>
<p>y es conocido como el <span class="math notranslate nohighlight">\(\textbf{generado}\)</span> de <span class="math notranslate nohighlight">\(S\)</span>. Note que <span class="math notranslate nohighlight">\(\text{span}\{S\}\)</span> es siempre un subespacio de <span class="math notranslate nohighlight">\(V\)</span>. Además si <span class="math notranslate nohighlight">\(\text{span}\{S\}=V\)</span>, decimos que <span class="math notranslate nohighlight">\(S\)</span> genera al espacio <span class="math notranslate nohighlight">\(V\)</span>.</p>
</section>
</div><div class="proof definition admonition" id="def_bases">
<p class="admonition-title"><span class="caption-number">Definition 11 </span> (Bases)</p>
<section class="definition-content" id="proof-content">
<p>Sea <span class="math notranslate nohighlight">\(V\)</span> un subespacio lineal y <span class="math notranslate nohighlight">\(S\subseteq V\)</span>. El conjunto <span class="math notranslate nohighlight">\(S\)</span> es conocido como <strong>base</strong> de <span class="math notranslate nohighlight">\(V\)</span>, si y solo si:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(S\)</span> es linealmente independiente</p></li>
<li><p><span class="math notranslate nohighlight">\(S\)</span> genera a <span class="math notranslate nohighlight">\(V\)</span></p></li>
</ul>
</section>
</div><p>Si el número de elementos que componen <span class="math notranslate nohighlight">\(S\)</span> es finito, decimos que <span class="math notranslate nohighlight">\(V\)</span> es de dimensión finita y el número de elementos distintos de S define la dimensión de <span class="math notranslate nohighlight">\(V\)</span>. Si el número de elementos de <span class="math notranslate nohighlight">\(S\)</span> no es finito, decimos que <span class="math notranslate nohighlight">\(V\)</span> es de dimensión infinita. Nótese que no hay una base única en <span class="math notranslate nohighlight">\(V\)</span>. Sin embargo, cualquier base de <span class="math notranslate nohighlight">\(V\)</span> tiene el mismo número de elementos. Además, se ha demostrado que todo espacio lineal tiene una base. Esto se conoce como como el <code class="docutils literal notranslate"><span class="pre">Lema</span> <span class="pre">de</span> <span class="pre">Zorn</span></code>. Sin embargo, encontrar una base no es necesariamente una tarea trivial. La dimensión de <span class="math notranslate nohighlight">\(\mathbb{R}^{l}\)</span> es <span class="math notranslate nohighlight">\(l\)</span>, y el espacio lineal <span class="math notranslate nohighlight">\(\mathcal{F}(\mathbb{R})\)</span> es de dimensión infinita.</p>
<div class="proof definition admonition" id="def_prod_interno">
<p class="admonition-title"><span class="caption-number">Definition 12 </span> (Espacio con producto interno)</p>
<section class="definition-content" id="proof-content">
<p>Sea <span class="math notranslate nohighlight">\(V\)</span> un espacio lineal. El producto interno es una función</p>
<div class="math notranslate nohighlight">
\[f:V\times V\longmapsto\mathbb{C}\]</div>
<p>la cual asigna un valor en <span class="math notranslate nohighlight">\(\mathbb{C}\)</span>, denotado <span class="math notranslate nohighlight">\(\langle\boldsymbol{x}, \boldsymbol{y}\rangle\)</span>, para cada punto de elementos <span class="math notranslate nohighlight">\(\boldsymbol{x}, \boldsymbol{y}\in V\)</span>, con las siguientes propiedades:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\langle\boldsymbol{x}, \boldsymbol{y}\rangle\geq0\)</span>, y <span class="math notranslate nohighlight">\(\langle\boldsymbol{x}, \boldsymbol{y}\rangle=0\)</span> si y solo si <span class="math notranslate nohighlight">\(\boldsymbol{x}=0\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(\langle\boldsymbol{x}+\boldsymbol{y}, \boldsymbol{z}\rangle=\langle\boldsymbol{x}, \boldsymbol{z}\rangle+\langle\boldsymbol{y}, \boldsymbol{z}\rangle\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(\langle a\boldsymbol{x}, \boldsymbol{y}\rangle=a\langle\boldsymbol{x}, \boldsymbol{y}\rangle\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(\langle\boldsymbol{x}, \boldsymbol{y}\rangle=\langle\boldsymbol{y}, \boldsymbol{x}\rangle^{\star}\)</span></p></li>
</ul>
<p>donde <span class="math notranslate nohighlight">\(\star\)</span> denota la conjugación compleja. Un espacio donde un producto interno a sido definido es conocido como un <strong>espacio con producto interno</strong>.</p>
</section>
</div><div class="proof definition admonition" id="ej_inner_prod">
<p class="admonition-title"><span class="caption-number">Definition 13 </span></p>
<section class="definition-content" id="proof-content">
<p>Consideremos el espacio vectorial <span class="math notranslate nohighlight">\(\mathbb{C}^{l}\)</span>. Entonces la operación</p>
<div class="math notranslate nohighlight">
\[\langle\boldsymbol{x}, \boldsymbol{y}\rangle:=\sum_{i=1}^{l}x_{i}y_{i}^{\star}=\boldsymbol{y}^{H}\boldsymbol{x},\]</div>
<p>es un producto interno con <span class="math notranslate nohighlight">\(\boldsymbol{x}, \boldsymbol{y}\in\mathbb{C}^{l}\)</span>.</p>
</section>
</div><div class="proof definition admonition" id="def_norm_spaces">
<p class="admonition-title"><span class="caption-number">Definition 14 </span> (Norma y espacios normados)</p>
<section class="definition-content" id="proof-content">
<p>Sea <span class="math notranslate nohighlight">\(V\)</span> un espacio lineal. Una norma es una función</p>
<div class="math notranslate nohighlight">
\[f:V\longmapsto[0,\infty),\]</div>
<p>que asigna un número real positivo a cada <span class="math notranslate nohighlight">\(\boldsymbol{x}\in V\)</span>, esta es denotada como <span class="math notranslate nohighlight">\(\|\boldsymbol{x}\|\)</span> y tiene las siguientes propiedades</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\|\boldsymbol{x}\|\geq0,\quad\)</span> <span class="math notranslate nohighlight">\(\|\boldsymbol{x}\|=0\quad\text{sii}\quad\boldsymbol{x}=\boldsymbol{0}\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(\|a\boldsymbol{x}\|=|a|\|\boldsymbol{x}\|,\quad\forall a\in\mathbb{C},\quad\text{y}\quad\boldsymbol{x}\in V\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(\|\boldsymbol{x}+\boldsymbol{y}\|\leq\|\boldsymbol{x}\|+\|\boldsymbol{y}\|,\quad\forall\boldsymbol{x}, \boldsymbol{y}\in V\)</span>.</p></li>
</ul>
</section>
</div><p>Dado un espacio lineal, podemos definir diferentes normas. Por ejemplo, el espacio vectorial <span class="math notranslate nohighlight">\(\mathbb{C}^{l}\)</span>. Entonces definimos la norma <span class="math notranslate nohighlight">\(l_{p}\)</span> como</p>
<div class="math notranslate nohighlight">
\[
\|\boldsymbol{x}\|_{p}=\left(\sum_{i=1}^{l}|x_{i}|^{p}\right)^{1/p},\quad p\geq1
\]</div>
<p>Se puede demostrar que la definición anterior cumple con todas las propiedades requeridas para que una función sea una norma. Para <span class="math notranslate nohighlight">\(p = 1\)</span>, nos referimos a la norma <span class="math notranslate nohighlight">\(l_{1}\)</span> y para <span class="math notranslate nohighlight">\(p = 2\)</span> se conoce como \textbf{norma euclidiana} o norma <span class="math notranslate nohighlight">\(l_{2}\)</span>. Nótese que esta última resulta de la operación de producto interior, es decir,</p>
<div class="math notranslate nohighlight" id="equation-eucl-norm">
<span class="eqno">(44)<a class="headerlink" href="#equation-eucl-norm" title="Permalink to this equation">#</a></span>\[
\|\boldsymbol{x}\|_{2}=\sqrt{\boldsymbol{x}^{H}\boldsymbol{x}}.
\]</div>
<p>Esto es válido para cualquier espacio lineal de producto interno. Es decir, dado un espacio lineal con producto interno, <span class="math notranslate nohighlight">\(V\)</span>, con <span class="math notranslate nohighlight">\(\langle\cdot,\cdot\rangle\)</span>, entonces la operación de producto interior induce una norma, es decir</p>
<div class="math notranslate nohighlight">
\[
\|\boldsymbol{x}\|=\langle\boldsymbol{x}, \boldsymbol{x}\rangle,\quad\boldsymbol{x}\in V.
\]</div>
<div class="proof theorem admonition" id="theorem-30">
<p class="admonition-title"><span class="caption-number">Theorem 5 </span> (Desigualdad de Cauchy-Schwarz)</p>
<section class="theorem-content" id="proof-content">
<p>Sea <span class="math notranslate nohighlight">\(V\)</span> un espacio de producto interno y el reproductor por la norma del producto interior. Entonces</p>
<div class="math notranslate nohighlight">
\[|\langle\boldsymbol{x}, \boldsymbol{y}\rangle|\leq\|\boldsymbol{x}\|\boldsymbol{y}\|,\quad\boldsymbol{x}, \boldsymbol{y}\in V:\quad\text{Desigualdad de Cauchy-Schwarz}.\]</div>
<p>Esta es una de las propiedades más fundamentales e importantes en la teoría de los espacios lineales. Una consecuencia directa de la desigualdad de Cauchy-Schwarz son las siguientes propiedades: Dado un espacio vectorial interior y su norma inducida <span class="math notranslate nohighlight">\(\|\boldsymbol{x}\|\)</span>, entonces</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\left|\|\boldsymbol{x}\|-\|\boldsymbol{y}\|\right|\leq\|\boldsymbol{x}-\boldsymbol{y}\|\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(\|\boldsymbol{x}+\boldsymbol{y}\|^{2}+\|\boldsymbol{x}-\boldsymbol{y}\|=2\left(\|\boldsymbol{x}\|^{2}+\|\boldsymbol{y}\|^{2}\right)\)</span>.</p></li>
</ul>
<p>Esta última se conoce como la ley del paralelogramo. Nótese que, todas estas propiedades, que pueden conocerse a partir de la geometría básica, son válidas para cualquier espacio lineal, incluso para los de dimensión infinita.</p>
</section>
</div><div class="proof example admonition" id="de_l2_space">
<p class="admonition-title"><span class="caption-number">Example 5 </span> (El espacio <span class="math notranslate nohighlight">\(l^{2}\)</span>)</p>
<section class="example-content" id="proof-content">
<p>Este es el espacio lineal de todas las sucesiones</p>
<div class="math notranslate nohighlight">
\[\boldsymbol{x}=(x_{1}, x_{2},\dots,x_{n},\dots),\]</div>
<p>con producto interno</p>
<div class="math notranslate nohighlight">
\[\langle\boldsymbol{x}, \boldsymbol{y}\rangle=\sum_{n=1}^{\infty}x_{n}y_{n}^{\star},\]</div>
<p>el cual induce la norma que satisface la siguiente propiedad</p>
<div class="math notranslate nohighlight">
\[\|\boldsymbol{x}\|:=\sqrt{\sum_{n=1}^{\infty}|x_{n}|^{2}}&lt;\infty\]</div>
</section>
</div><div class="proof example admonition" id="def_L2_space">
<p class="admonition-title"><span class="caption-number">Example 6 </span> (El espacio <span class="math notranslate nohighlight">\(L^{2}\)</span>)</p>
<section class="example-content" id="proof-content">
<p>Este es el espacio lineal de todas las funciones integrables</p>
<div class="math notranslate nohighlight">
\[f:\mathbb{R}\mapsto\mathbb{R},\]</div>
<p>con producto interno</p>
<div class="math notranslate nohighlight">
\[\langle\boldsymbol{f}, \boldsymbol{h}\rangle:=\int_{-\infty}^{\infty}f(x)h(x)dx,\]</div>
<p>el cual induce la norma que satisface la propiedad</p>
<div class="math notranslate nohighlight">
\[\|\boldsymbol{f}\|:=\sqrt{\int_{-\infty}^{\infty}|f(x)|^{2}dx}&lt;+\infty.\]</div>
</section>
</div><div class="proof definition admonition" id="def_complete_spaces">
<p class="admonition-title"><span class="caption-number">Definition 15 </span> (Convergencia, Sucesiones de Cauchy y Espacios Completos)</p>
<section class="definition-content" id="proof-content">
<p>Sea <span class="math notranslate nohighlight">\(V\)</span> un espacio lineal normado y sea <span class="math notranslate nohighlight">\(\boldsymbol{x}_{1}, \boldsymbol{x}_{2},\dots,\boldsymbol{x}_{n},\dots\)</span> una sucesión de elementos en <span class="math notranslate nohighlight">\(V\)</span>. Decimos que la sucesión converge a <span class="math notranslate nohighlight">\(\boldsymbol{x}\)</span> si</p>
<div class="math notranslate nohighlight">
\[\lim_{n\rightarrow\infty}\|\boldsymbol{x}_{n}-\boldsymbol{x}\|=0.\]</div>
<p>Nótese que si <span class="math notranslate nohighlight">\(\boldsymbol{x}\)</span> existe, este es único y es conocido como el límite de <span class="math notranslate nohighlight">\(\boldsymbol{x}_{n}\)</span>.</p>
<p>Una sucesión de elementos en un espacio lineal normado <span class="math notranslate nohighlight">\(V\)</span> es llamada una <strong>sucesión de Cauchy</strong> si esta satisface</p>
<div class="math notranslate nohighlight">
\[\lim_{n, m\rightarrow\infty}\|\boldsymbol{x}_{n}-\boldsymbol{x}_{m}\|=0.\]</div>
<p>En otras palabras, la norma de la diferencia de cualquier par de elementos en la sucesión tiende a cero. Se puede demostrar que toda sucesión convergente es de Cauchy, el sentido contrario de esta afirmación no siempre es cierto.</p>
<p>Un espacio lineal normado <span class="math notranslate nohighlight">\(V\)</span>, en el que cada sucesión de Cauchy converge en <span class="math notranslate nohighlight">\(V\)</span> se dice que es <strong>completo</strong>. Nótese que cualquier espacio lineal de dimensión finita es completo. Sin embargo, esto no es siempre verdadero para espacios de dimensión infinita.</p>
</section>
</div><div class="proof definition admonition" id="def_hilbert_space">
<p class="admonition-title"><span class="caption-number">Definition 16 </span> (Espacios de Hilbert)</p>
<section class="definition-content" id="proof-content">
<p>Un espacio con producto interno, el cual es completo con respecto a la norma inducida por el producto interno es llamado un <strong>espacio de Hilbert</strong>.</p>
</section>
</div><p>Ejemplos de espacios de Hilbert son <span class="math notranslate nohighlight">\(l^{2}\)</span> y <span class="math notranslate nohighlight">\(L^{2}\)</span>. También los espacios vectoriales <span class="math notranslate nohighlight">\(\mathbb{C}^{l}\)</span> y <span class="math notranslate nohighlight">\(\mathbb{R}^{l}\)</span>, equipados con la operación de producto interno <a class="reference internal" href="#ej_inner_prod">Definition 13</a> y la norma Euclideana definida por <a class="reference internal" href="#equation-eucl-norm">(44)</a>, conocidos como espacios Euclidianos son casos especiales de espacios de Hilbert de dimensión finita. Los espacios <span class="math notranslate nohighlight">\(l^{2}\)</span> y <span class="math notranslate nohighlight">\(L^{2}\)</span> son de dimensión infinita. Nótese que <span class="math notranslate nohighlight">\(\mathbb{C}^{l}\)</span>, equipado con la norma <span class="math notranslate nohighlight">\(l_{p},~ p\neq2\)</span>, no es un espacio de Hilbert, debido a que esta norma no es inducida por un producto interno.</p>
<div class="proof definition admonition" id="def_closed_subspace">
<p class="admonition-title"><span class="caption-number">Definition 17 </span> (Subsespacio cerrado)</p>
<section class="definition-content" id="proof-content">
<p>Sea <span class="math notranslate nohighlight">\(H\)</span> un espacio de Hilbert y <span class="math notranslate nohighlight">\(S\subseteq H\)</span>. Decimos que <span class="math notranslate nohighlight">\(S\)</span> es un subespacio cerrado de <span class="math notranslate nohighlight">\(H\)</span>, si para toda <span class="math notranslate nohighlight">\(\{x_{n}\}\subseteq S\)</span>, esto es, cualquier sucesión de elementos de <span class="math notranslate nohighlight">\(S\)</span>, que converge a un elemento <span class="math notranslate nohighlight">\(x\in H\)</span>, se tiene que <span class="math notranslate nohighlight">\(x\in S\)</span>.</p>
</section>
</div><div class="proof theorem admonition" id="th_closed_span">
<p class="admonition-title"><span class="caption-number">Theorem 6 </span></p>
<section class="theorem-content" id="proof-content">
<p>Sea <span class="math notranslate nohighlight">\(H\)</span> un espacio de Hilbert y <span class="math notranslate nohighlight">\(\varphi_{1}, \varphi_{2},\dots, \varphi_{m}\in H\)</span> donde <span class="math notranslate nohighlight">\(m&lt;\infty\)</span>. Entonces el espacio lineal generado <span class="math notranslate nohighlight">\(\text{span}\{\varphi_{1}, \varphi_{2},\dots, \varphi_{m}\}\)</span> es un subespacio cerrado de <span class="math notranslate nohighlight">\(H\)</span>.</p>
</section>
</div><div class="proof definition admonition" id="definition-37">
<p class="admonition-title"><span class="caption-number">Definition 18 </span></p>
<section class="definition-content" id="proof-content">
<p>Sea <span class="math notranslate nohighlight">\(A\)</span> un subconjunto no vacio de un espacio de Hilbert <span class="math notranslate nohighlight">\(H\)</span>. Entonces, el conjunto de todos los vectores ortogonales a <span class="math notranslate nohighlight">\(A\)</span>, dentoado por <span class="math notranslate nohighlight">\(A^{\perp}\)</span>, es llamado el complemento ortogonal de <span class="math notranslate nohighlight">\(A\)</span> y se define de las siguiente manera</p>
<div class="math notranslate nohighlight">
\[
A^{\perp}=\{x\in H:~\langle x, y\rangle=0,~\forall~y\in A\}.
\]</div>
</section>
</div><div class="proof theorem admonition" id="th_proy_ort">
<p class="admonition-title"><span class="caption-number">Theorem 7 </span> (Descomposición ortogonal)</p>
<section class="theorem-content" id="proof-content">
<p>Si <span class="math notranslate nohighlight">\(M\)</span> es un subespacio cerrado de un espacio de Hilbert <span class="math notranslate nohighlight">\(H\)</span>, entonces</p>
<div class="math notranslate nohighlight">
\[
H=M\oplus M^{T}.
\]</div>
</section>
</div></section>
<section id="bibliografia">
<h2>Bibliografía<a class="headerlink" href="#bibliografia" title="Permalink to this headline">#</a></h2>
<div class="docutils container" id="id19">
<dl class="citation">
<dt class="label" id="id38"><span class="brackets"><a class="fn-backref" href="#id1">1</a></span></dt>
<dd><p>S. Konishi. <em>Introduction to Multivariate Analysis: Linear and Nonlinear Modeling</em>. Chapman &amp; Hall/CRC Texts in Statistical Science. Taylor &amp; Francis, 2014. ISBN 9781466567283. URL: <a class="reference external" href="https://books.google.com.co/books?id=fcuuAwAAQBAJ">https://books.google.com.co/books?id=fcuuAwAAQBAJ</a>.</p>
</dd>
<dt class="label" id="id20"><span class="brackets"><a class="fn-backref" href="#id3">2</a></span></dt>
<dd><p>L Breiman, J Friedman, R Olshen, and C Stone. Cart. <em>Classification and Regression Trees</em>, 1984.</p>
</dd>
<dt class="label" id="id21"><span class="brackets"><a class="fn-backref" href="#id3">3</a></span></dt>
<dd><p>Brian D Ripley. <em>Pattern recognition and neural networks</em>. Cambridge university press, 2007.</p>
</dd>
<dt class="label" id="id22"><span class="brackets"><a class="fn-backref" href="#id4">4</a></span></dt>
<dd><p>Leo Breiman. Bagging predictors. <em>Machine learning</em>, 24(2):123–140, 1996.</p>
</dd>
<dt class="label" id="id23"><span class="brackets"><a class="fn-backref" href="#id5">5</a></span></dt>
<dd><p>Leo Breiman. Random forests. <em>Machine learning</em>, 45(1):5–32, 2001.</p>
</dd>
<dt class="label" id="id24"><span class="brackets"><a class="fn-backref" href="#id6">6</a></span></dt>
<dd><p>Jamie Shotton, Andrew Fitzgibbon, Mat Cook, Toby Sharp, Mark Finocchio, Richard Moore, Alex Kipman, and Andrew Blake. Real-time human pose recognition in parts from single depth images. In <em>CVPR 2011</em>, 1297–1304. Ieee, 2011.</p>
</dd>
<dt class="label" id="id25"><span class="brackets"><a class="fn-backref" href="#id7">7</a></span></dt>
<dd><p>Hugh A Chipman, Edward I George, and Robert E McCulloch. Bart: bayesian additive regression trees. <em>The Annals of Applied Statistics</em>, 4(1):266–298, 2010.</p>
</dd>
<dt class="label" id="id26"><span class="brackets"><a class="fn-backref" href="#id7">8</a></span></dt>
<dd><p>Yuhong Wu, Håkon Tjelmeland, and Mike West. Bayesian cart: prior specification and posterior simulation. <em>Journal of Computational and Graphical Statistics</em>, 16(1):44–66, 2007.</p>
</dd>
<dt class="label" id="id27"><span class="brackets"><a class="fn-backref" href="#id8">9</a></span></dt>
<dd><p>Anil K Jain, Robert P. W. Duin, and Jianchang Mao. Statistical pattern recognition: a review. <em>IEEE Transactions on pattern analysis and machine intelligence</em>, 22(1):4–37, 2000.</p>
</dd>
<dt class="label" id="id30"><span class="brackets"><a class="fn-backref" href="#id9">10</a></span></dt>
<dd><p>Thomas Hofmann, Bernhard Schölkopf, and Alexander J Smola. Kernel methods in machine learning. <em>The annals of statistics</em>, 36(3):1171–1220, 2008.</p>
</dd>
<dt class="label" id="id31"><span class="brackets"><a class="fn-backref" href="#id9">11</a></span></dt>
<dd><p>John Shawe-Taylor, Nello Cristianini, and others. <em>Kernel methods for pattern analysis</em>. Cambridge university press, 2004.</p>
</dd>
<dt class="label" id="id32"><span class="brackets"><a class="fn-backref" href="#id9">12</a></span></dt>
<dd><p>Konstantinos Slavakis, Pantelis Bouboulis, and Sergios Theodoridis. Online learning in reproducing kernel hilbert spaces. In <em>Academic Press Library in Signal Processing</em>, volume 1, pages 883–987. Elsevier, 2014.</p>
</dd>
<dt class="label" id="id33"><span class="brackets"><a class="fn-backref" href="#id10">13</a></span></dt>
<dd><p>Pantelis Bouboulis, Konstantinos Slavakis, and Sergios Theodoridis. Adaptive kernel-based image denoising employing semi-parametric regularization. <em>IEEE Transactions on Image Processing</em>, 19(6):1465–1479, 2010.</p>
</dd>
<dt class="label" id="id34"><span class="brackets"><a class="fn-backref" href="#id11">14</a></span></dt>
<dd><p>Peter J Huber. Robust estimation of a location parameter. In <em>Breakthroughs in statistics</em>, pages 492–518. Springer, 1992.</p>
</dd>
<dt class="label" id="id36"><span class="brackets"><a class="fn-backref" href="#id13">15</a></span></dt>
<dd><p>佐土原健. N. cristianini and j. shawe-taylor: an introduction to support vector machines, cambridge university press (2000). <em>人工知能</em>, 16(2):337–337, 2001.</p>
</dd>
<dt class="label" id="id37"><span class="brackets"><a class="fn-backref" href="#id13">16</a></span></dt>
<dd><p>Konstantinos Koutroumbas and Sergios Theodoridis. <em>Pattern recognition</em>. Academic Press, 2008.</p>
</dd>
<dt class="label" id="id35"><span class="brackets">17</span><span class="fn-backref">(<a href="#id15">1</a>,<a href="#id18">2</a>)</span></dt>
<dd><p>S. Theodoridis. <em>Machine Learning: A Bayesian and Optimization Perspective</em>. Elsevier Science, 2020. ISBN 9780128188040. URL: <a class="reference external" href="https://books.google.com.co/books?id=l-nEDwAAQBAJ">https://books.google.com.co/books?id=l-nEDwAAQBAJ</a>.</p>
</dd>
<dt class="label" id="id39"><span class="brackets"><a class="fn-backref" href="#id16">18</a></span></dt>
<dd><p>David E Rumelhart, Geoffrey E Hinton, and Ronald J Williams. Learning representations by back-propagating errors. <em>nature</em>, 323(6088):533–536, 1986.</p>
</dd>
<dt class="label" id="id40"><span class="brackets"><a class="fn-backref" href="#id17">19</a></span></dt>
<dd><p>Arthur E Bryson Jr, Walter F Denham, and Stewart E Dreyfus. Optimal programming problems with inequality constraints. <em>AIAA journal</em>, 1(11):2544–2550, 1963.</p>
</dd>
</dl>
</div>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="dash_jbook.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">Introducción a <code class="docutils literal notranslate"><span class="pre">Dash</span></code> y <code class="docutils literal notranslate"><span class="pre">Jupyter</span> <span class="pre">Book</span></code></p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="model_evaluation.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Evaluación de modelos</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By Lihki Rubio y Carlos de Oro<br/>
  
      &copy; Copyright 2022.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>