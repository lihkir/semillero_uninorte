
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Modelo predictivo &#8212; Semillero de Investigadores</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" href="_static/styles/sphinx-book-theme.css?digest=5115cc725059bd94278eecd172e13a965bf8f5a9" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/proof.css" />
    <link rel="stylesheet" type="text/css" href="_static/design-style.b7bb847fb20b106c3d81b95245e65545.min.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script src="_static/scripts/sphinx-book-theme.js?digest=9c920249402e914e316237a7dbc6769907cce411"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Evaluación de modelos" href="model_evaluation.html" />
    <link rel="prev" title="Visualización de datos" href="data_viz.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="_static/logo-uninorte.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Semillero de Investigadores</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="intro.html">
                    Semillero de Investigadores
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="data_viz.html">
   Visualización de datos
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   Modelo predictivo
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="model_evaluation.html">
   Evaluación de modelos
  </a>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<div class="menu-dropdown menu-dropdown-launch-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Launch interactive content">
      <i class="fas fa-rocket"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://mybinder.org/v2/gh/executablebooks/jupyter-book/master?urlpath=tree/docs/decision_tree.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Launch on Binder"
>
  

<span class="headerbtn__icon-container">
  
    <img src="_static/images/logo_binder.svg">
  </span>
<span class="headerbtn__text-container">Binder</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

<div class="menu-dropdown menu-dropdown-repository-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Source repositories">
      <i class="fab fa-github"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://github.com/executablebooks/jupyter-book"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Source repository"
>
  

<span class="headerbtn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="headerbtn__text-container">repository</span>
</a>

      </li>
      
      <li>
        <a href="https://github.com/executablebooks/jupyter-book/issues/new?title=Issue%20on%20page%20%2Fdecision_tree.html&body=Your%20issue%20content%20here."
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Open an issue"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="headerbtn__text-container">open issue</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="_sources/decision_tree.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.ipynb</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#aprendizaje-supervisado">
   Aprendizaje supervisado
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#ejemplos-de-tareas-de-aprendizaje-automatico-supervisado">
   Ejemplos de tareas de aprendizaje automático supervisado
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#clasificacion-y-regresion">
   Clasificación y regresión
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#generalizacion-sobreajuste-y-subajuste">
   Generalización, sobreajuste y subajuste
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#algunos-ejemplos-de-conjuntos-de-datos">
   Algunos ejemplos de conjuntos de datos
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#arboles-de-decision">
   Árboles de decisión
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#control-de-complejidad">
     Control de complejidad
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#analisis-de-los-arboles-de-decision">
     Análisis de los árboles de decisión
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#caracteristicas-importantes-en-los-arboles">
     Características importantes en los árboles
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#ensamble-de-arboles-de-decision">
     Ensamble de árboles de decisión
    </a>
   </li>
  </ul>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Modelo predictivo</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#aprendizaje-supervisado">
   Aprendizaje supervisado
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#ejemplos-de-tareas-de-aprendizaje-automatico-supervisado">
   Ejemplos de tareas de aprendizaje automático supervisado
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#clasificacion-y-regresion">
   Clasificación y regresión
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#generalizacion-sobreajuste-y-subajuste">
   Generalización, sobreajuste y subajuste
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#algunos-ejemplos-de-conjuntos-de-datos">
   Algunos ejemplos de conjuntos de datos
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#arboles-de-decision">
   Árboles de decisión
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#control-de-complejidad">
     Control de complejidad
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#analisis-de-los-arboles-de-decision">
     Análisis de los árboles de decisión
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#caracteristicas-importantes-en-los-arboles">
     Características importantes en los árboles
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#ensamble-de-arboles-de-decision">
     Ensamble de árboles de decisión
    </a>
   </li>
  </ul>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <section class="tex2jax_ignore mathjax_ignore" id="modelo-predictivo">
<h1>Modelo predictivo<a class="headerlink" href="#modelo-predictivo" title="Permalink to this headline">#</a></h1>
<section id="aprendizaje-supervisado">
<h2>Aprendizaje supervisado<a class="headerlink" href="#aprendizaje-supervisado" title="Permalink to this headline">#</a></h2>
<figure class="align-center" id="fig-supervised-classification">
<a class="reference internal image-reference" href="_images/supervised_classification.png"><img alt="_images/supervised_classification.png" src="_images/supervised_classification.png" style="width: 621.5999999999999px; height: 219.1px;" /></a>
</figure>
<ul class="simple">
<li><p>Los tipos de algoritmos de <code class="docutils literal notranslate"><span class="pre">aprendizaje</span> <span class="pre">automático</span></code> más exitosos son los que automatizan procesos de toma de decisiones mediante generalización, a partir de ejemplos conocidos, el <code class="docutils literal notranslate"><span class="pre">aprendizaje</span> <span class="pre">supervisado</span></code> es un claro ejemplo de este tipo de algoritmos. En el <code class="docutils literal notranslate"><span class="pre">aprendizaje</span> <span class="pre">supervisado</span></code>, el usuario proporciona al algoritmo pares de entradas/salidas deseadas <code class="docutils literal notranslate"><span class="pre">(datos</span> <span class="pre">etiquetados)</span></code>, para entrenar algoritmos que clasifiquen datos o predigan resultados con precisión.</p></li>
<li><p>El algoritmo encuentra la manera de producir el resultado deseado a partir de una entrada. A medida que los datos de entrada se introducen en el modelo, éste ajusta sus ponderaciones hasta que el modelo se ha ajustado adecuadamente. A este procedimiento de ajuste del modelo se le conoce como <code class="docutils literal notranslate"><span class="pre">validación</span> <span class="pre">cruzada</span></code>. En concreto, el algoritmo es capaz de crear una salida para una entrada que nunca ha visto antes, sin la ayuda de un humano. Los algoritmos de <code class="docutils literal notranslate"><span class="pre">aprendizaje</span> <span class="pre">supervisado</span></code> son llamados así, porque un “maestro” proporciona supervisión a los algoritmos, en forma de las salidas deseadas para cada ejemplo del que aprenden.</p></li>
</ul>
</section>
<section id="ejemplos-de-tareas-de-aprendizaje-automatico-supervisado">
<h2>Ejemplos de tareas de aprendizaje automático supervisado<a class="headerlink" href="#ejemplos-de-tareas-de-aprendizaje-automatico-supervisado" title="Permalink to this headline">#</a></h2>
<ul class="simple">
<li><p><strong><code class="docutils literal notranslate"><span class="pre">Identificar</span> <span class="pre">el</span> <span class="pre">código</span> <span class="pre">postal</span> <span class="pre">a</span> <span class="pre">partir</span> <span class="pre">de</span> <span class="pre">los</span> <span class="pre">dígitos</span> <span class="pre">escritos</span> <span class="pre">a</span> <span class="pre">mano</span> <span class="pre">en</span> <span class="pre">un</span> <span class="pre">sobre:</span></code></strong>
Aquí la entrada es un escaneo de la escritura a mano, y la salida deseada son los dígitos reales del código postal. Para crear un conjunto de datos para construir un modelo de aprendizaje automático, hay que recoger muchos sobres. Entonces puedes leer los códigos postales tú mismo y almacenar los dígitos como los resultados deseados.</p></li>
<li><p><strong><code class="docutils literal notranslate"><span class="pre">Determinar</span> <span class="pre">si</span> <span class="pre">un</span> <span class="pre">tumor</span> <span class="pre">es</span> <span class="pre">benigno</span> <span class="pre">a</span> <span class="pre">partir</span> <span class="pre">de</span> <span class="pre">una</span> <span class="pre">imagen</span> <span class="pre">médica:</span></code></strong>
Aquí la entrada es la imagen, y la salida es si el tumor es benigno. Para crear un conjunto de datos para construir un modelo, se necesita una base de datos de imágenes médicas. También se necesita la opinión de un experto, por lo que un médico tiene que ver todas las imágenes y decidir qué tumores son benignos y cuáles no. Incluso puede ser necesario hacer un diagnóstico adicional más allá del contenido de la imagen para determinar si el tumor de la imagen es cancerígeno o no.</p></li>
<li><p><strong><code class="docutils literal notranslate"><span class="pre">Detección</span> <span class="pre">de</span> <span class="pre">actividades</span> <span class="pre">fraudulentas</span> <span class="pre">en</span> <span class="pre">transacciones</span> <span class="pre">con</span> <span class="pre">tarjetas</span> <span class="pre">de</span> <span class="pre">crédito</span></code></strong>
Aquí la entrada es un registro de la transacción de la tarjeta de crédito, y la salida es si es probable que sea fraudulenta o no. Suponiendo que usted es la entidad que distribuye las tarjetas de crédito, recopilar un conjunto de datos significa almacenar todas las transacciones y registrar si un usuario denuncia alguna transacción como fraudulenta.</p></li>
</ul>
</section>
<section id="clasificacion-y-regresion">
<h2>Clasificación y regresión<a class="headerlink" href="#clasificacion-y-regresion" title="Permalink to this headline">#</a></h2>
<ul class="simple">
<li><p>Hay dos tipos principales de problemas de <code class="docutils literal notranslate"><span class="pre">aprendizaje</span> <span class="pre">automático</span> <span class="pre">supervisado</span></code>, denominados <code class="docutils literal notranslate"><span class="pre">clasificación</span></code> y <code class="docutils literal notranslate"><span class="pre">regresión</span></code>. En la <code class="docutils literal notranslate"><span class="pre">clasificación</span></code>, el objetivo es predecir una etiqueta de clase, que es una elección entre una lista predefinida de posibilidades. La <code class="docutils literal notranslate"><span class="pre">clasificación</span></code> se divide en <code class="docutils literal notranslate"><span class="pre">clasificación</span> <span class="pre">binaria</span></code>, que es el caso especial de distinguir entre exactamente dos clases, y <code class="docutils literal notranslate"><span class="pre">clasificación</span> <span class="pre">multiclase</span></code>, que es la clasificación entre más de dos clases. Se puede pensar en la <code class="docutils literal notranslate"><span class="pre">clasificación</span> <span class="pre">binaria</span></code> como si se tratara de responder sí/no a una pregunta. Clasificar los correos electrónicos como spam o no spam es un ejemplo de problema de clasificación binaria.</p></li>
<li><p><em>En la <code class="docutils literal notranslate"><span class="pre">clasificación</span> <span class="pre">binaria</span></code> se suele hablar de que una clase es la <code class="docutils literal notranslate"><span class="pre">positiva</span></code> y la otra la <code class="docutils literal notranslate"><span class="pre">negativa</span></code>. Aquí, <code class="docutils literal notranslate"><span class="pre">positivo</span></code> no representa tener un beneficio o un valor, sino cuál es el objeto de estudio. Así, cuando se busca el spam, <code class="docutils literal notranslate"><span class="pre">&quot;positivo&quot;</span></code> podría significar la clase de spam. Cuál de las dos clases se denomina <code class="docutils literal notranslate"><span class="pre">positiva</span></code> suele ser una cuestión subjetiva y específica del ámbito.</em></p></li>
</ul>
<ul class="simple">
<li><p>En las tareas de <code class="docutils literal notranslate"><span class="pre">regresión</span></code>, el objetivo es predecir un número continuo, o flotante en términos de programación (o un número real en términos matemáticos). Predecir los ingresos anuales de una persona a partir de su educación, su edad y su lugar de residencia es un ejemplo de tarea de <code class="docutils literal notranslate"><span class="pre">regresión</span></code>. Al predecir los ingresos, el valor predicho es una cantidad, y puede ser cualquier número en un rango determinado.</p></li>
<li><p>Una forma fácil de distinguir entre las tareas de <code class="docutils literal notranslate"><span class="pre">clasificación</span></code> y las de <code class="docutils literal notranslate"><span class="pre">regresión</span></code> es preguntarse si hay algún tipo de <em>continuidad en el resultado</em>. Si hay <em>continuidad</em> entre los posibles resultados, el problema es de regresión. En cambio, para la tarea de reconocer el idioma de un sitio web (que es un problema de <code class="docutils literal notranslate"><span class="pre">clasificación</span></code>), no hay cuestión de grado. Un sitio web está en un idioma o en otro. No hay continuidad entre las lenguas, y no hay ninguna lengua que esté entre el inglés y el francés.</p></li>
</ul>
</section>
<section id="generalizacion-sobreajuste-y-subajuste">
<h2>Generalización, sobreajuste y subajuste<a class="headerlink" href="#generalizacion-sobreajuste-y-subajuste" title="Permalink to this headline">#</a></h2>
<ul class="simple">
<li><p>En el <code class="docutils literal notranslate"><span class="pre">aprendizaje</span> <span class="pre">supervisado</span></code>, queremos construir un modelo sobre los datos de entrenamiento y luego ser capaces de realizar predicciones precisas, sobre datos desconocidos que tengan las mismas características que el conjunto de entrenamiento que hemos utilizado. Si un modelo es capaz de realizar predicciones precisas, sobre datos desconocidos, decimos que es capaz de <code class="docutils literal notranslate"><span class="pre">generalizar</span></code> del conjunto de <code class="docutils literal notranslate"><span class="pre">entrenamiento</span></code> al conjunto de <code class="docutils literal notranslate"><span class="pre">prueba</span></code>. Queremos construir un modelo que sea capaz de <code class="docutils literal notranslate"><span class="pre">generalizar</span></code> con la mayor precisión posible.</p></li>
<li><p>Por lo general, construimos un modelo de manera que pueda hacer predicciones precisas en el conjunto de entrenamiento. Si los conjuntos de <code class="docutils literal notranslate"><span class="pre">entrenamiento</span></code> y de <code class="docutils literal notranslate"><span class="pre">prueba</span></code> tienen suficientes puntos en común, esperamos que el modelo también sea preciso en el conjunto de <code class="docutils literal notranslate"><span class="pre">prueba</span></code>. Sin embargo, hay algunos casos en los que esto puede no funcionar. Por ejemplo, si nos permitimos construir modelos muy complejos, podemos siempre ser tan precisos como queramos en el conjunto de entrenamiento, pero que no es capaz de generalizarse a nuevos datos <code class="docutils literal notranslate"><span class="pre">sobreajuste</span></code>.</p></li>
<li><p>El <code class="docutils literal notranslate"><span class="pre">sobreajuste</span> <span class="pre">(overfitting)</span></code> se produce cuando se ajusta un modelo demasiado a las particularidades del conjunto de entrenamiento, y se obtiene un modelo que funciona bien en el conjunto de entrenamiento pero no es capaz de generalizarse con nuevos datos. Por otro lado, si el modelo es demasiado simple, es posible que no sea capaz de captar todos los aspectos y la variabilidad de los datos, y el modelo funcionará mal incluso en el conjunto de entrenamiento. La elección de demasiado simple se denomina <code class="docutils literal notranslate"><span class="pre">subajuste</span> <span class="pre">(underfitting)</span></code>.</p></li>
</ul>
<ul class="simple">
<li><p><em><code class="docutils literal notranslate"><span class="pre">Cuanto</span> <span class="pre">más</span> <span class="pre">complejo</span> <span class="pre">permitimos</span> <span class="pre">que</span> <span class="pre">sea</span> <span class="pre">nuestro</span> <span class="pre">modelo,</span> <span class="pre">mejor</span> <span class="pre">podremos</span> <span class="pre">predecir</span> <span class="pre">en</span> <span class="pre">los</span> <span class="pre">datos</span> <span class="pre">de</span> <span class="pre">entrenamiento.</span> <span class="pre">Sin</span> <span class="pre">embargo,</span> <span class="pre">si</span> <span class="pre">nuestro</span> <span class="pre">modelo</span> <span class="pre">se</span> <span class="pre">vuelve</span> <span class="pre">demasiado</span> <span class="pre">complejo,</span> <span class="pre">empezamos</span> <span class="pre">a</span> <span class="pre">centrarnos</span> <span class="pre">demasiado</span> <span class="pre">en</span> <span class="pre">cada</span> <span class="pre">punto</span> <span class="pre">de</span> <span class="pre">datos</span> <span class="pre">individual</span> <span class="pre">de</span> <span class="pre">nuestro</span> <span class="pre">conjunto</span> <span class="pre">de</span> <span class="pre">entrenamiento,</span> <span class="pre">y</span> <span class="pre">el</span> <span class="pre">modelo</span> <span class="pre">no</span> <span class="pre">se</span> <span class="pre">generalizará</span> <span class="pre">correctamente</span> <span class="pre">con</span> <span class="pre">nuevos</span> <span class="pre">datos.</span> <span class="pre">Hay</span> <span class="pre">un</span> <span class="pre">punto</span> <span class="pre">intermedio</span> <span class="pre">en</span> <span class="pre">el</span> <span class="pre">que</span> <span class="pre">se</span> <span class="pre">obtiene</span> <span class="pre">el</span> <span class="pre">mejor</span> <span class="pre">rendimiento</span> <span class="pre">de</span> <span class="pre">generalización.</span> <span class="pre">Este</span> <span class="pre">es</span> <span class="pre">el</span> <span class="pre">modelo</span> <span class="pre">que</span> <span class="pre">queremos</span> <span class="pre">encontrar.</span> <span class="pre">El</span> <span class="pre">equilibrio</span> <span class="pre">entre</span> <span class="pre">el</span> <span class="pre">overfitting</span> <span class="pre">y</span> <span class="pre">underfitting.</span></code></em></p></li>
</ul>
<figure class="align-center" id="fig-sweet-spot">
<img alt="_images/sweet_spot.png" src="_images/sweet_spot.png" />
<figcaption>
<p><span class="caption-number">Fig. 2 </span><span class="caption-text">Equilibrio entre la complejidad del modelo frente a la precisión del entrenamiento y la prueba.</span><a class="headerlink" href="#fig-sweet-spot" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
</section>
<section id="algunos-ejemplos-de-conjuntos-de-datos">
<h2>Algunos ejemplos de conjuntos de datos<a class="headerlink" href="#algunos-ejemplos-de-conjuntos-de-datos" title="Permalink to this headline">#</a></h2>
<ul>
<li><p>Utilizaremos varios conjuntos de datos para ilustrar los diferentes algoritmos. Algunos de los conjuntos de datos serán pequeños y sintéticos, diseñados para destacar aspectos concretos de los algoritmos. Otros conjuntos de datos serán ejemplos grandes del mundo real. Un ejemplo de conjunto de datos sintético de clasificación de dos clases es el conjunto de datos de <code class="docutils literal notranslate"><span class="pre">forge</span></code>, que tiene dos características.</p></li>
<li><p>El siguiente código crea un gráfico de dispersión que visualiza todos los puntos de datos de este <code class="docutils literal notranslate"><span class="pre">dataset</span></code>. El gráfico tiene la primera característica en el eje <span class="math notranslate nohighlight">\(x\)</span> y la segunda en el eje <span class="math notranslate nohighlight">\(y\)</span>. Como siempre ocurre en los gráficos de dispersión, cada punto de datos está representado por un punto. El color y la forma del punto indican su clase. Generamos el conjunto de datos usando la librería <code class="docutils literal notranslate"><span class="pre">mglearn</span></code> (también puede utilizar <code class="docutils literal notranslate"><span class="pre">make_blobs</span></code> de <code class="docutils literal notranslate"><span class="pre">sklearn</span></code>) e importamos <code class="docutils literal notranslate"><span class="pre">warning</span></code> para evitar mensajes molestos, relacionados con advertencias inofensivas o funciones obsoletas en la actual versión de <code class="docutils literal notranslate"><span class="pre">Python</span></code>. En el presente curso usaremos las <code class="docutils literal notranslate"><span class="pre">versión</span> <span class="pre">3.8</span> <span class="pre">de</span> <span class="pre">Python</span></code>.</p></li>
<li><p>Para instalar <code class="docutils literal notranslate"><span class="pre">mglearn</span></code> en su ambiente para <code class="docutils literal notranslate"><span class="pre">Machine</span> <span class="pre">Learning</span></code> utilizar la siguiente orden</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>pip install mglearn
</pre></div>
</div>
<p>Si su algortimo presenta algún problema a la hora de reconocer <code class="docutils literal notranslate"><span class="pre">mglearn</span></code>, para solucionar este problema, elimine su actual enviroment. Luego cree un nuevo enviroment y en este instale el requirement asociado a este curso. El archivo aparece en (ver <a class="reference external" href="https://github.com/lihkir/Data/blob/main/requirements.txt">requirements.txt</a>).</p>
<div class="highlight-shell notranslate"><div class="highlight"><pre><span></span>pip install -r requirements.txt
</pre></div>
</div>
</li>
</ul>
<ul class="simple">
<li><p>Procedemos ahora sí a importar cada una de las librerías del ejemplo, incluyendo: <code class="docutils literal notranslate"><span class="pre">matplotlib</span></code> y <code class="docutils literal notranslate"><span class="pre">numpy</span></code></p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">warnings</span>
<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s2">&quot;ignore&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">mglearn</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_breast_cancer</span>
<span class="n">cancer</span> <span class="o">=</span> <span class="n">load_breast_cancer</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;cancer.keys(): </span><span class="se">\n</span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">cancer</span><span class="o">.</span><span class="n">keys</span><span class="p">()))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>cancer.keys(): 
dict_keys([&#39;data&#39;, &#39;target&#39;, &#39;frame&#39;, &#39;target_names&#39;, &#39;DESCR&#39;, &#39;feature_names&#39;, &#39;filename&#39;, &#39;data_module&#39;])
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p><em><code class="docutils literal notranslate"><span class="pre">Los</span> <span class="pre">conjuntos</span> <span class="pre">de</span> <span class="pre">datos</span> <span class="pre">que</span> <span class="pre">se</span> <span class="pre">incluyen</span> <span class="pre">en</span> <span class="pre">scikit-learn</span> <span class="pre">suelen</span> <span class="pre">almacenarse</span> <span class="pre">como</span> <span class="pre">objetos</span> <span class="pre">Bunch,</span> <span class="pre">que</span> <span class="pre">contienen</span> <span class="pre">alguna</span> <span class="pre">información</span> <span class="pre">sobre</span> <span class="pre">el</span> <span class="pre">conjunto</span> <span class="pre">de</span> <span class="pre">datos</span> <span class="pre">así</span> <span class="pre">como</span> <span class="pre">los</span> <span class="pre">datos</span> <span class="pre">reales.</span> <span class="pre">Todo</span> <span class="pre">lo</span> <span class="pre">que</span> <span class="pre">necesita</span> <span class="pre">saber</span> <span class="pre">sobre</span> <span class="pre">los</span> <span class="pre">objetos</span> <span class="pre">Bunch</span> <span class="pre">es</span> <span class="pre">que</span> <span class="pre">se</span> <span class="pre">comportan</span> <span class="pre">como</span> <span class="pre">diccionarios,</span> <span class="pre">con</span> <span class="pre">la</span> <span class="pre">ventaja</span> <span class="pre">añadida</span> <span class="pre">de</span> <span class="pre">que</span> <span class="pre">se</span> <span class="pre">puede</span> <span class="pre">acceder</span> <span class="pre">a</span> <span class="pre">los</span> <span class="pre">valores</span> <span class="pre">utilizando</span> <span class="pre">un</span> <span class="pre">punto</span> <span class="pre">(como</span> <span class="pre">en</span> <span class="pre">bunch.key</span> <span class="pre">en</span> <span class="pre">lugar</span> <span class="pre">de</span> <span class="pre">bunch['clave']</span> <span class="pre">).</span></code></em></p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Shape of cancer data: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">cancer</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Shape of cancer data: (569, 30)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">cancer</span><span class="o">.</span><span class="n">target_names</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([&#39;malignant&#39;, &#39;benign&#39;], dtype=&#39;&lt;U9&#39;)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Sample counts per class:</span><span class="se">\n</span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
<span class="p">{</span><span class="n">n</span><span class="p">:</span> <span class="n">v</span> <span class="k">for</span> <span class="n">n</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">cancer</span><span class="o">.</span><span class="n">target_names</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">bincount</span><span class="p">(</span><span class="n">cancer</span><span class="o">.</span><span class="n">target</span><span class="p">))}))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Sample counts per class:
{&#39;malignant&#39;: 212, &#39;benign&#39;: 357}
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>De estos 569 puntos de datos, 212 están etiquetados como malignos y 357 como benignos. Para obtener una descripción del significado semántico de cada característica, podemos echar un vistazo a el atributo <code class="docutils literal notranslate"><span class="pre">feature_names</span></code>. Si está interesado, puede obtener más información sobre los datos leyendo <code class="docutils literal notranslate"><span class="pre">cancer.DESCR</span></code>. Para mas información acerca de este conjunto de datos (ver <a class="reference external" href="https://scikit-learn.org/stable/datasets/toy_dataset.html#breast-cancer-dataset">Breast cancer wisconsin (diagnostic) dataset</a>)</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Feature names:</span><span class="se">\n</span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">cancer</span><span class="o">.</span><span class="n">feature_names</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Feature names:
[&#39;mean radius&#39; &#39;mean texture&#39; &#39;mean perimeter&#39; &#39;mean area&#39;
 &#39;mean smoothness&#39; &#39;mean compactness&#39; &#39;mean concavity&#39;
 &#39;mean concave points&#39; &#39;mean symmetry&#39; &#39;mean fractal dimension&#39;
 &#39;radius error&#39; &#39;texture error&#39; &#39;perimeter error&#39; &#39;area error&#39;
 &#39;smoothness error&#39; &#39;compactness error&#39; &#39;concavity error&#39;
 &#39;concave points error&#39; &#39;symmetry error&#39; &#39;fractal dimension error&#39;
 &#39;worst radius&#39; &#39;worst texture&#39; &#39;worst perimeter&#39; &#39;worst area&#39;
 &#39;worst smoothness&#39; &#39;worst compactness&#39; &#39;worst concavity&#39;
 &#39;worst concave points&#39; &#39;worst symmetry&#39; &#39;worst fractal dimension&#39;]
</pre></div>
</div>
</div>
</div>
</section>
<section id="arboles-de-decision">
<h2>Árboles de decisión<a class="headerlink" href="#arboles-de-decision" title="Permalink to this headline">#</a></h2>
<p><strong><code class="docutils literal notranslate"><span class="pre">Observación</span></code></strong></p>
<ul class="simple">
<li><p>Los árboles de clasificación se basan en una idea simple, pero poderosa, y se encuentran entre las técnicas más populares de clasificación. Son sistemas de varias etapas, y la clasificación de un patrón en una clase se realiza de forma secuencial. A través de una serie de pruebas, las clases se rechazan de forma secuencial hasta que se llega a una decisión a favor de una clase restante.</p></li>
<li><p>Cada una de las pruebas, cuyo resultado decide qué clases se rechazan, es de tipo binario <code class="docutils literal notranslate"><span class="pre">&quot;Sí&quot;</span></code> o <code class="docutils literal notranslate"><span class="pre">&quot;No&quot;</span></code> y se aplica a una sola característica. Nuestro objetivo es presentar la filosofía principal en torno a un tipo especial de árboles conocidos como <code class="docutils literal notranslate"><span class="pre">árboles</span> <span class="pre">de</span> <span class="pre">clasificación</span> <span class="pre">binarios</span> <span class="pre">ordinarios</span> <span class="pre">(OBCT)</span></code>. Estos, pertenecen a una clase más general de métodos que construyen árboles, tanto para la clasificación como para la regresión, conocidos como <code class="docutils literal notranslate"><span class="pre">árboles</span> <span class="pre">de</span> <span class="pre">clasificación</span> <span class="pre">y</span> <span class="pre">regresión</span> <span class="pre">(CART)</span></code>.</p></li>
<li><p>La idea básica de los <code class="docutils literal notranslate"><span class="pre">OBCT</span></code> es dividir el espacio de características en (hiper) rectángulos; es decir, el espacio se divide mediante hiperplanos, que son paralelos a los ejes. Esto se ilustra en la <a class="reference internal" href="#fig-decision-hypplanes-obct"><span class="std std-numref">Fig. 3</span></a></p></li>
</ul>
<figure class="align-center" id="fig-decision-hypplanes-obct">
<a class="reference internal image-reference" href="_images/decision_hypplanes_obct.png"><img alt="_images/decision_hypplanes_obct.png" src="_images/decision_hypplanes_obct.png" style="width: 334.0px; height: 344.5px;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 3 </span><span class="caption-text">Partición del espacio de características bidimensional, correspondiente a tres clases, mediante un árbol de clasificación (OBCT).</span><a class="headerlink" href="#fig-decision-hypplanes-obct" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<ul class="simple">
<li><p>La partición del espacio en (hiper) rectángulos se realiza mediante una serie de <code class="docutils literal notranslate"><span class="pre">&quot;preguntas&quot;</span></code> de esta forma: ¿es el valor de la característica <span class="math notranslate nohighlight">\(x_{i} &lt; a\)</span>?. Este también se conoce como el <code class="docutils literal notranslate"><span class="pre">criterio</span> <span class="pre">de</span> <span class="pre">división</span></code>. La secuencia de preguntas puede realizarse de forma agradable mediante el uso de un árbol. La <a class="reference internal" href="#fig-decision-tree-obct"><span class="std std-numref">Fig. 4</span></a> muestra el árbol correspondiente al caso ilustrado
en la <a class="reference internal" href="#fig-decision-hypplanes-obct"><span class="std std-numref">Fig. 3</span></a>.</p></li>
</ul>
<figure class="align-center" id="fig-decision-tree-obct">
<a class="reference internal image-reference" href="_images/decision_tree_obct.png"><img alt="_images/decision_tree_obct.png" src="_images/decision_tree_obct.png" style="width: 405.59999999999997px; height: 362.4px;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 4 </span><span class="caption-text">Árbol de clasificación que realiza la partición del espacio para la tarea indicada en la <a class="reference internal" href="#fig-decision-hypplanes-obct"><span class="std std-numref">Fig. 3</span></a>.</span><a class="headerlink" href="#fig-decision-tree-obct" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">Cada</span> <span class="pre">nodo</span> <span class="pre">del</span> <span class="pre">árbol</span> <span class="pre">realiza</span> <span class="pre">una</span> <span class="pre">prueba</span> <span class="pre">contra</span> <span class="pre">una</span> <span class="pre">característica</span> <span class="pre">individual</span> <span class="pre">y,</span> <span class="pre">si</span> <span class="pre">este</span> <span class="pre">no</span> <span class="pre">es</span> <span class="pre">un</span> <span class="pre">nodo</span> <span class="pre">hoja</span> <span class="pre">(sin</span> <span class="pre">división</span> <span class="pre">adicional),</span> <span class="pre">este</span> <span class="pre">es</span> <span class="pre">conectado</span> <span class="pre">a</span> <span class="pre">dos</span> <span class="pre">nodos</span> <span class="pre">descendientes</span> <span class="pre">(nodo</span> <span class="pre">de</span> <span class="pre">decisión):</span> <span class="pre">uno</span> <span class="pre">está</span> <span class="pre">asociado</span> <span class="pre">a</span> <span class="pre">la</span> <span class="pre">respuesta</span> <span class="pre">&quot;Yes&quot;</span> <span class="pre">y</span> <span class="pre">el</span> <span class="pre">otro</span> <span class="pre">a</span> <span class="pre">la</span> <span class="pre">respuesta</span> <span class="pre">&quot;No&quot;</span></code>.</p></li>
</ul>
<ul class="simple">
<li><p>Partiendo del nodo raíz, se realiza un recorrido de decisiones sucesivas hasta llegar a un nodo hoja. <code class="docutils literal notranslate"><span class="pre">Cada</span> <span class="pre">nodo</span> <span class="pre">hoja</span> <span class="pre">está</span> <span class="pre">asociado</span> <span class="pre">a</span> <span class="pre">una</span> <span class="pre">única</span> <span class="pre">clase.</span> <span class="pre">La</span> <span class="pre">asignación</span> <span class="pre">de</span> <span class="pre">un</span> <span class="pre">punto</span> <span class="pre">a</span> <span class="pre">una</span> <span class="pre">clase</span> <span class="pre">se</span> <span class="pre">realiza</span> <span class="pre">según</span> <span class="pre">la</span> <span class="pre">etiqueta</span> <span class="pre">del</span> <span class="pre">nodo</span> <span class="pre">hoja</span> <span class="pre">correspondiente</span></code>. Este tipo de clasificación es conceptualmente simple y fácil de interpretar. Por ejemplo, en un sistema de diagnóstico médico, se puede empezar con una pregunta: ¿la temperatura es alta? Si la respuesta es afirmativa, una segunda pregunta puede ser: ¿presenta moquea? El proceso continúa hasta que se llega a una decisión final sobre la enfermedad.</p></li>
<li><p>Además, los árboles son útiles para construir sistemas de razonamiento en la inteligencia artificial. Por ejemplo, la existencia de objetos específicos, que se deduce a través de una serie de preguntas relacionadas, basadas en los valores de ciertas características (de alto nivel), puede conducir al reconocimiento de una escena o de un objeto representado en una imagen.</p></li>
<li><p>Una vez desarrollado el árbol, la clasificación es sencilla. El mayor reto consiste en construir el árbol, explotando la información que reside en el conjunto de datos de entrenamiento. Las principales preguntas a las que uno se enfrenta al diseñar un árbol, entreo otras que se discutiran más adelante, son:</p>
<ul>
<li><p>¿Qué criterio de división debe adoptarse?</p></li>
<li><p>¿Cuándo se debe detener el crecimiento de un árbol y declarar un nodo como final?</p></li>
<li><p>¿Cómo se asocia un nodo hoja a una clase concreta?</p></li>
</ul>
</li>
</ul>
<section id="control-de-complejidad">
<h3>Control de complejidad<a class="headerlink" href="#control-de-complejidad" title="Permalink to this headline">#</a></h3>
<ul class="simple">
<li><p>Al construir un árbol como se describe en esta sección, hasta que todas las hojas sean puras, da lugar a modelos muy complejos y muy ajustados a los datos de entrenamiento. <code class="docutils literal notranslate"><span class="pre">La</span> <span class="pre">presencia</span> <span class="pre">de</span> <span class="pre">hojas</span> <span class="pre">puras</span> <span class="pre">significa</span> <span class="pre">que</span> <span class="pre">un</span> <span class="pre">árbol</span> <span class="pre">es</span> <span class="pre">100%</span> <span class="pre">preciso</span> <span class="pre">en</span> <span class="pre">el</span> <span class="pre">conjunto</span> <span class="pre">de</span> <span class="pre">entrenamiento</span></code>; cada punto de datos del conjunto de entrenamiento está en una hoja que tiene la clase mayoritaria correcta.</p></li>
<li><p>Hay dos estrategias comunes para evitar el overfitting: <code class="docutils literal notranslate"><span class="pre">detener</span> <span class="pre">la</span> <span class="pre">creación</span> <span class="pre">del</span> <span class="pre">árbol</span> <span class="pre">antes</span> <span class="pre">de</span> <span class="pre">tiempo</span> <span class="pre">(también</span> <span class="pre">llamada</span> <span class="pre">prepoda),</span> <span class="pre">o</span> <span class="pre">construir</span> <span class="pre">el</span> <span class="pre">árbol,</span> <span class="pre">pero</span> <span class="pre">luego</span> <span class="pre">eliminar</span> <span class="pre">o</span> <span class="pre">colapsar</span> <span class="pre">nodos</span> <span class="pre">que</span> <span class="pre">contienen</span> <span class="pre">poca</span> <span class="pre">información</span> <span class="pre">(también</span> <span class="pre">llamada</span> <span class="pre">poda</span> <span class="pre">posterior</span> <span class="pre">o</span> <span class="pre">simplemente</span> <span class="pre">poda)</span></code>. Los posibles criterios para la <code class="docutils literal notranslate"><span class="pre">prepoda</span></code> incluyen la <code class="docutils literal notranslate"><span class="pre">limitación</span> <span class="pre">de</span> <span class="pre">la</span> <span class="pre">profundidad</span> <span class="pre">máxima</span> <span class="pre">del</span> <span class="pre">árbol,</span> <span class="pre">limitar</span> <span class="pre">el</span> <span class="pre">número</span> <span class="pre">máximo</span> <span class="pre">de</span> <span class="pre">hojas,</span> <span class="pre">o</span> <span class="pre">exigir</span> <span class="pre">un</span> <span class="pre">número</span> <span class="pre">mínimo</span> <span class="pre">de</span> <span class="pre">puntos</span> <span class="pre">en</span> <span class="pre">un</span> <span class="pre">nodo</span> <span class="pre">para</span> <span class="pre">seguir</span> <span class="pre">dividiéndolo</span></code>.</p></li>
<li><p>Los árboles de decisión en <code class="docutils literal notranslate"><span class="pre">scikit-learn</span></code> se implementan en las clases <code class="docutils literal notranslate"><span class="pre">DecisionTreeRegressor</span></code> y <code class="docutils literal notranslate"><span class="pre">DecisionTreeClassifier</span></code>. <code class="docutils literal notranslate"><span class="pre">scikit-learn</span></code> sólo implementa la pre-poda, no la post-poda. Veamos el efecto de la poda a priori con más detalle en el conjunto de datos de cáncer de mama. Como siempre, importamos el conjunto de datos y lo dividimos en una parte de entrenamiento y otra de prueba. A continuación, construimos un  modelo utilizando la configuración por defecto de desarrollo completo del árbol (extendiendo el árbol hasta que todas las hojas sean puras). Fijamos el <code class="docutils literal notranslate"><span class="pre">random_state</span></code> en el árbol, que se utiliza para ruptura interna de de los lazos. Nótese que seleccionamos <code class="docutils literal notranslate"><span class="pre">stratify=cancer.target</span></code>, los datos se dividen de forma estratificada, utilizando <code class="docutils literal notranslate"><span class="pre">cancer.target</span></code> como las etiquetas de clase (ver <a class="reference external" href="https://scikit-learn.org/stable/modules/cross_validation.html#stratification">stratified</a>).</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">warnings</span>
<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s1">&#39;ignore&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.tree</span> <span class="kn">import</span> <span class="n">DecisionTreeClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_breast_cancer</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">cancer</span> <span class="o">=</span> <span class="n">load_breast_cancer</span><span class="p">()</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">cancer</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">cancer</span><span class="o">.</span><span class="n">target</span><span class="p">,</span> 
                                                    <span class="n">stratify</span><span class="o">=</span><span class="n">cancer</span><span class="o">.</span><span class="n">target</span><span class="p">,</span> 
                                                    <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">tree</span> <span class="o">=</span> <span class="n">DecisionTreeClassifier</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">tree</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Accuracy on training set: </span><span class="si">{:.3f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">tree</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Accuracy on test set: </span><span class="si">{:.3f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">tree</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Accuracy on training set: 1.000
Accuracy on test set: 0.937
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Aquí la función <code class="docutils literal notranslate"><span class="pre">score</span></code> como en la mayoría de clasificadores, devuelve la precisión media en los datos de prueba y las etiquetas dadas. Como era de esperar, <code class="docutils literal notranslate"><span class="pre">la</span> <span class="pre">precisión</span> <span class="pre">en</span> <span class="pre">el</span> <span class="pre">conjunto</span> <span class="pre">de</span> <span class="pre">entrenamiento</span> <span class="pre">es</span> <span class="pre">del</span> <span class="pre">100%</span></code>, ya que las hojas son puras, el árbol creció lo suficiente como para poder memorizar perfectamente todas las etiquetas de los datos de entrenamiento. <code class="docutils literal notranslate"><span class="pre">La</span> <span class="pre">precisión</span> <span class="pre">del</span> <span class="pre">conjunto</span> <span class="pre">de</span> <span class="pre">prueba</span> <span class="pre">es</span> <span class="pre">ligeramente</span> <span class="pre">peor</span> <span class="pre">que</span> <span class="pre">la</span> <span class="pre">de</span> <span class="pre">los</span> <span class="pre">modelos</span> <span class="pre">lineales</span></code> que vimos anteriormente, que tenían una precisión de alrededor del 95%.</p></li>
<li><p>Si no restringimos la profundidad de un árbol de decisión, el árbol puede llegar a ser arbitrariamente profundo y complejo. <code class="docutils literal notranslate"><span class="pre">Los</span> <span class="pre">árboles</span> <span class="pre">no</span> <span class="pre">podados</span> <span class="pre">son,</span> <span class="pre">por</span> <span class="pre">tanto,</span> <span class="pre">son</span> <span class="pre">propensos</span> <span class="pre">a</span> <span class="pre">sobreajustarse</span> <span class="pre">y</span> <span class="pre">a</span> <span class="pre">no</span> <span class="pre">generalizar</span> <span class="pre">bien</span> <span class="pre">a</span> <span class="pre">los</span> <span class="pre">nuevos</span> <span class="pre">datos</span></code>. Ahora apliquemos la pre-poda, la cual que dejará de desarrollar el árbol antes de ajustarse perfectamente a los datos de entrenamiento. Una opción es dejar de construir el árbol después de alcanzar una cierta profundidad. En este caso,<code class="docutils literal notranslate"><span class="pre">establecemos</span> <span class="pre">que</span> <span class="pre">la</span> <span class="pre">profundidad</span> <span class="pre">máxima</span> <span class="pre">sea</span> <span class="pre">de</span> <span class="pre">4</span> <span class="pre">(max_depth=4),</span> <span class="pre">lo</span> <span class="pre">que</span> <span class="pre">significa</span> <span class="pre">que</span> <span class="pre">sólo</span> <span class="pre">se</span> <span class="pre">pueden</span> <span class="pre">formular</span> <span class="pre">cuatro</span> <span class="pre">preguntas</span> <span class="pre">consecutivas</span></code>. La limitación de la profundidad del árbol disminuye el sobreajuste. Esto conduce a una menor precisión en el conjunto de entrenamiento, pero una mejora en el conjunto de prueba</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">tree</span> <span class="o">=</span> <span class="n">DecisionTreeClassifier</span><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">tree</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Accuracy on training set: </span><span class="si">{:.3f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">tree</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Accuracy on test set: </span><span class="si">{:.3f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">tree</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Accuracy on training set: 0.988
Accuracy on test set: 0.951
</pre></div>
</div>
</div>
</div>
</section>
<section id="analisis-de-los-arboles-de-decision">
<h3>Análisis de los árboles de decisión<a class="headerlink" href="#analisis-de-los-arboles-de-decision" title="Permalink to this headline">#</a></h3>
<ul class="simple">
<li><p>Podemos visualizar un árbol de decisión utilizando la función <code class="docutils literal notranslate"><span class="pre">export_graphviz</span></code> del módulo <code class="docutils literal notranslate"><span class="pre">tree</span></code>. Esta función escribe un archivo en el formato <code class="docutils literal notranslate"><span class="pre">.dot</span></code> de archivo de texto para almacenar gráficos. Establecemos una opción para colorear los nodos, para reflejar la clase mayoritaria en cada nodo y pasamos los nombres de las clases y las características para que el árbol pueda ser etiquetado correctamente. El argumento <code class="docutils literal notranslate"><span class="pre">impurity</span></code> está relacionado con la probabilidad de que clasifiquemos incorrectamente un nuevo punto de datos de forma incorrecta, normalmente calculada mediante la métrica de entropia <code class="docutils literal notranslate"><span class="pre">giny</span></code> la cual se aborda teóricamente en la sección anterior.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.tree</span> <span class="kn">import</span> <span class="n">export_graphviz</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">export_graphviz</span><span class="p">(</span><span class="n">tree</span><span class="p">,</span>
                <span class="n">out_file</span><span class="o">=</span><span class="s2">&quot;tree.dot&quot;</span><span class="p">,</span> 
                <span class="n">class_names</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;malignant&quot;</span><span class="p">,</span> <span class="s2">&quot;benign&quot;</span><span class="p">],</span>
                <span class="n">feature_names</span><span class="o">=</span><span class="n">cancer</span><span class="o">.</span><span class="n">feature_names</span><span class="p">,</span> 
                <span class="n">impurity</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> 
                <span class="n">filled</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Podemos leer este archivo y visualizarlo, utilizando el modulo <code class="docutils literal notranslate"><span class="pre">graphviz</span></code> (o puede utilizar cualquier programa que pueda leer archivos <code class="docutils literal notranslate"><span class="pre">.dot</span></code>)</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">graphviz</span>
<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s2">&quot;tree.dot&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
    <span class="n">dot_graph</span> <span class="o">=</span> <span class="n">f</span><span class="o">.</span><span class="n">read</span><span class="p">()</span>
<span class="n">graphviz</span><span class="o">.</span><span class="n">Source</span><span class="p">(</span><span class="n">dot_graph</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/decision_tree_44_0.svg" src="_images/decision_tree_44_0.svg" /></div>
</div>
<ul class="simple">
<li><p>La visualización del árbol proporciona una <code class="docutils literal notranslate"><span class="pre">gran</span> <span class="pre">visión</span> <span class="pre">en</span> <span class="pre">profundidad</span> <span class="pre">de</span> <span class="pre">cómo</span> <span class="pre">el</span> <span class="pre">algoritmo</span> <span class="pre">realiza</span> <span class="pre">predicciones,</span> <span class="pre">y</span> <span class="pre">es</span> <span class="pre">un</span> <span class="pre">buen</span> <span class="pre">ejemplo</span> <span class="pre">de</span> <span class="pre">un</span> <span class="pre">algoritmo</span> <span class="pre">de</span> <span class="pre">aprendizaje</span> <span class="pre">automático</span> <span class="pre">que</span> <span class="pre">puede</span> <span class="pre">fácilmente</span> <span class="pre">explicarse</span> <span class="pre">a</span> <span class="pre">no</span> <span class="pre">expertos</span></code>. Sin embargo, incluso con un árbol de profundidad cuatro, como se ve aquí, el árbol puede resultar un poco abrumador. Los árboles más profundos (una profundidad de 10 puede ser común) son aún más difíciles de entender.</p></li>
<li><p>Un método de inspección del árbol que puede ser útil es, averiguar qué camino toma realmente la mayoría de los datos. <code class="docutils literal notranslate"><span class="pre">Las</span> <span class="pre">n_samples</span> <span class="pre">que</span> <span class="pre">se</span> <span class="pre">muestran</span> <span class="pre">en</span> <span class="pre">cada</span> <span class="pre">nodo</span> <span class="pre">de</span> <span class="pre">la</span> <span class="pre">figura,</span> <span class="pre">entregan</span> <span class="pre">el</span> <span class="pre">número</span> <span class="pre">de</span> <span class="pre">muestras</span> <span class="pre">en</span> <span class="pre">ese</span> <span class="pre">nodo</span></code>, mientras que <code class="docutils literal notranslate"><span class="pre">value</span> <span class="pre">provee</span> <span class="pre">el</span> <span class="pre">número</span> <span class="pre">de</span> <span class="pre">muestras</span> <span class="pre">por</span> <span class="pre">clase</span></code>. Siguiendo las ramas hacia la derecha, vemos que el <code class="docutils literal notranslate"><span class="pre">worst</span> <span class="pre">radius</span></code> <span class="math notranslate nohighlight">\(\leq\)</span> <code class="docutils literal notranslate"><span class="pre">16.795</span></code> crea un nodo que contiene sólo <code class="docutils literal notranslate"><span class="pre">8</span> <span class="pre">muestras</span> <span class="pre">benignas</span> <span class="pre">pero</span> <span class="pre">134</span> <span class="pre">muestras</span> <span class="pre">malignas.</span> <span class="pre">El</span> <span class="pre">resto</span> <span class="pre">de</span> <span class="pre">este</span> <span class="pre">lado</span> <span class="pre">del</span> <span class="pre">árbol</span> <span class="pre">utiliza</span> <span class="pre">entonces</span> <span class="pre">algunas</span> <span class="pre">distinciones</span> <span class="pre">más</span> <span class="pre">finas</span> <span class="pre">para</span> <span class="pre">separar</span> <span class="pre">estas</span> <span class="pre">8</span> <span class="pre">muestras</span> <span class="pre">benignas</span> <span class="pre">restantes</span></code>. De las 142 muestras que fueron a la derecha en la división inicial, casi todas ellas (132) terminan en la hoja de la derecha. Tomando la izquierda en la raíz, para el <code class="docutils literal notranslate"><span class="pre">worst</span> <span class="pre">radio</span> <span class="pre">&gt;</span> <span class="pre">16.795</span></code> terminamos con <code class="docutils literal notranslate"><span class="pre">25</span> <span class="pre">muestras</span> <span class="pre">malignas</span> <span class="pre">y</span> <span class="pre">259</span> <span class="pre">muestras</span> <span class="pre">benignas</span></code>. Casi todas las muestras benignas acaban en la segunda hoja de la derecha, y la mayoría de las demás hojas contienen muy pocas muestras.</p></li>
</ul>
</section>
<section id="caracteristicas-importantes-en-los-arboles">
<h3>Características importantes en los árboles<a class="headerlink" href="#caracteristicas-importantes-en-los-arboles" title="Permalink to this headline">#</a></h3>
<ul class="simple">
<li><p>En lugar de mirar todo el árbol, lo que puede ser agotador, hay algunas <code class="docutils literal notranslate"><span class="pre">propiedades</span> <span class="pre">útiles</span> <span class="pre">que</span> <span class="pre">podemos</span> <span class="pre">derivar</span> <span class="pre">para</span> <span class="pre">resumir</span> <span class="pre">el</span> <span class="pre">funcionamiento</span> <span class="pre">del</span> <span class="pre">árbol</span></code>. El resumen más utilizado es el de las <code class="docutils literal notranslate"><span class="pre">características</span> <span class="pre">importantes,</span> <span class="pre">que</span> <span class="pre">califica</span> <span class="pre">la</span> <span class="pre">importancia</span> <span class="pre">de</span> <span class="pre">cada</span> <span class="pre">característica</span> <span class="pre">para</span> <span class="pre">la</span> <span class="pre">decisión</span> <span class="pre">que</span> <span class="pre">toma</span> <span class="pre">el</span> <span class="pre">árbol</span></code>. Es un número entre 0 y 1 para cada característica, donde 0 significa “no se utiliza en absoluto” y 1 significa “predice perfectamente el objetivo”. Las características siempre suman 1</p></li>
</ul>
<ul class="simple">
<li><p>Otra <code class="docutils literal notranslate"><span class="pre">excelente</span> <span class="pre">manera</span> <span class="pre">de</span> <span class="pre">visualizar</span> <span class="pre">predicciones</span> <span class="pre">a</span> <span class="pre">partir</span> <span class="pre">de</span> <span class="pre">un</span> <span class="pre">random</span> <span class="pre">forest</span> <span class="pre">por</span> <span class="pre">ejemplo,</span> <span class="pre">es</span> <span class="pre">utilizando</span> <span class="pre">la</span> <span class="pre">librería</span></code> <a class="reference external" href="https://www.kaggle.com/code/prashant111/explain-your-model-predictions-with-lime/notebook">LIME</a> <code class="docutils literal notranslate"><span class="pre">de</span> <span class="pre">Python</span></code>. Con esta librería se pueden generar por cada instancias, figuras de cartaterísticas importantes y representar sus probabilidades de pertenecer a la clase predicha (<code class="docutils literal notranslate"><span class="pre">pruebela</span></code>).</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Feature importances:</span><span class="se">\n</span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">tree</span><span class="o">.</span><span class="n">feature_importances_</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Feature importances:
[0.         0.         0.         0.         0.         0.
 0.         0.         0.         0.         0.01019737 0.04839825
 0.         0.         0.0024156  0.         0.         0.
 0.         0.         0.72682851 0.0458159  0.         0.
 0.0141577  0.         0.018188   0.1221132  0.01188548 0.        ]
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Podemos visualizar las importancias de las características de forma similar a la forma en que visualizamos los coeficientes en el modelo lineal</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">plot_feature_importances_cancer</span><span class="p">(</span><span class="n">model</span><span class="p">):</span>
    <span class="n">n_features</span> <span class="o">=</span> <span class="n">cancer</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">barh</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">n_features</span><span class="p">),</span> <span class="n">model</span><span class="o">.</span><span class="n">feature_importances_</span><span class="p">,</span> <span class="n">align</span><span class="o">=</span><span class="s1">&#39;center&#39;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">yticks</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">n_features</span><span class="p">),</span> <span class="n">cancer</span><span class="o">.</span><span class="n">feature_names</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Feature importance&quot;</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Feature&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plot_feature_importances_cancer</span><span class="p">(</span><span class="n">tree</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/decision_tree_53_0.png" src="_images/decision_tree_53_0.png" />
</div>
</div>
<ul class="simple">
<li><p>Aquí vemos que la característica utilizada en la división superior <code class="docutils literal notranslate"><span class="pre">(&quot;worst</span> <span class="pre">radio&quot;)</span></code> es, con mucho, la más importante. Esto confirma nuestra observación al analizar el árbol de que el primer nivel ya separa bastante bien las dos clases. Sin embargo, si una característica tiene un <code class="docutils literal notranslate"><span class="pre">feature_importance</span></code> bajo, no significa que esta característica sea poco informativa. Sólo significa que la característica no fue elegida por el árbol, probablemente porque otra característica codifica la misma información.</p></li>
<li><p>A diferencia de los coeficientes de los modelos lineales, <code class="docutils literal notranslate"><span class="pre">las</span> <span class="pre">importancias</span> <span class="pre">de</span> <span class="pre">las</span> <span class="pre">características</span> <span class="pre">son</span> <span class="pre">siempre</span> <span class="pre">positivas</span> <span class="pre">y</span> <span class="pre">no</span> <span class="pre">codifican</span> <span class="pre">la</span> <span class="pre">clase</span> <span class="pre">de</span> <span class="pre">la</span> <span class="pre">que</span> <span class="pre">es</span> <span class="pre">indicativa</span> <span class="pre">una</span> <span class="pre">característica</span></code>. Las <code class="docutils literal notranslate"><span class="pre">feature_importance</span></code> nos dicen que el <code class="docutils literal notranslate"><span class="pre">&quot;worst</span> <span class="pre">radio&quot;</span></code> es importante, pero no si un radio alto es indicativo de que una muestra es benigna o maligna. De hecho, puede que no haya una relación tan sencilla entre las características y la clase, como se puede ver en el siguiente ejemplo. La siguiente figura muestra un conjunto de datos bidimensional en el que <code class="docutils literal notranslate"><span class="pre">la</span> <span class="pre">característica</span> <span class="pre">en</span> <span class="pre">el</span> <span class="pre">eje</span></code> <span class="math notranslate nohighlight">\(y\)</span> <code class="docutils literal notranslate"><span class="pre">tiene</span> <span class="pre">una</span> <span class="pre">relación</span> <span class="pre">no</span> <span class="pre">monótona</span> <span class="pre">con</span> <span class="pre">la</span> <span class="pre">etiqueta</span> <span class="pre">de</span> <span class="pre">clase,</span> <span class="pre">y</span> <span class="pre">los</span> <span class="pre">límites</span> <span class="pre">de</span> <span class="pre">decisión</span> <span class="pre">encontrados</span> <span class="pre">por</span> <span class="pre">un</span> <span class="pre">árbol</span> <span class="pre">de</span> <span class="pre">decisión</span></code></p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">mglearn</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">tree</span> <span class="o">=</span> <span class="n">mglearn</span><span class="o">.</span><span class="n">plots</span><span class="o">.</span><span class="n">plot_tree_not_monotone</span><span class="p">()</span>
<span class="n">display</span><span class="p">(</span><span class="n">tree</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Feature importances: [0. 1.]
</pre></div>
</div>
<img alt="_images/decision_tree_56_1.svg" src="_images/decision_tree_56_1.svg" /><img alt="_images/decision_tree_56_2.png" src="_images/decision_tree_56_2.png" />
</div>
</div>
<ul class="simple">
<li><p>El gráfico muestra un conjunto de datos con dos características y dos clases. Aquí, toda la información está contenida en <code class="docutils literal notranslate"><span class="pre">X[1]</span></code> , y <code class="docutils literal notranslate"><span class="pre">X[0]</span></code> no se utiliza en absoluto. Pero la relación entre X[1] y la clase de salida no es monótona, lo que significa que no podemos decir <code class="docutils literal notranslate"><span class="pre">&quot;un</span> <span class="pre">valor</span> <span class="pre">alto</span> <span class="pre">de</span> <span class="pre">X[0]</span> <span class="pre">significa</span> <span class="pre">la</span> <span class="pre">clase</span> <span class="pre">0,</span> <span class="pre">y</span> <span class="pre">un</span> <span class="pre">valor</span> <span class="pre">bajo</span> <span class="pre">significa</span> <span class="pre">la</span> <span class="pre">clase</span> <span class="pre">1&quot;</span> <span class="pre">(o</span> <span class="pre">viceversa)</span></code>. Aunque hemos centrado nuestra discusión aquí en los árboles de decisión para la clasificación, todo lo que se ha dicho es igualmente cierto para los árboles de decisión para la regresión, como se implementa en <code class="docutils literal notranslate"><span class="pre">DecisionTreeRegressor</span></code>.</p></li>
<li><p>El uso y análisis de los árboles de regresión es muy similar al de los árboles de clasificación. Hay una propiedad particular del uso de modelos basados en árboles para regresión que queremos señalar, sin embargo, <code class="docutils literal notranslate"><span class="pre">DecisionTreeRegressor</span> <span class="pre">(y</span> <span class="pre">todos</span> <span class="pre">los</span> <span class="pre">otros</span> <span class="pre">modelos</span> <span class="pre">de</span> <span class="pre">regresión</span> <span class="pre">basados</span> <span class="pre">en</span> <span class="pre">árboles)</span> <span class="pre">no</span> <span class="pre">son</span> <span class="pre">capaces</span> <span class="pre">de</span> <span class="pre">extrapolar,</span> <span class="pre">o</span> <span class="pre">hacer</span> <span class="pre">predicciones</span> <span class="pre">fuera</span> <span class="pre">del</span> <span class="pre">rango</span> <span class="pre">de</span> <span class="pre">los</span> <span class="pre">datos</span> <span class="pre">de</span> <span class="pre">entrenamiento</span></code>. Veamos esto con más detalle, utilizando un conjunto de datos de los precios históricos de la memoria de los ordenadores (RAM). La siguiente figura muestra el conjunto de datos, con la fecha en el eje <span class="math notranslate nohighlight">\(x\)</span> y el precio de un megabyte de RAM en ese año en el eje <span class="math notranslate nohighlight">\(y\)</span>:</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="n">ram_prices</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;https://raw.githubusercontent.com/lihkir/Data/main/ram_price.csv&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">semilogy</span><span class="p">(</span><span class="n">ram_prices</span><span class="o">.</span><span class="n">date</span><span class="p">,</span> <span class="n">ram_prices</span><span class="o">.</span><span class="n">price</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Year&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Price in $/Mbyte&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Text(0, 0.5, &#39;Price in $/Mbyte&#39;)
</pre></div>
</div>
<img alt="_images/decision_tree_58_1.png" src="_images/decision_tree_58_1.png" />
</div>
</div>
<ul class="simple">
<li><p>Nótese que en la escala logarítmica del eje <span class="math notranslate nohighlight">\(y\)</span>, <code class="docutils literal notranslate"><span class="pre">la</span> <span class="pre">relación</span> <span class="pre">parece</span> <span class="pre">ser</span> <span class="pre">bastante</span> <span class="pre">lineal</span> <span class="pre">y,</span> <span class="pre">por</span> <span class="pre">tanto,</span> <span class="pre">debería</span> <span class="pre">ser</span> <span class="pre">relativamente</span> <span class="pre">fácil</span> <span class="pre">de</span> <span class="pre">predecir</span></code>. Vamos a hacer una predicción para los años posteriores al 2000 utilizando los datos históricos hasta esa fecha como única característica. Compararemos dos modelos sencillos: un <code class="docutils literal notranslate"><span class="pre">DecisionTreeRegressor</span></code> y <code class="docutils literal notranslate"><span class="pre">LinearRegression</span></code>.</p></li>
<li><p>Cambiamos la escala de los precios utilizando un logaritmo, para que la relación sea relativamente lineal. Esto no supone ninguna diferencia para el <code class="docutils literal notranslate"><span class="pre">DecisionTreeRegressor</span></code>, pero supone una gran diferencia para el <code class="docutils literal notranslate"><span class="pre">LinearRegression</span></code>. Después de entrenar los modelos y hacer predicciones, aplicamos la función exponencial para deshacer la transformación del logaritmo. Realizamos predicciones sobre todo el conjunto de datos para su visualización, pero para una evaluación cuantitativa, sólo consideraríamos el conjunto de datos de prueba</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.tree</span> <span class="kn">import</span> <span class="n">DecisionTreeRegressor</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LinearRegression</span>
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Utilizamos los datos históricos para prever los precios después del año 2000. <code class="docutils literal notranslate"><span class="pre">Realizamos</span> <span class="pre">predicción</span> <span class="pre">de</span> <span class="pre">los</span> <span class="pre">precios</span> <span class="pre">en</span> <span class="pre">función</span> <span class="pre">de</span> <span class="pre">la</span> <span class="pre">fecha</span></code>. Utilizamos una transformación logarítmica para obtener una relación más sencilla de los datos con el objetivo</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">data_train</span> <span class="o">=</span> <span class="n">ram_prices</span><span class="p">[</span><span class="n">ram_prices</span><span class="o">.</span><span class="n">date</span> <span class="o">&lt;</span> <span class="mi">2000</span><span class="p">]</span>
<span class="n">data_test</span>  <span class="o">=</span> <span class="n">ram_prices</span><span class="p">[</span><span class="n">ram_prices</span><span class="o">.</span><span class="n">date</span> <span class="o">&gt;=</span> <span class="mi">2000</span><span class="p">]</span>

<span class="n">X_train</span> <span class="o">=</span> <span class="n">data_train</span><span class="o">.</span><span class="n">date</span><span class="p">[:,</span> <span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">]</span> <span class="c1"># Vector columna</span>
<span class="n">y_train</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">data_train</span><span class="o">.</span><span class="n">price</span><span class="p">)</span>

<span class="n">tree</span> <span class="o">=</span> <span class="n">DecisionTreeRegressor</span><span class="p">()</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">linear_reg</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">()</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="n">X_all</span> <span class="o">=</span> <span class="n">ram_prices</span><span class="o">.</span><span class="n">date</span><span class="p">[:,</span> <span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">]</span>
<span class="n">pred_tree</span> <span class="o">=</span> <span class="n">tree</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_all</span><span class="p">)</span>
<span class="n">pred_lr</span> <span class="o">=</span> <span class="n">linear_reg</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_all</span><span class="p">)</span>

<span class="n">price_tree</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">pred_tree</span><span class="p">)</span>
<span class="n">price_lr</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">pred_lr</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Realizamos una figura para comparar las predicciones del árbol de decisión y del modelo de regresión lineal con la los datos reales de entrenamiento y de prueba</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">semilogy</span><span class="p">(</span><span class="n">data_train</span><span class="o">.</span><span class="n">date</span><span class="p">,</span> <span class="n">data_train</span><span class="o">.</span><span class="n">price</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Training data&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">semilogy</span><span class="p">(</span><span class="n">data_test</span><span class="o">.</span><span class="n">date</span><span class="p">,</span> <span class="n">data_test</span><span class="o">.</span><span class="n">price</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Test data&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">semilogy</span><span class="p">(</span><span class="n">ram_prices</span><span class="o">.</span><span class="n">date</span><span class="p">,</span> <span class="n">price_tree</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Tree prediction&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">semilogy</span><span class="p">(</span><span class="n">ram_prices</span><span class="o">.</span><span class="n">date</span><span class="p">,</span> <span class="n">price_lr</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Linear prediction&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">();</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/decision_tree_64_0.png" src="_images/decision_tree_64_0.png" />
</div>
</div>
<ul class="simple">
<li><p>La diferencia entre los modelos es bastante sorprendente. El modelo lineal se aproxima a los datos con una línea, como sabíamos que haría. Esta línea proporciona una previsión bastante buena para los datos de prueba (los años posteriores al 2000), mientras que pasa por alto algunas de las variaciones más finas en los datos de entrenamiento y de prueba. <code class="docutils literal notranslate"><span class="pre">El</span> <span class="pre">modelo</span> <span class="pre">de</span> <span class="pre">árbol,</span> <span class="pre">por</span> <span class="pre">su</span> <span class="pre">parte,</span> <span class="pre">hace</span> <span class="pre">predicciones</span> <span class="pre">perfectas</span> <span class="pre">sobre</span> <span class="pre">los</span> <span class="pre">datos</span> <span class="pre">de</span> <span class="pre">entrenamiento</span></code>, no restringimos la complejidad del árbol, por lo que aprendió de memoria todo el conjunto de datos. Sin embargo, <code class="docutils literal notranslate"><span class="pre">una</span> <span class="pre">vez</span> <span class="pre">que</span> <span class="pre">salimos</span> <span class="pre">del</span> <span class="pre">rango</span> <span class="pre">para</span> <span class="pre">el</span> <span class="pre">que</span> <span class="pre">el</span> <span class="pre">arbol</span> <span class="pre">tiene</span> <span class="pre">datos,</span> <span class="pre">el</span> <span class="pre">modelo</span> <span class="pre">simplemente</span> <span class="pre">sigue</span> <span class="pre">prediciendo</span> <span class="pre">el</span> <span class="pre">último</span> <span class="pre">punto</span> <span class="pre">conocido</span></code>. El árbol no tiene la capacidad para generar <code class="docutils literal notranslate"><span class="pre">&quot;nuevas&quot;</span></code> respuestas, fuera de lo que se vio en los datos de de entrenamiento. Esta deficiencia se aplica a todos los modelos basados en árboles.</p></li>
</ul>
<p><strong><code class="docutils literal notranslate"><span class="pre">Puntos</span> <span class="pre">fuertes,</span> <span class="pre">puntos</span> <span class="pre">débiles</span> <span class="pre">y</span> <span class="pre">parámetros</span></code></strong></p>
<ul class="simple">
<li><p>Como ya se ha comentado, los parámetros que controlan la complejidad del modelo en los árboles de decisión son los parámetros de pre-selección que detienen la construcción del árbol antes de que esté completamente desarrollado. Por lo general, la elección de una de las estrategias de pre-poda y configuración de: <code class="docutils literal notranslate"><span class="pre">max_depth,</span> <span class="pre">max_leaf_nodes,</span> <span class="pre">min_samples_leaf</span></code> es suficiente para evitar el overfitting de la misma.</p></li>
<li><p>Los árboles de decisión tienen dos ventajas sobre muchos de los algoritmos que hemos analizado hasta ahora: <code class="docutils literal notranslate"><span class="pre">el</span> <span class="pre">modelo</span> <span class="pre">resultante</span> <span class="pre">puede</span> <span class="pre">ser</span> <span class="pre">fácilmente</span> <span class="pre">visualizado</span> <span class="pre">y</span> <span class="pre">entendido</span> <span class="pre">por</span> <span class="pre">personas</span> <span class="pre">no</span> <span class="pre">expertas</span> <span class="pre">(al</span> <span class="pre">menos</span> <span class="pre">para</span> <span class="pre">los</span> <span class="pre">árboles</span> <span class="pre">más</span> <span class="pre">pequeños)</span></code>, y los <code class="docutils literal notranslate"><span class="pre">algoritmos</span> <span class="pre">son</span> <span class="pre">completamente</span> <span class="pre">invariables</span> <span class="pre">a</span> <span class="pre">la</span> <span class="pre">escala</span> <span class="pre">de</span> <span class="pre">los</span> <span class="pre">datos</span></code>. Como <code class="docutils literal notranslate"><span class="pre">cada</span> <span class="pre">característica</span> <span class="pre">se</span> <span class="pre">procesa</span> <span class="pre">por</span> <span class="pre">separado</span></code>, y las posibles divisiones de los datos no dependen de la escala, no es necesario un preprocesamiento como la normalización o la estandarización de las características para los algoritmos de árboles de decisión.</p></li>
<li><p>En particular, los árboles de decisión funcionan bien cuando se tienen características que están en escalas completamente diferentes, o una mezcla de características binarias y continuas. <code class="docutils literal notranslate"><span class="pre">El</span> <span class="pre">principal</span> <span class="pre">inconveniente</span> <span class="pre">de</span> <span class="pre">los</span> <span class="pre">árboles</span> <span class="pre">de</span> <span class="pre">decisión</span> <span class="pre">es</span> <span class="pre">que,</span> <span class="pre">incluso</span> <span class="pre">con</span> <span class="pre">el</span> <span class="pre">uso</span> <span class="pre">de</span> <span class="pre">la</span> <span class="pre">pre-poda,</span> <span class="pre">tienden</span> <span class="pre">a</span> <span class="pre">sobreajustarse</span> <span class="pre">y</span> <span class="pre">a</span> <span class="pre">proporcionar</span> <span class="pre">un</span> <span class="pre">pobre</span> <span class="pre">rendimiento</span> <span class="pre">de</span> <span class="pre">generalización</span></code>. Por lo tanto, en la mayoría de las aplicaciones, los <code class="docutils literal notranslate"><span class="pre">métodos</span> <span class="pre">combiandos</span></code> que analizamos a continuación suelen utilizarse en lugar de un único árbol de decisión.</p></li>
</ul>
</section>
<section id="ensamble-de-arboles-de-decision">
<h3>Ensamble de árboles de decisión<a class="headerlink" href="#ensamble-de-arboles-de-decision" title="Permalink to this headline">#</a></h3>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">Los</span> <span class="pre">ensambles</span> <span class="pre">son</span> <span class="pre">métodos</span> <span class="pre">que</span> <span class="pre">combinan</span> <span class="pre">múltiples</span> <span class="pre">modelos</span> <span class="pre">de</span> <span class="pre">aprendizaje</span> <span class="pre">automático</span> <span class="pre">para</span> <span class="pre">crear</span> <span class="pre">modelos</span> <span class="pre">más</span> <span class="pre">potentes</span></code>. Hay muchos modelos en la literatura de aprendizaje automático que pertenecen a esta categoría, pero hay dos modelos de ensamble que han demostrado su eficacia en una amplia gama de conjuntos de datos de clasificación y regresión, ambos utilizan árboles de decisión como bloques de construcción: los <code class="docutils literal notranslate"><span class="pre">random</span> <span class="pre">forest</span></code> y los <code class="docutils literal notranslate"><span class="pre">gradient</span> <span class="pre">boosted</span> <span class="pre">decision</span> <span class="pre">trees.</span></code></p></li>
</ul>
<p><strong><code class="docutils literal notranslate"><span class="pre">Bosques</span> <span class="pre">aleatorios</span></code></strong></p>
<ul class="simple">
<li><p>Como acabamos de observar, uno de los principales inconvenientes de <code class="docutils literal notranslate"><span class="pre">los</span> <span class="pre">árboles</span> <span class="pre">de</span> <span class="pre">decisión</span> <span class="pre">es</span> <span class="pre">que</span> <span class="pre">tienden</span> <span class="pre">a</span> <span class="pre">sobreajustar</span> <span class="pre">los</span> <span class="pre">datos</span> <span class="pre">de</span> <span class="pre">entrenamiento.</span> <span class="pre">Los</span> <span class="pre">bosques</span> <span class="pre">aleatorios</span> <span class="pre">son</span> <span class="pre">una</span> <span class="pre">forma</span> <span class="pre">de</span> <span class="pre">abordar</span> <span class="pre">este</span> <span class="pre">problema</span></code>. Un bosque aleatorio es esencialmente una colección de árboles de decisión, donde cada árbol es ligeramente diferente de de los demás. La idea detrás de los bosques aleatorios es que cada árbol puede hacer un trabajo de predicción relativamente bien, pero es probable que se ajuste demasiado a una parte de los datos. <code class="docutils literal notranslate"><span class="pre">Si</span> <span class="pre">construimos</span> <span class="pre">muchos</span> <span class="pre">árboles,</span> <span class="pre">todos</span> <span class="pre">los</span> <span class="pre">cuales</span> <span class="pre">funcionan</span> <span class="pre">bien</span> <span class="pre">y</span> <span class="pre">se</span> <span class="pre">ajustan</span> <span class="pre">en</span> <span class="pre">exceso</span> <span class="pre">de</span> <span class="pre">diferentes</span> <span class="pre">maneras,</span> <span class="pre">podemos</span> <span class="pre">reducir</span> <span class="pre">la</span> <span class="pre">cantidad</span> <span class="pre">de</span> <span class="pre">sobreajuste</span> <span class="pre">promediando</span> <span class="pre">sus</span> <span class="pre">resultados</span></code>. Esta reducción de overfitting, al tiempo que se mantiene el poder de predicción de los árboles se puede verificar matemáticamente.</p></li>
<li><p>Para poner en práctica esta estrategia, tenemos que construir muchos árboles de decisión. Cada árbol debe hacer un trabajo aceptable de predicción del objetivo, y también debe ser diferente de los otros árboles. Los bosques aleatorios reciben su nombre de la inyección de aleatoriedad en la construcción de árboles para garantizar que cada árbol sea diferente. Hay dos formas de aleatorizar los árboles de un bosque aleatorio: <code class="docutils literal notranslate"><span class="pre">seleccionando</span> <span class="pre">los</span> <span class="pre">puntos</span> <span class="pre">de</span> <span class="pre">datos</span> <span class="pre">utilizados</span> <span class="pre">para</span> <span class="pre">construir</span> <span class="pre">un</span> <span class="pre">árbol</span> <span class="pre">y</span> <span class="pre">seleccionando</span> <span class="pre">las</span> <span class="pre">características</span> <span class="pre">en</span> <span class="pre">cada</span> <span class="pre">prueba</span> <span class="pre">de</span> <span class="pre">división</span></code>. Veamos este proceso con más detalle.</p></li>
</ul>
<p><strong><code class="docutils literal notranslate"><span class="pre">Construcción</span> <span class="pre">de</span> <span class="pre">bosques</span> <span class="pre">aleatorios</span></code></strong></p>
<ul class="simple">
<li><p>Para construir un modelo de bosque aleatorio (<code class="docutils literal notranslate"><span class="pre">random</span> <span class="pre">forest</span></code>), hay que decidir el número de árboles a construir (el parámetro <code class="docutils literal notranslate"><span class="pre">n_estimators</span></code> de <code class="docutils literal notranslate"><span class="pre">RandomForestRegressor</span></code> o <code class="docutils literal notranslate"><span class="pre">RandomForestClassifier</span></code>). Digamos que queremos construir 10 árboles. Estos árboles se construirán de forma completamente independiente unos de otros, y <code class="docutils literal notranslate"><span class="pre">el</span> <span class="pre">algoritmo</span> <span class="pre">hará</span> <span class="pre">elecciones</span> <span class="pre">aleatorias</span> <span class="pre">diferentes</span> <span class="pre">para</span> <span class="pre">cada</span> <span class="pre">árbol</span> <span class="pre">con</span> <span class="pre">el</span> <span class="pre">fin</span> <span class="pre">de</span> <span class="pre">asegurarse</span> <span class="pre">de</span> <span class="pre">que</span> <span class="pre">los</span> <span class="pre">árboles</span> <span class="pre">son</span> <span class="pre">distintos</span></code>.</p></li>
<li><p>Para construir un árbol, primero tomamos lo que se llama una <code class="docutils literal notranslate"><span class="pre">muestra</span> <span class="pre">bootstrap</span></code> de nuestros datos. Es decir, a partir de nuestras <code class="docutils literal notranslate"><span class="pre">n_samples</span></code> (puntos de datos), extraemos repetidamente un ejemplo al azar con reemplazo (lo que significa que la misma muestra puede ser elegida varias veces), <code class="docutils literal notranslate"><span class="pre">n_samples</span></code> veces. Esto creará un conjunto de datos que es tan grande como el conjunto de datos original, pero en el que faltarán algunos puntos de dato (aproximadamente un tercio), y algunos se repetirán.</p></li>
<li><p>Para ilustrarlo, digamos que queremos crear una <code class="docutils literal notranslate"><span class="pre">muestra</span> <span class="pre">bootstrap</span></code> de la lista <code class="docutils literal notranslate"><span class="pre">['a',</span> <span class="pre">'b',</span> <span class="pre">'c',</span> <span class="pre">'d']</span></code>. Una posible muestra bootstrap sería <code class="docutils literal notranslate"><span class="pre">['b',</span> <span class="pre">'d',</span> <span class="pre">'d',</span> <span class="pre">'c']</span></code>. Otra muestra posible sería <code class="docutils literal notranslate"><span class="pre">['d',</span> <span class="pre">'a',</span> <span class="pre">'d',</span> <span class="pre">'a']</span></code>. A continuación, <code class="docutils literal notranslate"><span class="pre">se</span> <span class="pre">construye</span> <span class="pre">un</span> <span class="pre">árbol</span> <span class="pre">de</span> <span class="pre">decisión</span> <span class="pre">basado</span> <span class="pre">en</span> <span class="pre">este</span> <span class="pre">conjunto</span> <span class="pre">de</span> <span class="pre">datos</span> <span class="pre">(muestra</span> <span class="pre">bootstrap)</span> <span class="pre">recién</span> <span class="pre">creado</span></code>. Sin embargo, el algoritmo que hemos descrito para el árbol de decisión se ha modificado ligeramente. En lugar de buscar la mejor prueba para cada nodo, el algoritmo <code class="docutils literal notranslate"><span class="pre">selecciona</span> <span class="pre">aleatoriamente</span> <span class="pre">un</span> <span class="pre">subconjunto</span> <span class="pre">de</span> <span class="pre">características</span> <span class="pre">y</span> <span class="pre">busca</span> <span class="pre">la</span> <span class="pre">mejor</span> <span class="pre">prueba</span> <span class="pre">posible</span> <span class="pre">que</span> <span class="pre">incluya</span> <span class="pre">una</span> <span class="pre">de</span> <span class="pre">estas</span> <span class="pre">características</span></code>.</p></li>
</ul>
<ul class="simple">
<li><p>El número de características que se seleccionan se controla con el parámetro <code class="docutils literal notranslate"><span class="pre">max_features</span></code>. La selección de un subconjunto de características se repite por separado en cada nodo, de modo que <code class="docutils literal notranslate"><span class="pre">cada</span> <span class="pre">nodo</span> <span class="pre">de</span> <span class="pre">un</span> <span class="pre">árbol</span> <span class="pre">puede</span> <span class="pre">tomar</span> <span class="pre">una</span> <span class="pre">decisión</span> <span class="pre">utilizando</span> <span class="pre">un</span> <span class="pre">subconjunto</span> <span class="pre">diferente</span> <span class="pre">de</span> <span class="pre">las</span> <span class="pre">características</span></code>. <code class="docutils literal notranslate"><span class="pre">El</span> <span class="pre">muestreo</span> <span class="pre">bootstrap</span> <span class="pre">hace</span> <span class="pre">que</span> <span class="pre">cada</span> <span class="pre">árbol</span> <span class="pre">de</span> <span class="pre">decisión</span> <span class="pre">del</span> <span class="pre">bosque</span> <span class="pre">aleatorio</span> <span class="pre">se</span> <span class="pre">construya</span> <span class="pre">en</span> <span class="pre">un</span> <span class="pre">conjunto</span> <span class="pre">de</span> <span class="pre">datos</span> <span class="pre">ligeramente</span> <span class="pre">diferente</span></code>. Debido a la selección de características en cada nodo, cada división de cada árbol opera con un subconjunto diferente de características. Juntos, estos dos mecanismos aseguran que todos los árboles del bosque aleatorio son diferentes.</p></li>
<li><p>En este proceso el parámetro <code class="docutils literal notranslate"><span class="pre">max_features</span></code> es crítico. Si establecemos <code class="docutils literal notranslate"><span class="pre">max_features</span></code> en <code class="docutils literal notranslate"><span class="pre">n_features</span></code>, <code class="docutils literal notranslate"><span class="pre">significa</span> <span class="pre">que</span> <span class="pre">cada</span> <span class="pre">división</span> <span class="pre">puede</span> <span class="pre">mirar</span> <span class="pre">todas</span> <span class="pre">las</span> <span class="pre">características</span> <span class="pre">del</span> <span class="pre">conjunto</span> <span class="pre">de</span> <span class="pre">datos,</span> <span class="pre">y</span> <span class="pre">no</span> <span class="pre">se</span> <span class="pre">inyectará</span> <span class="pre">aleatoriedad</span> <span class="pre">ninguna</span> <span class="pre">en</span> <span class="pre">la</span> <span class="pre">selección</span> <span class="pre">de</span> <span class="pre">características</span></code> (la aleatoriedad debida al bootstrap permanece, sin embargo). Si establecemos <code class="docutils literal notranslate"><span class="pre">max_features</span> <span class="pre">en</span> <span class="pre">1,</span> <span class="pre">esto</span> <span class="pre">significa</span> <span class="pre">que</span> <span class="pre">las</span> <span class="pre">divisiones</span> <span class="pre">no</span> <span class="pre">tienen</span> <span class="pre">ninguna</span> <span class="pre">opción</span> <span class="pre">sobre</span> <span class="pre">qué</span> <span class="pre">característica</span> <span class="pre">probar</span></code>, y sólo pueden buscar sobre diferentes umbrales para la característica que fue seleccionada  al azar. Por lo tanto, un <code class="docutils literal notranslate"><span class="pre">max_feature</span></code> significa que los árboles del bosque aleatorio serán bastante similares y podrán con facilidad ajustarse a los datos, utilizando las características más distintivas. <code class="docutils literal notranslate"><span class="pre">Un</span> <span class="pre">max_features</span> <span class="pre">bajo</span> <span class="pre">significa</span> <span class="pre">que</span> <span class="pre">los</span> <span class="pre">árboles</span> <span class="pre">del</span> <span class="pre">bosque</span> <span class="pre">aleatorio</span> <span class="pre">serán</span> <span class="pre">bastante</span> <span class="pre">diferentes,</span> <span class="pre">y</span> <span class="pre">que</span> <span class="pre">cada</span> <span class="pre">árbol</span> <span class="pre">puede</span> <span class="pre">necesitar</span> <span class="pre">ser</span> <span class="pre">muy</span> <span class="pre">profundo</span> <span class="pre">para</span> <span class="pre">ajustarse</span> <span class="pre">bien</span> <span class="pre">a</span> <span class="pre">los</span> <span class="pre">datos</span></code>.</p></li>
<li><p>Para hacer una predicción utilizando el bosque aleatorio, el algoritmo realiza primero una predicción para cada árbol del bosque. <code class="docutils literal notranslate"><span class="pre">Para</span> <span class="pre">la</span> <span class="pre">regresión,</span> <span class="pre">podemos</span> <span class="pre">promediar</span> <span class="pre">estos</span> <span class="pre">resultados</span> <span class="pre">para</span> <span class="pre">obtener</span> <span class="pre">nuestra</span> <span class="pre">predicción</span> <span class="pre">final</span></code>. Para la clasificación, se utiliza una estrategia de <code class="docutils literal notranslate"><span class="pre">&quot;votación</span> <span class="pre">suave&quot;</span></code>. Esto significa que cada algoritmo hace una predicción <code class="docutils literal notranslate"><span class="pre">&quot;suave&quot;</span></code>, proporcionando una probabilidad para cada posible etiqueta de salida. <code class="docutils literal notranslate"><span class="pre">Las</span> <span class="pre">probabilidades</span> <span class="pre">predichas</span> <span class="pre">por</span> <span class="pre">todos</span> <span class="pre">los</span> <span class="pre">árboles</span> <span class="pre">se</span> <span class="pre">promedian</span> <span class="pre">y</span> <span class="pre">se</span> <span class="pre">predice</span> <span class="pre">la</span> <span class="pre">clase</span> <span class="pre">con</span> <span class="pre">la</span> <span class="pre">mayor</span> <span class="pre">probabilidad</span></code>.</p></li>
</ul>
<figure class="align-center" id="random-forest-diagram">
<a class="reference internal image-reference" href="_images/random-forest-diagram.png"><img alt="_images/random-forest-diagram.png" src="_images/random-forest-diagram.png" style="width: 574.0px; height: 438.9px;" /></a>
</figure>
<p><strong><code class="docutils literal notranslate"><span class="pre">Análisis</span> <span class="pre">de</span> <span class="pre">los</span> <span class="pre">bosques</span> <span class="pre">aleatorios</span></code></strong>. Apliquemos un bosque aleatorio compuesto por cinco árboles al conjunto de datos <code class="docutils literal notranslate"><span class="pre">two_moons</span></code></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">make_moons</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">mglearn</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">make_moons</span><span class="p">(</span><span class="n">n_samples</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">noise</span><span class="o">=</span><span class="mf">0.25</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">stratify</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>
<span class="n">forest</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="n">forest</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>RandomForestClassifier(n_estimators=5, random_state=2)
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">Los</span> <span class="pre">árboles</span> <span class="pre">que</span> <span class="pre">se</span> <span class="pre">construyen</span> <span class="pre">como</span> <span class="pre">parte</span> <span class="pre">del</span> <span class="pre">bosque</span> <span class="pre">aleatorio</span> <span class="pre">se</span> <span class="pre">almacenan</span> <span class="pre">en</span> <span class="pre">estimator_attribute</span></code>. Visualicemos los límites de decisión aprendidos por cada árbol, junto con su predicción agregada</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">axes</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>

<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">ax</span><span class="p">,</span> <span class="n">tree</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">axes</span><span class="o">.</span><span class="n">ravel</span><span class="p">(),</span> <span class="n">forest</span><span class="o">.</span><span class="n">estimators_</span><span class="p">)):</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Tree </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">i</span><span class="p">))</span>
    <span class="n">mglearn</span><span class="o">.</span><span class="n">plots</span><span class="o">.</span><span class="n">plot_tree_partition</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">tree</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">)</span>

<span class="n">mglearn</span><span class="o">.</span><span class="n">plots</span><span class="o">.</span><span class="n">plot_2d_separator</span><span class="p">(</span><span class="n">forest</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">fill</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">axes</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">.4</span><span class="p">)</span>
<span class="n">axes</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Random Forest&quot;</span><span class="p">)</span>
<span class="n">mglearn</span><span class="o">.</span><span class="n">discrete_scatter</span><span class="p">(</span><span class="n">X_train</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">X_train</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">y_train</span><span class="p">);</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/decision_tree_79_0.png" src="_images/decision_tree_79_0.png" />
</div>
</div>
<ul class="simple">
<li><p>Se puede ver claramente que los límites de decisión aprendidos por los cinco árboles son bastante diferentes. Cada uno de ellos comete algunos errores, ya que algunos de los puntos que se representan aquí no se incluyeron en los conjuntos de entrenamiento de los árboles, debido al muestreo bootstrap. <code class="docutils literal notranslate"><span class="pre">El</span> <span class="pre">bosque</span> <span class="pre">aleatorio</span> <span class="pre">se</span> <span class="pre">ajusta</span> <span class="pre">menos</span> <span class="pre">que</span> <span class="pre">cualquiera</span> <span class="pre">de</span> <span class="pre">los</span> <span class="pre">árboles</span> <span class="pre">por</span> <span class="pre">separado</span> <span class="pre">y</span> <span class="pre">proporciona</span> <span class="pre">un</span> <span class="pre">límite</span> <span class="pre">de</span> <span class="pre">decisión</span> <span class="pre">mucho</span> <span class="pre">más</span> <span class="pre">intuitivo</span></code>. En cualquier aplicación real, utilizaríamos muchos más árboles (a menudo cientos o miles), lo que daría lugar a límites aún más suaves.</p></li>
</ul>
<ul class="simple">
<li><p>Como otro ejemplo, apliquemos un bosque aleatorio compuesto por 100 árboles en el conjunto de datos <code class="docutils literal notranslate"><span class="pre">Breast</span> <span class="pre">Cancer</span></code></p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_breast_cancer</span>
<span class="n">cancer</span> <span class="o">=</span> <span class="n">load_breast_cancer</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">cancer</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">cancer</span><span class="o">.</span><span class="n">target</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">forest</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">n_estimators</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">forest</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Accuracy on training set: </span><span class="si">{:.3f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">forest</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Accuracy on test set: </span><span class="si">{:.3f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">forest</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Accuracy on training set: 0.993
Accuracy on test set: 0.965
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">El</span> <span class="pre">bosque</span> <span class="pre">aleatorio</span> <span class="pre">nos</span> <span class="pre">da</span> <span class="pre">una</span> <span class="pre">precisión</span> <span class="pre">del</span> <span class="pre">97%,</span> <span class="pre">mejor</span> <span class="pre">que</span> <span class="pre">los</span> <span class="pre">modelos</span> <span class="pre">lineales</span> <span class="pre">o</span> <span class="pre">un</span> <span class="pre">árbol</span> <span class="pre">de</span> <span class="pre">decisión</span> <span class="pre">único,</span> <span class="pre">sin</span> <span class="pre">necesidad</span> <span class="pre">de</span> <span class="pre">ajustar</span> <span class="pre">ningún</span> <span class="pre">parámetro</span></code>. Podríamos ajustar la configuración de <code class="docutils literal notranslate"><span class="pre">max_features</span></code>, o aplicar la pre-selección como hicimos con el árbol de decisión simple. Sin embargo, a menudo los parámetros por defecto del bosque aleatorio ya funcionan bastante bien. <code class="docutils literal notranslate"><span class="pre">Al</span> <span class="pre">igual</span> <span class="pre">que</span> <span class="pre">el</span> <span class="pre">árbol</span> <span class="pre">de</span> <span class="pre">decisión,</span> <span class="pre">el</span> <span class="pre">bosque</span> <span class="pre">aleatorio</span> <span class="pre">proporciona</span> <span class="pre">importancias</span> <span class="pre">de</span> <span class="pre">características,</span> <span class="pre">que</span> <span class="pre">se</span> <span class="pre">calculan</span> <span class="pre">agregando</span> <span class="pre">las</span> <span class="pre">importancias</span> <span class="pre">de</span> <span class="pre">las</span> <span class="pre">características</span> <span class="pre">en</span> <span class="pre">los</span> <span class="pre">árboles</span> <span class="pre">del</span> <span class="pre">bosque</span></code>. Normalmente, las <code class="docutils literal notranslate"><span class="pre">importancias</span> <span class="pre">de</span> <span class="pre">las</span> <span class="pre">características</span> <span class="pre">proporcionadas</span> <span class="pre">por</span> <span class="pre">el</span> <span class="pre">bosque</span> <span class="pre">aleatorio</span> <span class="pre">son</span> <span class="pre">más</span> <span class="pre">fiables</span> <span class="pre">que</span> <span class="pre">las</span> <span class="pre">proporcionadas</span> <span class="pre">por</span> <span class="pre">un</span> <span class="pre">solo</span> <span class="pre">árbol</span></code>.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plot_feature_importances_cancer</span><span class="p">(</span><span class="n">forest</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/decision_tree_85_0.png" src="_images/decision_tree_85_0.png" />
</div>
</div>
<ul class="simple">
<li><p>Como puede ver, <code class="docutils literal notranslate"><span class="pre">el</span> <span class="pre">bosque</span> <span class="pre">aleatorio</span> <span class="pre">da</span> <span class="pre">una</span> <span class="pre">importancia</span> <span class="pre">no</span> <span class="pre">nula</span> <span class="pre">a</span> <span class="pre">muchas</span> <span class="pre">más</span> <span class="pre">características</span> <span class="pre">que</span> <span class="pre">el</span> <span class="pre">árbol</span> <span class="pre">simple</span></code>. Al igual que el árbol de decisión simple, el bosque aleatorio también da importancia a la característica <code class="docutils literal notranslate"><span class="pre">&quot;worst</span> <span class="pre">radius&quot;</span></code>, pero en realidad elige <code class="docutils literal notranslate"><span class="pre">&quot;worst</span> <span class="pre">perimeter&quot;</span></code> como la <code class="docutils literal notranslate"><span class="pre">característica</span> <span class="pre">más</span> <span class="pre">informativa</span></code>. <code class="docutils literal notranslate"><span class="pre">La</span> <span class="pre">aleatoriedad</span> <span class="pre">en</span> <span class="pre">la</span> <span class="pre">construcción</span> <span class="pre">del</span> <span class="pre">bosque</span> <span class="pre">aleatorio</span> <span class="pre">obliga</span> <span class="pre">al</span> <span class="pre">algoritmo</span> <span class="pre">a</span> <span class="pre">considerar</span> <span class="pre">muchas</span> <span class="pre">explicaciones</span> <span class="pre">posibles</span></code>. El resultado es que el bosque aleatorio capta una imagen mucho más amplia de los datos que un árbol simple.</p></li>
</ul>
<div class="tip admonition">
<p class="admonition-title">Observación</p>
<p>La <code class="docutils literal notranslate"><span class="pre">importancia</span> <span class="pre">de</span> <span class="pre">la</span> <span class="pre">característica</span></code> se calcula como la disminución de la impureza del nodo ponderada por la probabilidad de alcanzar ese nodo. <code class="docutils literal notranslate"><span class="pre">La</span> <span class="pre">probabilidad</span> <span class="pre">del</span> <span class="pre">nodo</span> <span class="pre">puede</span> <span class="pre">calcularse</span> <span class="pre">mediante</span> <span class="pre">el</span> <span class="pre">número</span> <span class="pre">de</span> <span class="pre">muestras</span> <span class="pre">que</span> <span class="pre">llegan</span> <span class="pre">al</span> <span class="pre">nodo,</span> <span class="pre">dividido</span> <span class="pre">por</span> <span class="pre">el</span> <span class="pre">número</span> <span class="pre">total</span> <span class="pre">de</span> <span class="pre">muestras.</span> <span class="pre">Cuanto</span> <span class="pre">mayor</span> <span class="pre">sea</span> <span class="pre">el</span> <span class="pre">valor,</span> <span class="pre">más</span> <span class="pre">importante</span> <span class="pre">será</span> <span class="pre">la</span> <span class="pre">característica</span></code>. Si tenemos <span class="math notranslate nohighlight">\(C\)</span> clases totales y <span class="math notranslate nohighlight">\(p(i)\)</span> es la probabilidad de escoger un punto de datos con la clase <span class="math notranslate nohighlight">\(i\)</span>, entonces la <code class="docutils literal notranslate"><span class="pre">impureza</span> <span class="pre">de</span> <span class="pre">Gini</span></code> se calcula como</p>
<div class="math notranslate nohighlight">
\[
G=\sum_{i=1}^{C}p(i)(1-p(i)).
\]</div>
</div>
<p><strong><code class="docutils literal notranslate"><span class="pre">Puntos</span> <span class="pre">fuertes,</span> <span class="pre">puntos</span> <span class="pre">débiles</span> <span class="pre">y</span> <span class="pre">parámetros</span></code></strong></p>
<ul class="simple">
<li><p>Los bosques aleatorios para la regresión y la clasificación se encuentran actualmente entre los métodos de aprendizaje automático más utilizados. <code class="docutils literal notranslate"><span class="pre">Son</span> <span class="pre">muy</span> <span class="pre">potentes,</span> <span class="pre">suelen</span> <span class="pre">funcionar</span> <span class="pre">bien</span> <span class="pre">sin</span> <span class="pre">necesidad</span> <span class="pre">de</span> <span class="pre">ajustar</span> <span class="pre">mucho</span> <span class="pre">los</span> <span class="pre">parámetros</span> <span class="pre">y</span> <span class="pre">no</span> <span class="pre">requieren</span> <span class="pre">el</span> <span class="pre">escalado</span> <span class="pre">de</span> <span class="pre">los</span> <span class="pre">datos</span></code>. Esencialmente, los bosques aleatorios comparten todos los beneficios de los árboles de decisión, mientras que compensan algunas de sus deficiencias. Una razón para seguir utilizando los árboles de decisión es, <strong><code class="docutils literal notranslate"><span class="pre">si</span> <span class="pre">se</span> <span class="pre">necesita</span> <span class="pre">una</span> <span class="pre">representación</span> <span class="pre">compacta</span> <span class="pre">del</span> <span class="pre">proceso</span> <span class="pre">de</span> <span class="pre">toma</span> <span class="pre">de</span> <span class="pre">decisiones</span></code></strong>. Es básicamente imposible interpretar decenas o cientos de árboles en detalle, y los árboles de los bosques aleatorios tienden a ser más profundos que los árboles de decisión (debido al uso de subconjuntos de características). Por lo tanto, si se necesita resumir las predicciones de forma visual para los no expertos, un único árbol de decisión puede ser la mejor opción.</p></li>
<li><p>Aunque la construcción de bosques aleatorios en grandes conjuntos de datos puede llevar algo de tiempo, <code class="docutils literal notranslate"><span class="pre">se</span> <span class="pre">puede</span> <span class="pre">paralelizar</span> <span class="pre">a</span> <span class="pre">través</span> <span class="pre">de</span> <span class="pre">múltiples</span> <span class="pre">núcleos</span> <span class="pre">de</span> <span class="pre">CPU</span> <span class="pre">dentro</span> <span class="pre">de</span> <span class="pre">un</span> <span class="pre">ordenador</span> <span class="pre">fácilmente</span></code>. Si utiliza un procesador multinúcleo (como casi todos los ordenadores modernos),  puede utilizar el parámetro <code class="docutils literal notranslate"><span class="pre">n_jobs</span></code> para ajustar el número de núcleos a utilizar. El uso de más núcleos de la CPU dará lugar a un aumento lineal de la velocidad (utilizando dos núcleos, el entrenamiento del bosque aleatorio será el doble de rápido), pero especificar <code class="docutils literal notranslate"><span class="pre">n_jobs</span></code> mayor que el número de núcleos no ayudará. <code class="docutils literal notranslate"><span class="pre">Puede</span> <span class="pre">establecer</span> <span class="pre">n_jobs=-1</span> <span class="pre">para</span> <span class="pre">utilizar</span> <span class="pre">todos</span> <span class="pre">los</span> <span class="pre">núcleos</span> <span class="pre">en</span> <span class="pre">su</span> <span class="pre">ordenador</span></code>.</p></li>
<li><p>Debe tener en cuenta que los bosques aleatorios, por su naturaleza, son aleatorios, y establecen diferentes estados aleatorios (o no establecen el <code class="docutils literal notranslate"><span class="pre">random_state</span></code> en absoluto) puede cambiar drásticamente el modelo que se construye. <code class="docutils literal notranslate"><span class="pre">Cuanto</span> <span class="pre">más</span> <span class="pre">árboles</span> <span class="pre">haya</span> <span class="pre">en</span> <span class="pre">el</span> <span class="pre">bosque,</span> <span class="pre">más</span> <span class="pre">robusto</span> <span class="pre">será</span> <span class="pre">frente</span> <span class="pre">a</span> <span class="pre">la</span> <span class="pre">elección</span> <span class="pre">del</span> <span class="pre">estado</span> <span class="pre">aleatorio</span></code>. Si quiere tener resultados reproducibles, es importante fijar el <code class="docutils literal notranslate"><span class="pre">random_state</span></code> a caulquier número entero. <code class="docutils literal notranslate"><span class="pre">Los</span> <span class="pre">bosques</span> <span class="pre">aleatorios</span> <span class="pre">no</span> <span class="pre">tienden</span> <span class="pre">a</span> <span class="pre">funcionar</span> <span class="pre">bien</span> <span class="pre">en</span> <span class="pre">datos</span> <span class="pre">muy</span> <span class="pre">dimensionales</span> <span class="pre">y</span> <span class="pre">escasos,</span> <span class="pre">como</span> <span class="pre">los</span> <span class="pre">datos</span> <span class="pre">de</span> <span class="pre">texto</span></code>. Para este tipo de datos, los modelos lineales pueden ser más apropiados. Los bosques aleatorios suelen funcionar bien incluso en conjuntos de datos muy grandes, y el entrenamiento se puede paralelizar fácilmente en muchos núcleos de la CPU de un ordenador potente.  Sin embargo, <code class="docutils literal notranslate"><span class="pre">los</span> <span class="pre">bosques</span> <span class="pre">aleatorios</span> <span class="pre">requieren</span> <span class="pre">más</span> <span class="pre">memoria</span> <span class="pre">y</span> <span class="pre">son</span> <span class="pre">más</span> <span class="pre">lentos</span> <span class="pre">de</span> <span class="pre">entrenar</span> <span class="pre">y</span> <span class="pre">predecir</span> <span class="pre">que</span> <span class="pre">los</span> <span class="pre">modelos</span> <span class="pre">lineales</span></code>. Si el tiempo y la memoria son importantes en una aplicación, puede tener sentido utilizar un modelo lineal en su lugar.</p></li>
<li><p>Los parámetros importantes a ajustar son <code class="docutils literal notranslate"><span class="pre">n_estimators</span> <span class="pre">,</span> <span class="pre">max_features</span></code>, y posiblemente opciones de pre-poda como <code class="docutils literal notranslate"><span class="pre">max_depth</span></code>. En el caso de <code class="docutils literal notranslate"><span class="pre">n_estimators</span></code>, un número mayor es siempre mejor. <code class="docutils literal notranslate"><span class="pre">Promediar</span> <span class="pre">más</span> <span class="pre">árboles</span> <span class="pre">dará</span> <span class="pre">lugar</span> <span class="pre">a</span> <span class="pre">un</span> <span class="pre">conjunto</span> <span class="pre">más</span> <span class="pre">robusto</span> <span class="pre">al</span> <span class="pre">reducir</span> <span class="pre">el</span> <span class="pre">sobreajuste</span></code>. Sin embargo, hay rendimientos decrecientes, y más árboles necesitan más memoria y más tiempo para entrenar. Una regla común es construir “tantos como tenga tiempo/memoria”.  Como se ha descrito anteriormente, <code class="docutils literal notranslate"><span class="pre">max_features</span></code> determina el grado de aleatoriedad de cada árbol, y un <code class="docutils literal notranslate"><span class="pre">max_features</span> <span class="pre">pequeño</span> <span class="pre">reduce</span> <span class="pre">el</span> <span class="pre">sobreajuste</span></code>. En general, es una buena regla general utilizar los valores por defecto: <code class="docutils literal notranslate"><span class="pre">max_features=sqrt(n_features)</span></code> para la clasificación y <code class="docutils literal notranslate"><span class="pre">max_features=log2(n_features)</span></code> para la regresión. Añadir <code class="docutils literal notranslate"><span class="pre">max_features</span></code> o <code class="docutils literal notranslate"><span class="pre">max_leaf_nodes</span></code> puede mejorar a veces el rendimiento. También puede reducir drásticamente los requisitos de espacio y tiempo para el entrenamiento y la predicción.</p></li>
</ul>
<p><strong><code class="docutils literal notranslate"><span class="pre">Árboles</span> <span class="pre">de</span> <span class="pre">regresión</span> <span class="pre">de</span> <span class="pre">gradiente</span> <span class="pre">reforzado</span> <span class="pre">(máquinas</span> <span class="pre">de</span> <span class="pre">gradiente</span> <span class="pre">reforzado)</span></code></strong></p>
<ul class="simple">
<li><p>El árbol de regresión de gradiente reforzado es otro método de conjunto que combina múltiples árboles de decisión. A pesar de la <code class="docutils literal notranslate"><span class="pre">&quot;regresión&quot;</span></code> en el nombre, estos modelos pueden utilizarse para la regresión y la clasificación. A diferencia del enfoque de bosque aleatorio, <code class="docutils literal notranslate"><span class="pre">el</span> <span class="pre">refuerzo</span> <span class="pre">de</span> <span class="pre">gradiente</span> <span class="pre">funciona</span> <span class="pre">construyendo</span> <span class="pre">árboles</span> <span class="pre">en</span> <span class="pre">forma</span> <span class="pre">de</span> <span class="pre">serie,</span> <span class="pre">en</span> <span class="pre">el</span> <span class="pre">que</span> <span class="pre">cada</span> <span class="pre">árbol</span> <span class="pre">trata</span> <span class="pre">de</span> <span class="pre">corregir</span> <span class="pre">los</span> <span class="pre">errores</span> <span class="pre">del</span> <span class="pre">anterior</span></code>. Por defecto, no hay aleatoriedad en los árboles de regresión de gradiente; en su lugar, <code class="docutils literal notranslate"><span class="pre">se</span> <span class="pre">utiliza</span> <span class="pre">una</span> <span class="pre">fuerte</span> <span class="pre">pre-poda</span></code>. Los árboles de impulso por gradiente suelen utilizar árboles muy poco profundos, de una a cinco profundidades, lo que hace que el modelo sea más pequeño en términos de memoria y que las predicciones sean más rápidas.</p></li>
<li><p>La idea principal del <code class="docutils literal notranslate"><span class="pre">gradient</span> <span class="pre">boosting</span></code> es combinar muchos modelos simples (en este contexto conocidos como aprendices débiles), como árboles poco profundos. Cada árbol sólo puede proporcionar buenas predicciones sobre una parte de los datos, por lo que se añaden más y más árboles para mejorar el rendimiento. <code class="docutils literal notranslate"><span class="pre">Los</span> <span class="pre">árboles</span> <span class="pre">con</span> <span class="pre">refuerzo</span> <span class="pre">de</span> <span class="pre">gradiente</span> <span class="pre">suelen</span> <span class="pre">ser</span> <span class="pre">los</span> <span class="pre">ganadores</span> <span class="pre">de</span> <span class="pre">los</span> <span class="pre">concursos</span> <span class="pre">de</span> <span class="pre">aprendizaje</span> <span class="pre">automático</span> <span class="pre">y</span> <span class="pre">se</span> <span class="pre">utilizan</span> <span class="pre">mucho</span> <span class="pre">en</span> <span class="pre">la</span> <span class="pre">industria</span></code>. Suelen ser un poco más sensibles a los ajustes de los parámetros que los bosques aleatorios, pero pueden proporcionar una mayor precisión si los parámetros se ajustan correctamente.</p></li>
<li><p>Aparte de la pre-poda y el número de árboles en el conjunto, otro parámetro importante del gradient boosting es la <code class="docutils literal notranslate"><span class="pre">tasa</span> <span class="pre">de</span> <span class="pre">aprendizaje,</span> <span class="pre">que</span> <span class="pre">controla</span> <span class="pre">la</span> <span class="pre">intensidad</span> <span class="pre">con</span> <span class="pre">la</span> <span class="pre">que</span> <span class="pre">cada</span> <span class="pre">árbol</span> <span class="pre">trata</span> <span class="pre">de</span> <span class="pre">corregir</span> <span class="pre">los</span> <span class="pre">errores</span> <span class="pre">de</span> <span class="pre">los</span> <span class="pre">árboles</span> <span class="pre">anteriores</span></code>. Una tasa de aprendizaje alta significa que cada árbol puede hacer correcciones más fuertes, lo que permite modelos más complejos. Si se añaden más árboles al conjunto, lo que puede conseguirse aumentando <code class="docutils literal notranslate"><span class="pre">n_estimators</span></code>, también aumenta la complejidad del modelo, ya que éste tiene más oportunidades de corregir errores en el conjunto de entrenamiento.</p></li>
</ul>
<ul class="simple">
<li><p>Este es un ejemplo del uso del clasificador <code class="docutils literal notranslate"><span class="pre">GradientBoosting</span></code> en el conjunto de datos del <code class="docutils literal notranslate"><span class="pre">Breast</span> <span class="pre">Cancer</span></code>. Por defecto, se utilizan 100 árboles de profundidad máxima 3 y una tasa de aprendizaje de 0.1</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">GradientBoostingClassifier</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_breast_cancer</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="n">cancer</span> <span class="o">=</span> <span class="n">load_breast_cancer</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">cancer</span><span class="o">.</span><span class="n">data</span><span class="p">,</span> <span class="n">cancer</span><span class="o">.</span><span class="n">target</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">gbrt</span> <span class="o">=</span> <span class="n">GradientBoostingClassifier</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">gbrt</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Accuracy on training set: </span><span class="si">{:.3f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">gbrt</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Accuracy on test set: </span><span class="si">{:.3f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">gbrt</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Accuracy on training set: 1.000
Accuracy on test set: 0.965
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Como la <code class="docutils literal notranslate"><span class="pre">precisión</span> <span class="pre">del</span> <span class="pre">conjunto</span> <span class="pre">de</span> <span class="pre">entrenamiento</span> <span class="pre">es</span> <span class="pre">del</span> <span class="pre">100%,</span> <span class="pre">es</span> <span class="pre">probable</span> <span class="pre">que</span> <span class="pre">estemos</span> <span class="pre">sobreajustando.</span> <span class="pre">Para</span> <span class="pre">reducir</span> <span class="pre">el</span> <span class="pre">sobreajuste,</span> <span class="pre">podemos</span> <span class="pre">aplicar</span> <span class="pre">una</span> <span class="pre">pre-poda</span> <span class="pre">más</span> <span class="pre">fuerte</span> <span class="pre">limitando</span> <span class="pre">la</span> <span class="pre">profundidad</span> <span class="pre">máxima</span> <span class="pre">o</span> <span class="pre">reducir</span> <span class="pre">la</span> <span class="pre">tasa</span> <span class="pre">de</span> <span class="pre">aprendizaje</span></code></p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">gbrt</span> <span class="o">=</span> <span class="n">GradientBoostingClassifier</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">max_depth</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">gbrt</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Accuracy on training set: </span><span class="si">{:.3f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">gbrt</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Accuracy on test set: </span><span class="si">{:.3f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">gbrt</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Accuracy on training set: 0.991
Accuracy on test set: 0.972
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">gbrt</span> <span class="o">=</span> <span class="n">GradientBoostingClassifier</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>
<span class="n">gbrt</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Accuracy on training set: </span><span class="si">{:.3f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">gbrt</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Accuracy on test set: </span><span class="si">{:.3f}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">gbrt</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Accuracy on training set: 0.988
Accuracy on test set: 0.965
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Ambos métodos para disminuir la complejidad del modelo <code class="docutils literal notranslate"><span class="pre">redujeron</span> <span class="pre">la</span> <span class="pre">precisión</span> <span class="pre">del</span> <span class="pre">conjunto</span> <span class="pre">de</span> <span class="pre">entrenamiento,</span> <span class="pre">como</span> <span class="pre">era</span> <span class="pre">de</span> <span class="pre">esperar</span></code>. En este caso, <code class="docutils literal notranslate"><span class="pre">la</span> <span class="pre">reducción</span> <span class="pre">de</span> <span class="pre">la</span> <span class="pre">profundidad</span> <span class="pre">máxima</span> <span class="pre">de</span> <span class="pre">los</span> <span class="pre">árboles</span> <span class="pre">proporcionó</span> <span class="pre">una</span> <span class="pre">mejora</span> <span class="pre">significativa</span> <span class="pre">del</span> <span class="pre">modelo,</span> <span class="pre">mientras</span> <span class="pre">que</span> <span class="pre">la</span> <span class="pre">reducción</span> <span class="pre">de</span> <span class="pre">la</span> <span class="pre">tasa</span> <span class="pre">de</span> <span class="pre">aprendizaje</span> <span class="pre">sólo</span> <span class="pre">aumentó</span> <span class="pre">la</span> <span class="pre">precisión</span> <span class="pre">del</span> <span class="pre">conjunto</span> <span class="pre">de</span> <span class="pre">entrenamiento</span> <span class="pre">ligeramente</span></code>. En cuanto a los otros modelos basados en árboles de decisión, podemos volver a visualizar las características para obtener más información sobre nuestro modelo. Como utilizamos 100 árboles, es poco práctico inspeccionarlos todos, aunque todos tengan una profundidad de 1.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">gbrt</span> <span class="o">=</span> <span class="n">GradientBoostingClassifier</span><span class="p">(</span><span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">max_depth</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">gbrt</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
<span class="n">plot_feature_importances_cancer</span><span class="p">(</span><span class="n">gbrt</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/decision_tree_99_0.png" src="_images/decision_tree_99_0.png" />
</div>
</div>
<ul class="simple">
<li><p>Podemos ver que las importancias de las características de los árboles <code class="docutils literal notranslate"><span class="pre">gradient-boost</span></code> son algo similares a las de los bosques aleatorios, aunque el refuerzo del gradiente ignora por completo algunas de las características. Como tanto el refuerzo de gradiente como los bosques aleatorios funcionan bien en tipos de datos similares, <code class="docutils literal notranslate"><span class="pre">un</span> <span class="pre">enfoque</span> <span class="pre">común</span> <span class="pre">es</span> <span class="pre">probar</span> <span class="pre">primero</span> <span class="pre">los</span> <span class="pre">bosques</span> <span class="pre">aleatorios,</span> <span class="pre">que</span> <span class="pre">funcionan</span> <span class="pre">con</span> <span class="pre">bastante</span> <span class="pre">solidez.</span> <span class="pre">Si</span> <span class="pre">los</span> <span class="pre">bosques</span> <span class="pre">aleatorios</span> <span class="pre">funcionan</span> <span class="pre">bien,</span> <span class="pre">pero</span> <span class="pre">el</span> <span class="pre">tiempo</span> <span class="pre">de</span> <span class="pre">predicción</span> <span class="pre">es</span> <span class="pre">un</span> <span class="pre">problema,</span> <span class="pre">o</span> <span class="pre">si</span> <span class="pre">es</span> <span class="pre">importante</span> <span class="pre">exprimir</span> <span class="pre">el</span> <span class="pre">último</span> <span class="pre">porcentaje</span> <span class="pre">de</span> <span class="pre">precisión</span> <span class="pre">del</span> <span class="pre">modelo</span> <span class="pre">de</span> <span class="pre">aprendizaje</span> <span class="pre">automático,</span> <span class="pre">pasar</span> <span class="pre">a</span> <span class="pre">la</span> <span class="pre">refuerzo</span> <span class="pre">por</span> <span class="pre">gradiente</span> <span class="pre">suele</span> <span class="pre">ser</span> <span class="pre">útil</span></code>.</p></li>
<li><p><strong><code class="docutils literal notranslate"><span class="pre">Si</span> <span class="pre">quiere</span> <span class="pre">aplicar</span> <span class="pre">el</span> <span class="pre">refuerzo</span> <span class="pre">de</span> <span class="pre">gradiente</span> <span class="pre">a</span> <span class="pre">un</span> <span class="pre">problema</span> <span class="pre">a</span> <span class="pre">gran</span> <span class="pre">escala,</span> <span class="pre">puede</span> <span class="pre">que</span> <span class="pre">merezca</span> <span class="pre">la</span> <span class="pre">pena</span> <span class="pre">investigar</span> <span class="pre">el</span> <span class="pre">paquete</span> <span class="pre">xgboost</span> <span class="pre">y</span> <span class="pre">su</span> <span class="pre">interfaz</span> <span class="pre">de</span> <span class="pre">Python,</span> <span class="pre">que</span> <span class="pre">hasta</span> <span class="pre">el</span> <span class="pre">momento</span> <span class="pre">es</span> <span class="pre">más</span> <span class="pre">rápido</span> <span class="pre">(y</span> <span class="pre">a</span> <span class="pre">veces</span> <span class="pre">más</span> <span class="pre">fácil</span> <span class="pre">de</span> <span class="pre">usar)</span> <span class="pre">que</span> <span class="pre">la</span> <span class="pre">implementación</span> <span class="pre">de</span> <span class="pre">scikit-learn</span> <span class="pre">en</span> <span class="pre">muchos</span> <span class="pre">conjuntos</span> <span class="pre">de</span> <span class="pre">datos</span></code></strong>.</p></li>
</ul>
<p><strong><code class="docutils literal notranslate"><span class="pre">Puntos</span> <span class="pre">fuertes,</span> <span class="pre">puntos</span> <span class="pre">débiles</span> <span class="pre">y</span> <span class="pre">parámetros</span></code></strong></p>
<ul class="simple">
<li><p>Los árboles de decisión con refuerzo de gradiente se encuentran entre los modelos más potentes y utilizados para el aprendizaje supervisado. <code class="docutils literal notranslate"><span class="pre">Su</span> <span class="pre">principal</span> <span class="pre">inconveniente</span> <span class="pre">es</span> <span class="pre">que</span> <span class="pre">requieren</span> <span class="pre">un</span> <span class="pre">ajuste</span> <span class="pre">cuidadoso</span> <span class="pre">de</span> <span class="pre">los</span> <span class="pre">parámetros</span> <span class="pre">y</span> <span class="pre">pueden</span> <span class="pre">tardar</span> <span class="pre">mucho</span> <span class="pre">tiempo</span> <span class="pre">de</span> <span class="pre">entrenamiento</span></code>. Al igual que otros modelos basados en árboles, el algoritmo funciona bien sin escalar y con una mezcla de características binarias y continuas. Al igual que otros modelos basados en árboles tampoco suele funcionar bien con datos dispersos de alta dimensión.</p></li>
<li><p>Los principales parámetros de los modelos de árbol de gradiente reforzado son el número de árboles, <code class="docutils literal notranslate"><span class="pre">n_estimators</span></code>, y el <code class="docutils literal notranslate"><span class="pre">learning_rate</span></code> que <code class="docutils literal notranslate"><span class="pre">controla</span> <span class="pre">el</span> <span class="pre">grado</span> <span class="pre">en</span> <span class="pre">que</span> <span class="pre">cada</span> <span class="pre">árbol</span> <span class="pre">puede</span> <span class="pre">corregir</span> <span class="pre">los</span> <span class="pre">errores</span> <span class="pre">de</span> <span class="pre">los</span> <span class="pre">árboles</span> <span class="pre">anteriores</span></code>. Estos dos parámetros están muy interconectados, ya que una tasa de aprendizaje más baja significa que se necesitan más árboles para construir un modelo de complejidad similar. A diferencia de los bosques aleatorios, en los que un valor de <code class="docutils literal notranslate"><span class="pre">n_estimators</span></code> es siempre mejor, el aumento de <code class="docutils literal notranslate"><span class="pre">n_estimators</span></code> en el <code class="docutils literal notranslate"><span class="pre">gradient</span> <span class="pre">boosting</span></code> conduce a un modelo más complejo, lo que puede llevar a un sobreajuste. Una práctica común es ajustar <code class="docutils literal notranslate"><span class="pre">n_estimators</span></code> dependiendo del presupuesto de tiempo y memoria, y luego buscar sobre diferentes tasas de aprendizaje.</p></li>
<li><p>Otro parámetro importante es <code class="docutils literal notranslate"><span class="pre">max_depth</span></code> (o alternativamente <code class="docutils literal notranslate"><span class="pre">max_leaf_nodes</span></code>), para reducir la complejidad de cada árbol. <code class="docutils literal notranslate"><span class="pre">Por</span> <span class="pre">lo</span> <span class="pre">general,</span> <span class="pre">la</span> <span class="pre">profundidad</span> <span class="pre">máxima</span> <span class="pre">es</span> <span class="pre">muy</span> <span class="pre">baja</span> <span class="pre">para</span> <span class="pre">los</span> <span class="pre">modelos</span> <span class="pre">de</span> <span class="pre">gradiente,</span> <span class="pre">a</span> <span class="pre">menudo</span> <span class="pre">no</span> <span class="pre">más</span> <span class="pre">allá</span> <span class="pre">de</span> <span class="pre">cinco</span> <span class="pre">divisiones</span></code>.</p></li>
</ul>
</section>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "ml_venv"
        },
        kernelOptions: {
            kernelName: "ml_venv",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'ml_venv'</script>

              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="data_viz.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">Visualización de datos</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="model_evaluation.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Evaluación de modelos</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By Lihki Rubio - Email lihkir@uninorte.edu.co<br/>
  
      &copy; Copyright Departamento de Matemáticas y Estadística.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>